Namespace(accimage=False, annotation_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/UCF-101/json_annotations/ucf101_01.json'), arch='resnet-50', batch_size=16, batchnorm_sync=False, begin_epoch=1, checkpoint=5, colorjitter=False, conv1_t_size=7, conv1_t_stride=1, dampening=0.0, dataset='ucf101', dist_url='tcp://127.0.0.1:23456', distributed=False, file_type='jpg', ft_begin_module='', inference=False, inference_batch_size=16, inference_crop='center', inference_no_average=False, inference_stride=16, inference_subset='val', input_type='rgb', learning_rate=0.01, lr_scheduler='multistep', manual_seed=1, mean=[0.4345, 0.4051, 0.3775], mean_dataset='kinetics', model='resnet', model_depth=50, momentum=0.9, multistep_milestones=[40], n_classes=101, n_epochs=80, n_input_channels=3, n_pretrain_classes=0, n_threads=2, n_val_samples=3, nesterov=False, no_cuda=False, no_hflip=False, no_max_pool=False, no_mean_norm=False, no_std_norm=False, no_train=False, no_val=False, optimizer='sgd', output_topk=5, overwrite_milestones=False, plateau_patience=10, pretrain_path=None, receptive_size=9, resnet_shortcut='B', resnet_widen_factor=1.0, resnext_cardinality=32, result_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/results/UCF101'), resume_path=None, root_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff'), sample_duration=48, sample_size=64, sample_t_stride=1, std=[0.2768, 0.2713, 0.2737], tensorboard=True, train_crop='random', train_crop_min_ratio=0.75, train_crop_min_scale=0.25, train_t_crop='random', value_scale=1, video_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/UCF-101/jpg'), weight_decay=0.001, wide_resnet_k=2, world_size=-1)
DataParallel(
  (module): ResNet(
    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)
    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))
    (fc): Linear(in_features=2048, out_features=101, bias=True)
  )
)
random
random
Building VideoDataset for UCF-101.
Compose(
    RandomResizedCrop(size=(64, 64), scale=(0.25, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    <spatial_transforms.ScaleValue object at 0x7f9bcc29a5b0>
    Normalize(mean=[0.4345, 0.4051, 0.3775], std=[0.2768, 0.2713, 0.2737])
)
<temporal_transforms.Compose object at 0x7f9bcc29a730>
<datasets.loader.VideoLoader object at 0x7f9bcc29a790>
dataset loading [0/9537]
dataset loading [1907/9537]
dataset loading [3814/9537]
dataset loading [5721/9537]
dataset loading [7628/9537]
dataset loading [9535/9537]
VideoDataset temporal_transform <temporal_transforms.Compose object at 0x7f9bcc29a730>
dataset loading [0/3783]
dataset loading [756/3783]
dataset loading [1512/3783]
dataset loading [2268/3783]
dataset loading [3024/3783]
dataset loading [3780/3783]
VideoDataset temporal_transform <temporal_transforms.Compose object at 0x7f9bd5670490>
train at epoch 1
Epoch: [1][1/597]	Time 20.629 (20.629)	Data 14.371 (14.371)	Loss 4.7446 (4.7446)	Acc 0.000 (0.000)
Epoch: [1][2/597]	Time 0.092 (10.360)	Data 0.000 (7.185)	Loss 4.9929 (4.8688)	Acc 0.062 (0.031)
Epoch: [1][3/597]	Time 5.754 (8.825)	Data 5.673 (6.681)	Loss 5.4265 (5.0547)	Acc 0.062 (0.042)
Epoch: [1][4/597]	Time 0.704 (6.795)	Data 0.632 (5.169)	Loss 5.7673 (5.2328)	Acc 0.000 (0.031)
Epoch: [1][5/597]	Time 12.083 (7.852)	Data 12.001 (6.535)	Loss 6.8458 (5.5554)	Acc 0.000 (0.025)
Epoch: [1][6/597]	Time 1.089 (6.725)	Data 1.001 (5.613)	Loss 5.7200 (5.5829)	Acc 0.000 (0.021)
Epoch: [1][7/597]	Time 11.362 (7.387)	Data 11.280 (6.423)	Loss 7.7775 (5.8964)	Acc 0.000 (0.018)
Epoch: [1][8/597]	Time 2.714 (6.803)	Data 2.632 (5.949)	Loss 6.2630 (5.9422)	Acc 0.000 (0.016)
Epoch: [1][9/597]	Time 11.260 (7.298)	Data 11.176 (6.530)	Loss 5.9832 (5.9468)	Acc 0.188 (0.035)
Epoch: [1][10/597]	Time 3.161 (6.885)	Data 3.079 (6.185)	Loss 7.2193 (6.0740)	Acc 0.000 (0.031)
Epoch: [1][11/597]	Time 10.446 (7.208)	Data 10.363 (6.564)	Loss 6.4072 (6.1043)	Acc 0.062 (0.034)
Epoch: [1][12/597]	Time 3.558 (6.904)	Data 3.477 (6.307)	Loss 7.6972 (6.2371)	Acc 0.000 (0.031)
Epoch: [1][13/597]	Time 11.224 (7.237)	Data 11.144 (6.679)	Loss 9.0358 (6.4523)	Acc 0.000 (0.029)
Epoch: [1][14/597]	Time 2.209 (6.877)	Data 2.128 (6.354)	Loss 12.2668 (6.8677)	Acc 0.000 (0.027)
Epoch: [1][15/597]	Time 11.508 (7.186)	Data 11.424 (6.692)	Loss 6.6508 (6.8532)	Acc 0.000 (0.025)
Epoch: [1][16/597]	Time 2.998 (6.924)	Data 2.920 (6.456)	Loss 11.6880 (7.1554)	Acc 0.062 (0.027)
Epoch: [1][17/597]	Time 10.983 (7.163)	Data 10.903 (6.718)	Loss 10.0599 (7.3262)	Acc 0.000 (0.026)
Epoch: [1][18/597]	Time 3.240 (6.945)	Data 3.160 (6.520)	Loss 8.8661 (7.4118)	Acc 0.062 (0.028)
Epoch: [1][19/597]	Time 11.008 (7.159)	Data 10.929 (6.752)	Loss 9.7224 (7.5334)	Acc 0.000 (0.026)
Epoch: [1][20/597]	Time 2.695 (6.936)	Data 2.614 (6.545)	Loss 8.6185 (7.5876)	Acc 0.000 (0.025)
Epoch: [1][21/597]	Time 11.112 (7.135)	Data 10.950 (6.755)	Loss 7.4389 (7.5806)	Acc 0.062 (0.027)
Epoch: [1][22/597]	Time 2.320 (6.916)	Data 2.232 (6.550)	Loss 10.1222 (7.6961)	Acc 0.000 (0.026)
Epoch: [1][23/597]	Time 11.201 (7.102)	Data 11.123 (6.748)	Loss 7.3323 (7.6803)	Acc 0.000 (0.024)
Epoch: [1][24/597]	Time 2.589 (6.914)	Data 2.511 (6.572)	Loss 6.8084 (7.6440)	Acc 0.000 (0.023)
Epoch: [1][25/597]	Time 11.431 (7.095)	Data 11.353 (6.763)	Loss 7.7255 (7.6472)	Acc 0.000 (0.022)
Epoch: [1][26/597]	Time 1.481 (6.879)	Data 1.396 (6.557)	Loss 9.9188 (7.7346)	Acc 0.000 (0.022)
Epoch: [1][27/597]	Time 12.876 (7.101)	Data 12.799 (6.788)	Loss 8.5272 (7.7639)	Acc 0.000 (0.021)
Epoch: [1][28/597]	Time 1.879 (6.915)	Data 1.780 (6.609)	Loss 7.0800 (7.7395)	Acc 0.000 (0.020)
Epoch: [1][29/597]	Time 12.634 (7.112)	Data 12.538 (6.813)	Loss 8.7906 (7.7758)	Acc 0.000 (0.019)
Epoch: [1][30/597]	Time 1.902 (6.938)	Data 1.822 (6.647)	Loss 6.7168 (7.7405)	Acc 0.000 (0.019)
Epoch: [1][31/597]	Time 12.741 (7.125)	Data 12.660 (6.841)	Loss 6.6561 (7.7055)	Acc 0.000 (0.018)
Epoch: [1][32/597]	Time 1.840 (6.960)	Data 1.759 (6.682)	Loss 6.8839 (7.6798)	Acc 0.062 (0.020)
Epoch: [1][33/597]	Time 13.226 (7.150)	Data 13.143 (6.878)	Loss 7.2694 (7.6674)	Acc 0.000 (0.019)
Epoch: [1][34/597]	Time 1.478 (6.983)	Data 1.399 (6.717)	Loss 9.7965 (7.7300)	Acc 0.000 (0.018)
Epoch: [1][35/597]	Time 12.516 (7.141)	Data 12.433 (6.880)	Loss 9.3797 (7.7771)	Acc 0.062 (0.020)
Epoch: [1][36/597]	Time 1.240 (6.977)	Data 1.159 (6.721)	Loss 7.9359 (7.7815)	Acc 0.000 (0.019)
Epoch: [1][37/597]	Time 13.870 (7.164)	Data 13.784 (6.912)	Loss 7.3096 (7.7688)	Acc 0.000 (0.019)
Epoch: [1][38/597]	Time 1.348 (7.011)	Data 1.266 (6.764)	Loss 6.9195 (7.7464)	Acc 0.000 (0.018)
Epoch: [1][39/597]	Time 13.086 (7.166)	Data 13.008 (6.924)	Loss 6.1137 (7.7046)	Acc 0.000 (0.018)
Epoch: [1][40/597]	Time 1.702 (7.030)	Data 1.616 (6.791)	Loss 6.2593 (7.6684)	Acc 0.000 (0.017)
Epoch: [1][41/597]	Time 13.743 (7.193)	Data 13.677 (6.959)	Loss 12.9043 (7.7961)	Acc 0.000 (0.017)
Epoch: [1][42/597]	Time 1.091 (7.048)	Data 1.025 (6.818)	Loss 9.1926 (7.8294)	Acc 0.000 (0.016)
Epoch: [1][43/597]	Time 13.583 (7.200)	Data 13.518 (6.973)	Loss 7.1525 (7.8136)	Acc 0.000 (0.016)
Epoch: [1][44/597]	Time 0.706 (7.053)	Data 0.643 (6.830)	Loss 7.8993 (7.8156)	Acc 0.000 (0.016)
Epoch: [1][45/597]	Time 12.964 (7.184)	Data 12.892 (6.964)	Loss 8.6248 (7.8336)	Acc 0.000 (0.015)
Epoch: [1][46/597]	Time 0.816 (7.045)	Data 0.738 (6.829)	Loss 6.2577 (7.7993)	Acc 0.000 (0.015)
Epoch: [1][47/597]	Time 13.219 (7.177)	Data 13.154 (6.964)	Loss 8.5618 (7.8155)	Acc 0.000 (0.015)
Epoch: [1][48/597]	Time 0.361 (7.035)	Data 0.299 (6.825)	Loss 5.7594 (7.7727)	Acc 0.000 (0.014)
Epoch: [1][49/597]	Time 13.165 (7.160)	Data 13.102 (6.953)	Loss 5.1764 (7.7197)	Acc 0.062 (0.015)
Epoch: [1][50/597]	Time 1.461 (7.046)	Data 1.403 (6.842)	Loss 5.6552 (7.6784)	Acc 0.000 (0.015)
Epoch: [1][51/597]	Time 12.474 (7.152)	Data 12.412 (6.951)	Loss 4.5696 (7.6175)	Acc 0.000 (0.015)
Epoch: [1][52/597]	Time 1.842 (7.050)	Data 1.775 (6.851)	Loss 7.3535 (7.6124)	Acc 0.062 (0.016)
Epoch: [1][53/597]	Time 12.555 (7.154)	Data 12.491 (6.958)	Loss 5.8783 (7.5797)	Acc 0.000 (0.015)
Epoch: [1][54/597]	Time 1.665 (7.053)	Data 1.607 (6.859)	Loss 6.8046 (7.5653)	Acc 0.000 (0.015)
Epoch: [1][55/597]	Time 12.451 (7.151)	Data 12.386 (6.959)	Loss 5.9309 (7.5356)	Acc 0.000 (0.015)
Epoch: [1][56/597]	Time 1.540 (7.050)	Data 1.483 (6.861)	Loss 6.6750 (7.5202)	Acc 0.000 (0.015)
Epoch: [1][57/597]	Time 12.674 (7.149)	Data 12.610 (6.962)	Loss 7.6193 (7.5220)	Acc 0.000 (0.014)
Epoch: [1][58/597]	Time 0.809 (7.040)	Data 0.752 (6.855)	Loss 6.3592 (7.5019)	Acc 0.062 (0.015)
Epoch: [1][59/597]	Time 12.680 (7.135)	Data 12.615 (6.953)	Loss 5.6282 (7.4702)	Acc 0.000 (0.015)
Epoch: [1][60/597]	Time 1.023 (7.034)	Data 0.964 (6.853)	Loss 6.0803 (7.4470)	Acc 0.062 (0.016)
Epoch: [1][61/597]	Time 12.346 (7.121)	Data 12.233 (6.941)	Loss 4.8444 (7.4043)	Acc 0.062 (0.016)
Epoch: [1][62/597]	Time 0.964 (7.021)	Data 0.900 (6.844)	Loss 5.8920 (7.3799)	Acc 0.000 (0.016)
Epoch: [1][63/597]	Time 12.848 (7.114)	Data 12.779 (6.938)	Loss 5.7162 (7.3535)	Acc 0.000 (0.016)
Epoch: [1][64/597]	Time 0.792 (7.015)	Data 0.726 (6.841)	Loss 6.8931 (7.3463)	Acc 0.000 (0.016)
Epoch: [1][65/597]	Time 12.561 (7.100)	Data 12.495 (6.928)	Loss 7.2428 (7.3447)	Acc 0.000 (0.015)
Epoch: [1][66/597]	Time 1.183 (7.011)	Data 1.125 (6.840)	Loss 4.9967 (7.3092)	Acc 0.000 (0.015)
Epoch: [1][67/597]	Time 11.999 (7.085)	Data 11.937 (6.916)	Loss 5.7906 (7.2865)	Acc 0.000 (0.015)
Epoch: [1][68/597]	Time 1.085 (6.997)	Data 1.021 (6.829)	Loss 4.8872 (7.2512)	Acc 0.000 (0.015)
Epoch: [1][69/597]	Time 13.080 (7.085)	Data 13.007 (6.919)	Loss 5.0791 (7.2197)	Acc 0.000 (0.014)
Epoch: [1][70/597]	Time 0.863 (6.996)	Data 0.807 (6.832)	Loss 6.3086 (7.2067)	Acc 0.000 (0.014)
Epoch: [1][71/597]	Time 12.765 (7.077)	Data 12.701 (6.914)	Loss 6.8354 (7.2015)	Acc 0.062 (0.015)
Epoch: [1][72/597]	Time 1.349 (6.998)	Data 1.290 (6.836)	Loss 5.2114 (7.1739)	Acc 0.000 (0.015)
Epoch: [1][73/597]	Time 12.867 (7.078)	Data 12.787 (6.918)	Loss 5.5283 (7.1513)	Acc 0.000 (0.015)
Epoch: [1][74/597]	Time 1.883 (7.008)	Data 1.818 (6.849)	Loss 5.9769 (7.1354)	Acc 0.062 (0.015)
Epoch: [1][75/597]	Time 12.987 (7.088)	Data 12.923 (6.930)	Loss 5.0957 (7.1082)	Acc 0.062 (0.016)
Epoch: [1][76/597]	Time 2.140 (7.023)	Data 2.074 (6.866)	Loss 5.2419 (7.0837)	Acc 0.000 (0.016)
Epoch: [1][77/597]	Time 11.479 (7.081)	Data 11.413 (6.925)	Loss 5.9849 (7.0694)	Acc 0.000 (0.015)
Epoch: [1][78/597]	Time 2.005 (7.016)	Data 1.941 (6.861)	Loss 5.3524 (7.0474)	Acc 0.000 (0.015)
Epoch: [1][79/597]	Time 11.382 (7.071)	Data 11.318 (6.917)	Loss 5.4153 (7.0268)	Acc 0.000 (0.015)
Epoch: [1][80/597]	Time 2.811 (7.018)	Data 2.749 (6.865)	Loss 5.2452 (7.0045)	Acc 0.000 (0.015)
Epoch: [1][81/597]	Time 11.491 (7.073)	Data 11.426 (6.922)	Loss 5.0608 (6.9805)	Acc 0.000 (0.015)
Epoch: [1][82/597]	Time 2.154 (7.013)	Data 2.087 (6.863)	Loss 5.1292 (6.9579)	Acc 0.000 (0.014)
Epoch: [1][83/597]	Time 11.322 (7.065)	Data 11.257 (6.916)	Loss 6.0271 (6.9467)	Acc 0.000 (0.014)
Epoch: [1][84/597]	Time 2.261 (7.007)	Data 2.194 (6.859)	Loss 5.0556 (6.9242)	Acc 0.062 (0.015)
Epoch: [1][85/597]	Time 11.692 (7.063)	Data 11.611 (6.915)	Loss 4.5673 (6.8965)	Acc 0.062 (0.015)
Epoch: [1][86/597]	Time 2.017 (7.004)	Data 1.952 (6.858)	Loss 5.2352 (6.8771)	Acc 0.000 (0.015)
Epoch: [1][87/597]	Time 12.089 (7.062)	Data 12.006 (6.917)	Loss 4.7446 (6.8526)	Acc 0.000 (0.015)
Epoch: [1][88/597]	Time 1.646 (7.001)	Data 1.587 (6.856)	Loss 5.3699 (6.8358)	Acc 0.000 (0.015)
Epoch: [1][89/597]	Time 12.706 (7.065)	Data 12.641 (6.921)	Loss 5.2862 (6.8184)	Acc 0.000 (0.015)
Epoch: [1][90/597]	Time 1.195 (7.000)	Data 1.127 (6.857)	Loss 6.1039 (6.8104)	Acc 0.000 (0.015)
Epoch: [1][91/597]	Time 13.341 (7.069)	Data 13.275 (6.927)	Loss 6.1817 (6.8035)	Acc 0.000 (0.014)
Epoch: [1][92/597]	Time 1.262 (7.006)	Data 1.204 (6.865)	Loss 5.3342 (6.7875)	Acc 0.000 (0.014)
Epoch: [1][93/597]	Time 13.024 (7.071)	Data 12.949 (6.931)	Loss 5.1897 (6.7704)	Acc 0.000 (0.014)
Epoch: [1][94/597]	Time 0.874 (7.005)	Data 0.796 (6.865)	Loss 4.7311 (6.7487)	Acc 0.000 (0.014)
Epoch: [1][95/597]	Time 13.524 (7.074)	Data 13.449 (6.935)	Loss 4.7439 (6.7276)	Acc 0.000 (0.014)
Epoch: [1][96/597]	Time 1.011 (7.011)	Data 0.946 (6.872)	Loss 5.5434 (6.7152)	Acc 0.000 (0.014)
Epoch: [1][97/597]	Time 13.227 (7.075)	Data 13.164 (6.937)	Loss 4.7583 (6.6951)	Acc 0.000 (0.014)
Epoch: [1][98/597]	Time 1.397 (7.017)	Data 1.334 (6.880)	Loss 5.1488 (6.6793)	Acc 0.000 (0.013)
Epoch: [1][99/597]	Time 12.082 (7.068)	Data 12.016 (6.932)	Loss 4.7495 (6.6598)	Acc 0.000 (0.013)
Epoch: [1][100/597]	Time 1.455 (7.012)	Data 1.323 (6.876)	Loss 4.8327 (6.6415)	Acc 0.062 (0.014)
Epoch: [1][101/597]	Time 11.605 (7.057)	Data 11.541 (6.922)	Loss 5.0301 (6.6256)	Acc 0.000 (0.014)
Epoch: [1][102/597]	Time 1.970 (7.007)	Data 1.907 (6.873)	Loss 4.8008 (6.6077)	Acc 0.000 (0.013)
Epoch: [1][103/597]	Time 11.529 (7.051)	Data 11.463 (6.917)	Loss 5.2286 (6.5943)	Acc 0.000 (0.013)
Epoch: [1][104/597]	Time 1.971 (7.002)	Data 1.902 (6.869)	Loss 5.0382 (6.5793)	Acc 0.062 (0.014)
Epoch: [1][105/597]	Time 11.785 (7.048)	Data 11.723 (6.915)	Loss 4.9358 (6.5637)	Acc 0.062 (0.014)
Epoch: [1][106/597]	Time 1.732 (6.998)	Data 1.668 (6.866)	Loss 5.6673 (6.5552)	Acc 0.000 (0.014)
Epoch: [1][107/597]	Time 12.190 (7.046)	Data 12.124 (6.915)	Loss 4.4804 (6.5358)	Acc 0.000 (0.014)
Epoch: [1][108/597]	Time 2.058 (7.000)	Data 1.990 (6.869)	Loss 4.7407 (6.5192)	Acc 0.000 (0.014)
Epoch: [1][109/597]	Time 11.064 (7.037)	Data 11.000 (6.907)	Loss 4.9176 (6.5045)	Acc 0.000 (0.014)
Epoch: [1][110/597]	Time 2.768 (6.999)	Data 2.706 (6.869)	Loss 4.8434 (6.4894)	Acc 0.062 (0.014)
Epoch: [1][111/597]	Time 11.243 (7.037)	Data 11.176 (6.908)	Loss 5.0569 (6.4765)	Acc 0.000 (0.014)
Epoch: [1][112/597]	Time 3.527 (7.005)	Data 3.463 (6.877)	Loss 4.9596 (6.4630)	Acc 0.000 (0.014)
Epoch: [1][113/597]	Time 10.861 (7.040)	Data 10.799 (6.912)	Loss 4.8658 (6.4488)	Acc 0.000 (0.014)
Epoch: [1][114/597]	Time 3.014 (7.004)	Data 2.949 (6.877)	Loss 5.1486 (6.4374)	Acc 0.000 (0.014)
Epoch: [1][115/597]	Time 11.018 (7.039)	Data 10.953 (6.912)	Loss 4.7725 (6.4229)	Acc 0.000 (0.014)
Epoch: [1][116/597]	Time 2.708 (7.002)	Data 2.644 (6.876)	Loss 5.1822 (6.4122)	Acc 0.000 (0.013)
Epoch: [1][117/597]	Time 10.894 (7.035)	Data 10.822 (6.909)	Loss 4.8527 (6.3989)	Acc 0.000 (0.013)
Epoch: [1][118/597]	Time 2.956 (7.001)	Data 2.890 (6.875)	Loss 4.6575 (6.3842)	Acc 0.062 (0.014)
Epoch: [1][119/597]	Time 10.608 (7.031)	Data 10.540 (6.906)	Loss 4.7640 (6.3705)	Acc 0.000 (0.014)
Epoch: [1][120/597]	Time 3.431 (7.001)	Data 3.365 (6.877)	Loss 5.1907 (6.3607)	Acc 0.000 (0.014)
Epoch: [1][121/597]	Time 10.606 (7.031)	Data 10.543 (6.907)	Loss 4.9688 (6.3492)	Acc 0.000 (0.013)
Epoch: [1][122/597]	Time 2.881 (6.997)	Data 2.813 (6.873)	Loss 4.4575 (6.3337)	Acc 0.000 (0.013)
Epoch: [1][123/597]	Time 11.981 (7.037)	Data 11.914 (6.914)	Loss 4.7541 (6.3209)	Acc 0.000 (0.013)
Epoch: [1][124/597]	Time 2.290 (6.999)	Data 2.226 (6.877)	Loss 4.6116 (6.3071)	Acc 0.062 (0.014)
Epoch: [1][125/597]	Time 11.067 (7.031)	Data 11.005 (6.910)	Loss 4.8610 (6.2955)	Acc 0.000 (0.013)
Epoch: [1][126/597]	Time 2.226 (6.993)	Data 2.160 (6.872)	Loss 4.9629 (6.2849)	Acc 0.000 (0.013)
Epoch: [1][127/597]	Time 11.527 (7.029)	Data 11.464 (6.908)	Loss 4.8132 (6.2733)	Acc 0.000 (0.013)
Epoch: [1][128/597]	Time 1.835 (6.988)	Data 1.750 (6.868)	Loss 5.2197 (6.2651)	Acc 0.000 (0.013)
Epoch: [1][129/597]	Time 11.731 (7.025)	Data 11.668 (6.905)	Loss 4.3744 (6.2505)	Acc 0.125 (0.014)
Epoch: [1][130/597]	Time 1.939 (6.986)	Data 1.861 (6.866)	Loss 5.0309 (6.2411)	Acc 0.000 (0.014)
Epoch: [1][131/597]	Time 11.590 (7.021)	Data 11.528 (6.902)	Loss 4.9168 (6.2310)	Acc 0.000 (0.014)
Epoch: [1][132/597]	Time 2.521 (6.987)	Data 2.458 (6.868)	Loss 4.8367 (6.2204)	Acc 0.062 (0.014)
Epoch: [1][133/597]	Time 11.315 (7.020)	Data 11.251 (6.901)	Loss 5.0725 (6.2118)	Acc 0.000 (0.014)
Epoch: [1][134/597]	Time 2.400 (6.985)	Data 2.336 (6.867)	Loss 5.1016 (6.2035)	Acc 0.000 (0.014)
Epoch: [1][135/597]	Time 11.882 (7.021)	Data 11.817 (6.904)	Loss 5.0793 (6.1952)	Acc 0.000 (0.014)
Epoch: [1][136/597]	Time 1.889 (6.984)	Data 1.826 (6.866)	Loss 5.2106 (6.1879)	Acc 0.000 (0.014)
Epoch: [1][137/597]	Time 12.624 (7.025)	Data 12.559 (6.908)	Loss 5.0844 (6.1799)	Acc 0.000 (0.014)
Epoch: [1][138/597]	Time 2.116 (6.989)	Data 2.051 (6.873)	Loss 4.9550 (6.1710)	Acc 0.000 (0.014)
Epoch: [1][139/597]	Time 11.687 (7.023)	Data 11.549 (6.906)	Loss 5.1064 (6.1633)	Acc 0.000 (0.013)
Epoch: [1][140/597]	Time 2.512 (6.991)	Data 2.447 (6.874)	Loss 4.8852 (6.1542)	Acc 0.000 (0.013)
Epoch: [1][141/597]	Time 11.638 (7.024)	Data 11.573 (6.908)	Loss 4.6509 (6.1435)	Acc 0.000 (0.013)
Epoch: [1][142/597]	Time 2.376 (6.991)	Data 2.313 (6.875)	Loss 4.9453 (6.1351)	Acc 0.000 (0.013)
Epoch: [1][143/597]	Time 11.607 (7.023)	Data 11.542 (6.908)	Loss 4.7565 (6.1255)	Acc 0.000 (0.013)
Epoch: [1][144/597]	Time 2.106 (6.989)	Data 2.024 (6.874)	Loss 4.8139 (6.1163)	Acc 0.000 (0.013)
Epoch: [1][145/597]	Time 11.266 (7.019)	Data 11.203 (6.904)	Loss 5.2287 (6.1102)	Acc 0.000 (0.013)
Epoch: [1][146/597]	Time 2.039 (6.985)	Data 1.976 (6.870)	Loss 4.6965 (6.1005)	Acc 0.000 (0.013)
Epoch: [1][147/597]	Time 11.428 (7.015)	Data 11.363 (6.901)	Loss 4.7671 (6.0915)	Acc 0.000 (0.013)
Epoch: [1][148/597]	Time 1.221 (6.976)	Data 1.157 (6.862)	Loss 5.0007 (6.0841)	Acc 0.000 (0.013)
Epoch: [1][149/597]	Time 12.902 (7.015)	Data 12.839 (6.902)	Loss 4.7559 (6.0752)	Acc 0.000 (0.013)
Epoch: [1][150/597]	Time 1.209 (6.977)	Data 1.142 (6.864)	Loss 5.0772 (6.0685)	Acc 0.000 (0.013)
Epoch: [1][151/597]	Time 12.280 (7.012)	Data 12.217 (6.899)	Loss 4.7616 (6.0599)	Acc 0.000 (0.012)
Epoch: [1][152/597]	Time 1.897 (6.978)	Data 1.832 (6.866)	Loss 4.9472 (6.0526)	Acc 0.000 (0.012)
Epoch: [1][153/597]	Time 12.794 (7.016)	Data 12.732 (6.904)	Loss 4.7827 (6.0443)	Acc 0.000 (0.012)
Epoch: [1][154/597]	Time 2.693 (6.988)	Data 2.630 (6.876)	Loss 4.7852 (6.0361)	Acc 0.125 (0.013)
Epoch: [1][155/597]	Time 12.241 (7.022)	Data 12.175 (6.911)	Loss 4.8420 (6.0284)	Acc 0.000 (0.013)
Epoch: [1][156/597]	Time 2.083 (6.990)	Data 2.018 (6.879)	Loss 4.9855 (6.0217)	Acc 0.000 (0.013)
Epoch: [1][157/597]	Time 12.234 (7.024)	Data 12.169 (6.913)	Loss 5.0198 (6.0153)	Acc 0.000 (0.013)
Epoch: [1][158/597]	Time 2.141 (6.993)	Data 2.077 (6.882)	Loss 4.6726 (6.0068)	Acc 0.062 (0.013)
Epoch: [1][159/597]	Time 11.511 (7.021)	Data 11.448 (6.911)	Loss 4.8695 (5.9997)	Acc 0.000 (0.013)
Epoch: [1][160/597]	Time 2.208 (6.991)	Data 2.143 (6.881)	Loss 5.3361 (5.9955)	Acc 0.000 (0.013)
Epoch: [1][161/597]	Time 11.963 (7.022)	Data 11.900 (6.912)	Loss 4.8128 (5.9882)	Acc 0.000 (0.013)
Epoch: [1][162/597]	Time 2.254 (6.993)	Data 2.190 (6.883)	Loss 4.5420 (5.9792)	Acc 0.000 (0.013)
Epoch: [1][163/597]	Time 11.541 (7.021)	Data 11.476 (6.911)	Loss 4.5508 (5.9705)	Acc 0.125 (0.013)
Epoch: [1][164/597]	Time 2.322 (6.992)	Data 2.258 (6.883)	Loss 4.7847 (5.9632)	Acc 0.062 (0.014)
Epoch: [1][165/597]	Time 13.016 (7.028)	Data 12.952 (6.920)	Loss 5.1790 (5.9585)	Acc 0.000 (0.014)
Epoch: [1][166/597]	Time 1.932 (6.998)	Data 1.868 (6.889)	Loss 4.8039 (5.9515)	Acc 0.000 (0.014)
Epoch: [1][167/597]	Time 13.320 (7.036)	Data 13.255 (6.928)	Loss 4.5423 (5.9431)	Acc 0.000 (0.013)
Epoch: [1][168/597]	Time 0.896 (6.999)	Data 0.836 (6.891)	Loss 4.7665 (5.9361)	Acc 0.125 (0.014)
Epoch: [1][169/597]	Time 14.022 (7.041)	Data 13.958 (6.933)	Loss 4.7531 (5.9291)	Acc 0.000 (0.014)
Epoch: [1][170/597]	Time 0.512 (7.002)	Data 0.449 (6.895)	Loss 5.1566 (5.9246)	Acc 0.000 (0.014)
Epoch: [1][171/597]	Time 15.360 (7.051)	Data 15.284 (6.944)	Loss 5.1817 (5.9202)	Acc 0.000 (0.014)
Epoch: [1][172/597]	Time 0.121 (7.011)	Data 0.000 (6.904)	Loss 4.7207 (5.9132)	Acc 0.000 (0.014)
Epoch: [1][173/597]	Time 14.748 (7.055)	Data 14.683 (6.949)	Loss 5.0607 (5.9083)	Acc 0.000 (0.014)
Epoch: [1][174/597]	Time 0.425 (7.017)	Data 0.361 (6.911)	Loss 4.5638 (5.9006)	Acc 0.000 (0.014)
Epoch: [1][175/597]	Time 14.668 (7.061)	Data 14.604 (6.955)	Loss 4.9868 (5.8954)	Acc 0.000 (0.014)
Epoch: [1][176/597]	Time 0.154 (7.022)	Data 0.090 (6.916)	Loss 4.6316 (5.8882)	Acc 0.000 (0.013)
Epoch: [1][177/597]	Time 14.339 (7.063)	Data 14.276 (6.957)	Loss 5.1184 (5.8838)	Acc 0.000 (0.013)
Epoch: [1][178/597]	Time 0.123 (7.024)	Data 0.000 (6.918)	Loss 4.9813 (5.8788)	Acc 0.000 (0.013)
Epoch: [1][179/597]	Time 14.179 (7.064)	Data 14.115 (6.958)	Loss 4.6030 (5.8716)	Acc 0.000 (0.013)
Epoch: [1][180/597]	Time 0.119 (7.026)	Data 0.000 (6.920)	Loss 4.5930 (5.8645)	Acc 0.000 (0.013)
Epoch: [1][181/597]	Time 13.092 (7.059)	Data 13.029 (6.953)	Loss 5.3337 (5.8616)	Acc 0.000 (0.013)
Epoch: [1][182/597]	Time 0.121 (7.021)	Data 0.000 (6.915)	Loss 4.9351 (5.8565)	Acc 0.000 (0.013)
Epoch: [1][183/597]	Time 13.444 (7.056)	Data 13.377 (6.951)	Loss 4.9124 (5.8513)	Acc 0.000 (0.013)
Epoch: [1][184/597]	Time 0.119 (7.018)	Data 0.000 (6.913)	Loss 5.0448 (5.8470)	Acc 0.000 (0.013)
Epoch: [1][185/597]	Time 13.598 (7.054)	Data 13.536 (6.949)	Loss 4.7088 (5.8408)	Acc 0.000 (0.013)
Epoch: [1][186/597]	Time 0.123 (7.017)	Data 0.000 (6.911)	Loss 5.1932 (5.8373)	Acc 0.000 (0.013)
Epoch: [1][187/597]	Time 13.542 (7.052)	Data 13.478 (6.946)	Loss 4.6573 (5.8310)	Acc 0.062 (0.013)
Epoch: [1][188/597]	Time 0.120 (7.015)	Data 0.000 (6.909)	Loss 4.8121 (5.8256)	Acc 0.000 (0.013)
Epoch: [1][189/597]	Time 13.496 (7.049)	Data 13.429 (6.944)	Loss 4.8175 (5.8203)	Acc 0.000 (0.013)
Epoch: [1][190/597]	Time 0.269 (7.013)	Data 0.206 (6.908)	Loss 4.7586 (5.8147)	Acc 0.000 (0.013)
Epoch: [1][191/597]	Time 13.670 (7.048)	Data 13.606 (6.944)	Loss 4.6620 (5.8086)	Acc 0.000 (0.013)
Epoch: [1][192/597]	Time 0.288 (7.013)	Data 0.220 (6.908)	Loss 4.9110 (5.8040)	Acc 0.000 (0.013)
Epoch: [1][193/597]	Time 12.738 (7.043)	Data 12.674 (6.938)	Loss 4.8431 (5.7990)	Acc 0.000 (0.013)
Epoch: [1][194/597]	Time 2.061 (7.017)	Data 1.997 (6.913)	Loss 4.7975 (5.7938)	Acc 0.000 (0.013)
Epoch: [1][195/597]	Time 11.809 (7.042)	Data 11.745 (6.938)	Loss 4.7673 (5.7886)	Acc 0.000 (0.013)
Epoch: [1][196/597]	Time 2.301 (7.017)	Data 2.230 (6.914)	Loss 4.9300 (5.7842)	Acc 0.000 (0.012)
Epoch: [1][197/597]	Time 11.494 (7.040)	Data 11.430 (6.937)	Loss 4.9089 (5.7797)	Acc 0.000 (0.012)
Epoch: [1][198/597]	Time 2.084 (7.015)	Data 2.019 (6.912)	Loss 4.6733 (5.7742)	Acc 0.000 (0.012)
Epoch: [1][199/597]	Time 10.651 (7.033)	Data 10.573 (6.930)	Loss 4.3627 (5.7671)	Acc 0.062 (0.013)
Epoch: [1][200/597]	Time 2.478 (7.011)	Data 2.414 (6.908)	Loss 4.9683 (5.7631)	Acc 0.000 (0.013)
Epoch: [1][201/597]	Time 11.936 (7.035)	Data 11.869 (6.932)	Loss 4.9196 (5.7589)	Acc 0.000 (0.012)
Epoch: [1][202/597]	Time 1.021 (7.005)	Data 0.958 (6.903)	Loss 4.8798 (5.7545)	Acc 0.000 (0.012)
Epoch: [1][203/597]	Time 11.961 (7.030)	Data 11.895 (6.927)	Loss 4.8781 (5.7502)	Acc 0.062 (0.013)
Epoch: [1][204/597]	Time 2.516 (7.008)	Data 2.443 (6.905)	Loss 4.9756 (5.7464)	Acc 0.000 (0.013)
Epoch: [1][205/597]	Time 10.618 (7.025)	Data 10.556 (6.923)	Loss 5.0042 (5.7428)	Acc 0.000 (0.013)
Epoch: [1][206/597]	Time 3.577 (7.008)	Data 3.515 (6.907)	Loss 5.1270 (5.7398)	Acc 0.000 (0.012)
Epoch: [1][207/597]	Time 10.646 (7.026)	Data 10.584 (6.924)	Loss 4.5905 (5.7342)	Acc 0.000 (0.012)
Epoch: [1][208/597]	Time 2.843 (7.006)	Data 2.780 (6.904)	Loss 4.7479 (5.7295)	Acc 0.000 (0.012)
Epoch: [1][209/597]	Time 11.038 (7.025)	Data 10.974 (6.924)	Loss 4.8446 (5.7253)	Acc 0.000 (0.012)
Epoch: [1][210/597]	Time 2.635 (7.004)	Data 2.571 (6.903)	Loss 4.4800 (5.7193)	Acc 0.000 (0.012)
Epoch: [1][211/597]	Time 11.035 (7.023)	Data 10.953 (6.922)	Loss 4.5303 (5.7137)	Acc 0.000 (0.012)
Epoch: [1][212/597]	Time 2.761 (7.003)	Data 2.695 (6.902)	Loss 4.5965 (5.7084)	Acc 0.000 (0.012)
Epoch: [1][213/597]	Time 11.060 (7.022)	Data 10.997 (6.922)	Loss 4.9102 (5.7047)	Acc 0.000 (0.012)
Epoch: [1][214/597]	Time 2.947 (7.003)	Data 2.886 (6.903)	Loss 4.8266 (5.7006)	Acc 0.000 (0.012)
Epoch: [1][215/597]	Time 10.973 (7.022)	Data 10.911 (6.921)	Loss 5.0845 (5.6977)	Acc 0.000 (0.012)
Epoch: [1][216/597]	Time 2.121 (6.999)	Data 2.057 (6.899)	Loss 5.1512 (5.6952)	Acc 0.000 (0.012)
Epoch: [1][217/597]	Time 11.615 (7.020)	Data 11.484 (6.920)	Loss 4.8442 (5.6913)	Acc 0.000 (0.012)
Epoch: [1][218/597]	Time 1.401 (6.995)	Data 1.343 (6.894)	Loss 4.6737 (5.6866)	Acc 0.000 (0.012)
Epoch: [1][219/597]	Time 11.937 (7.017)	Data 11.875 (6.917)	Loss 5.1387 (5.6841)	Acc 0.000 (0.012)
Epoch: [1][220/597]	Time 1.875 (6.994)	Data 1.810 (6.894)	Loss 4.9761 (5.6809)	Acc 0.000 (0.012)
Epoch: [1][221/597]	Time 12.140 (7.017)	Data 12.078 (6.917)	Loss 4.8584 (5.6772)	Acc 0.000 (0.012)
Epoch: [1][222/597]	Time 1.620 (6.993)	Data 1.562 (6.893)	Loss 5.0421 (5.6743)	Acc 0.000 (0.012)
Epoch: [1][223/597]	Time 11.854 (7.015)	Data 11.787 (6.915)	Loss 4.6482 (5.6697)	Acc 0.000 (0.011)
Epoch: [1][224/597]	Time 1.623 (6.990)	Data 1.564 (6.891)	Loss 4.5690 (5.6648)	Acc 0.062 (0.012)
Epoch: [1][225/597]	Time 12.697 (7.016)	Data 12.632 (6.917)	Loss 4.8841 (5.6613)	Acc 0.000 (0.012)
Epoch: [1][226/597]	Time 2.106 (6.994)	Data 2.042 (6.895)	Loss 4.9451 (5.6581)	Acc 0.000 (0.012)
Epoch: [1][227/597]	Time 11.895 (7.016)	Data 11.828 (6.917)	Loss 4.9720 (5.6551)	Acc 0.000 (0.012)
Epoch: [1][228/597]	Time 1.247 (6.990)	Data 1.188 (6.892)	Loss 4.8326 (5.6515)	Acc 0.000 (0.012)
Epoch: [1][229/597]	Time 12.369 (7.014)	Data 12.305 (6.916)	Loss 4.4534 (5.6463)	Acc 0.062 (0.012)
Epoch: [1][230/597]	Time 2.074 (6.992)	Data 2.011 (6.894)	Loss 4.5625 (5.6416)	Acc 0.000 (0.012)
Epoch: [1][231/597]	Time 11.534 (7.012)	Data 11.471 (6.914)	Loss 4.9471 (5.6386)	Acc 0.000 (0.012)
Epoch: [1][232/597]	Time 2.197 (6.991)	Data 2.133 (6.893)	Loss 4.9879 (5.6358)	Acc 0.000 (0.012)
Epoch: [1][233/597]	Time 11.179 (7.009)	Data 11.112 (6.912)	Loss 4.6638 (5.6316)	Acc 0.062 (0.012)
Epoch: [1][234/597]	Time 2.111 (6.988)	Data 2.048 (6.891)	Loss 4.5993 (5.6272)	Acc 0.062 (0.012)
Epoch: [1][235/597]	Time 11.685 (7.008)	Data 11.622 (6.911)	Loss 4.5611 (5.6226)	Acc 0.000 (0.012)
Epoch: [1][236/597]	Time 2.885 (6.991)	Data 2.824 (6.894)	Loss 4.8805 (5.6195)	Acc 0.000 (0.012)
Epoch: [1][237/597]	Time 11.323 (7.009)	Data 11.258 (6.912)	Loss 4.8315 (5.6162)	Acc 0.000 (0.012)
Epoch: [1][238/597]	Time 2.730 (6.991)	Data 2.667 (6.894)	Loss 4.7088 (5.6124)	Acc 0.062 (0.012)
Epoch: [1][239/597]	Time 12.083 (7.012)	Data 12.018 (6.916)	Loss 4.8726 (5.6093)	Acc 0.000 (0.012)
Epoch: [1][240/597]	Time 1.283 (6.989)	Data 1.220 (6.892)	Loss 4.5797 (5.6050)	Acc 0.062 (0.012)
Epoch: [1][241/597]	Time 11.278 (7.006)	Data 11.216 (6.910)	Loss 4.6942 (5.6012)	Acc 0.000 (0.012)
Epoch: [1][242/597]	Time 2.293 (6.987)	Data 2.228 (6.890)	Loss 5.1060 (5.5991)	Acc 0.000 (0.012)
Epoch: [1][243/597]	Time 10.866 (7.003)	Data 10.805 (6.907)	Loss 4.6786 (5.5954)	Acc 0.000 (0.012)
Epoch: [1][244/597]	Time 3.586 (6.989)	Data 3.523 (6.893)	Loss 4.6033 (5.5913)	Acc 0.062 (0.012)
Epoch: [1][245/597]	Time 10.119 (7.002)	Data 10.045 (6.906)	Loss 4.6754 (5.5875)	Acc 0.062 (0.013)
Epoch: [1][246/597]	Time 3.636 (6.988)	Data 3.570 (6.892)	Loss 4.9271 (5.5849)	Acc 0.000 (0.012)
Epoch: [1][247/597]	Time 9.885 (7.000)	Data 9.822 (6.904)	Loss 4.6976 (5.5813)	Acc 0.000 (0.012)
Epoch: [1][248/597]	Time 3.312 (6.985)	Data 3.242 (6.889)	Loss 4.7669 (5.5780)	Acc 0.000 (0.012)
Epoch: [1][249/597]	Time 10.852 (7.000)	Data 10.788 (6.905)	Loss 4.3964 (5.5732)	Acc 0.000 (0.012)
Epoch: [1][250/597]	Time 4.129 (6.989)	Data 4.065 (6.893)	Loss 4.5353 (5.5691)	Acc 0.000 (0.012)
Epoch: [1][251/597]	Time 10.158 (7.001)	Data 10.092 (6.906)	Loss 4.8440 (5.5662)	Acc 0.000 (0.012)
Epoch: [1][252/597]	Time 4.647 (6.992)	Data 4.583 (6.897)	Loss 4.5495 (5.5622)	Acc 0.062 (0.012)
Epoch: [1][253/597]	Time 9.527 (7.002)	Data 9.465 (6.907)	Loss 4.6329 (5.5585)	Acc 0.000 (0.012)
Epoch: [1][254/597]	Time 4.164 (6.991)	Data 4.101 (6.896)	Loss 4.8350 (5.5556)	Acc 0.000 (0.012)
Epoch: [1][255/597]	Time 9.538 (7.001)	Data 9.473 (6.906)	Loss 4.6446 (5.5521)	Acc 0.000 (0.012)
Epoch: [1][256/597]	Time 4.209 (6.990)	Data 4.096 (6.895)	Loss 4.7325 (5.5489)	Acc 0.062 (0.012)
Epoch: [1][257/597]	Time 9.303 (6.999)	Data 9.240 (6.904)	Loss 4.5894 (5.5451)	Acc 0.000 (0.012)
Epoch: [1][258/597]	Time 4.256 (6.988)	Data 4.193 (6.894)	Loss 5.0054 (5.5430)	Acc 0.000 (0.012)
Epoch: [1][259/597]	Time 9.364 (6.998)	Data 9.289 (6.903)	Loss 4.8902 (5.5405)	Acc 0.000 (0.012)
Epoch: [1][260/597]	Time 5.317 (6.991)	Data 5.254 (6.897)	Loss 5.0916 (5.5388)	Acc 0.000 (0.012)
Epoch: [1][261/597]	Time 8.347 (6.996)	Data 8.284 (6.902)	Loss 5.0826 (5.5371)	Acc 0.000 (0.012)
Epoch: [1][262/597]	Time 4.954 (6.989)	Data 4.871 (6.894)	Loss 4.6801 (5.5338)	Acc 0.000 (0.012)
Epoch: [1][263/597]	Time 9.205 (6.997)	Data 9.140 (6.903)	Loss 4.9196 (5.5314)	Acc 0.000 (0.012)
Epoch: [1][264/597]	Time 4.456 (6.987)	Data 4.393 (6.893)	Loss 4.6769 (5.5282)	Acc 0.000 (0.012)
Epoch: [1][265/597]	Time 8.809 (6.994)	Data 8.744 (6.900)	Loss 4.8513 (5.5257)	Acc 0.000 (0.012)
Epoch: [1][266/597]	Time 4.664 (6.985)	Data 4.601 (6.892)	Loss 4.4697 (5.5217)	Acc 0.062 (0.012)
Epoch: [1][267/597]	Time 8.950 (6.993)	Data 8.886 (6.899)	Loss 4.7573 (5.5188)	Acc 0.000 (0.012)
Epoch: [1][268/597]	Time 4.855 (6.985)	Data 4.784 (6.891)	Loss 4.6005 (5.5154)	Acc 0.062 (0.012)
Epoch: [1][269/597]	Time 9.041 (6.992)	Data 8.962 (6.899)	Loss 4.5387 (5.5118)	Acc 0.062 (0.013)
Epoch: [1][270/597]	Time 4.577 (6.984)	Data 4.514 (6.890)	Loss 4.5476 (5.5082)	Acc 0.062 (0.013)
Epoch: [1][271/597]	Time 8.817 (6.990)	Data 8.753 (6.897)	Loss 4.7638 (5.5054)	Acc 0.000 (0.013)
Epoch: [1][272/597]	Time 5.192 (6.984)	Data 5.129 (6.890)	Loss 4.6010 (5.5021)	Acc 0.000 (0.013)
Epoch: [1][273/597]	Time 8.529 (6.989)	Data 8.467 (6.896)	Loss 4.7242 (5.4993)	Acc 0.000 (0.013)
Epoch: [1][274/597]	Time 5.769 (6.985)	Data 5.706 (6.892)	Loss 4.6159 (5.4960)	Acc 0.000 (0.013)
Epoch: [1][275/597]	Time 9.093 (6.993)	Data 9.030 (6.900)	Loss 4.8228 (5.4936)	Acc 0.000 (0.013)
Epoch: [1][276/597]	Time 5.538 (6.987)	Data 5.474 (6.894)	Loss 4.6562 (5.4906)	Acc 0.062 (0.013)
Epoch: [1][277/597]	Time 8.386 (6.992)	Data 8.322 (6.900)	Loss 4.9717 (5.4887)	Acc 0.000 (0.013)
Epoch: [1][278/597]	Time 5.173 (6.986)	Data 5.108 (6.893)	Loss 4.6094 (5.4855)	Acc 0.062 (0.013)
Epoch: [1][279/597]	Time 9.174 (6.994)	Data 9.111 (6.901)	Loss 4.4298 (5.4817)	Acc 0.000 (0.013)
Epoch: [1][280/597]	Time 5.233 (6.987)	Data 5.170 (6.895)	Loss 4.4359 (5.4780)	Acc 0.000 (0.013)
Epoch: [1][281/597]	Time 10.228 (6.999)	Data 10.163 (6.907)	Loss 4.7607 (5.4755)	Acc 0.062 (0.013)
Epoch: [1][282/597]	Time 4.177 (6.989)	Data 4.112 (6.897)	Loss 4.7896 (5.4730)	Acc 0.000 (0.013)
Epoch: [1][283/597]	Time 9.645 (6.998)	Data 9.579 (6.906)	Loss 4.9985 (5.4713)	Acc 0.000 (0.013)
Epoch: [1][284/597]	Time 4.215 (6.988)	Data 4.151 (6.896)	Loss 4.9099 (5.4694)	Acc 0.062 (0.013)
Epoch: [1][285/597]	Time 10.296 (7.000)	Data 10.233 (6.908)	Loss 4.6865 (5.4666)	Acc 0.062 (0.013)
Epoch: [1][286/597]	Time 3.716 (6.989)	Data 3.653 (6.897)	Loss 4.6703 (5.4638)	Acc 0.000 (0.013)
Epoch: [1][287/597]	Time 9.578 (6.998)	Data 9.514 (6.906)	Loss 4.6780 (5.4611)	Acc 0.000 (0.013)
Epoch: [1][288/597]	Time 4.342 (6.988)	Data 4.276 (6.897)	Loss 4.5373 (5.4579)	Acc 0.062 (0.013)
Epoch: [1][289/597]	Time 9.478 (6.997)	Data 9.415 (6.905)	Loss 4.3539 (5.4541)	Acc 0.062 (0.013)
Epoch: [1][290/597]	Time 4.146 (6.987)	Data 4.082 (6.896)	Loss 4.7619 (5.4517)	Acc 0.000 (0.013)
Epoch: [1][291/597]	Time 9.380 (6.995)	Data 9.314 (6.904)	Loss 4.4335 (5.4482)	Acc 0.125 (0.014)
Epoch: [1][292/597]	Time 4.037 (6.985)	Data 3.973 (6.894)	Loss 4.5780 (5.4452)	Acc 0.000 (0.014)
Epoch: [1][293/597]	Time 9.642 (6.994)	Data 9.578 (6.903)	Loss 4.9810 (5.4436)	Acc 0.000 (0.014)
Epoch: [1][294/597]	Time 4.228 (6.985)	Data 4.165 (6.894)	Loss 4.9332 (5.4419)	Acc 0.000 (0.014)
Epoch: [1][295/597]	Time 9.564 (6.994)	Data 9.447 (6.902)	Loss 4.7224 (5.4394)	Acc 0.000 (0.014)
Epoch: [1][296/597]	Time 3.980 (6.983)	Data 3.915 (6.892)	Loss 4.4309 (5.4360)	Acc 0.000 (0.014)
Epoch: [1][297/597]	Time 10.243 (6.994)	Data 10.179 (6.903)	Loss 4.6727 (5.4335)	Acc 0.000 (0.013)
Epoch: [1][298/597]	Time 3.385 (6.982)	Data 3.323 (6.891)	Loss 4.6589 (5.4309)	Acc 0.000 (0.013)
Epoch: [1][299/597]	Time 10.045 (6.993)	Data 9.981 (6.902)	Loss 4.6550 (5.4283)	Acc 0.000 (0.013)
Epoch: [1][300/597]	Time 4.264 (6.983)	Data 4.200 (6.893)	Loss 4.5654 (5.4254)	Acc 0.062 (0.014)
Epoch: [1][301/597]	Time 9.878 (6.993)	Data 9.812 (6.902)	Loss 4.6798 (5.4229)	Acc 0.000 (0.013)
Epoch: [1][302/597]	Time 4.269 (6.984)	Data 4.205 (6.894)	Loss 4.4367 (5.4197)	Acc 0.250 (0.014)
Epoch: [1][303/597]	Time 8.963 (6.991)	Data 8.898 (6.900)	Loss 4.5461 (5.4168)	Acc 0.000 (0.014)
Epoch: [1][304/597]	Time 5.512 (6.986)	Data 5.448 (6.895)	Loss 4.8042 (5.4148)	Acc 0.000 (0.014)
Epoch: [1][305/597]	Time 7.325 (6.987)	Data 7.260 (6.897)	Loss 4.7072 (5.4124)	Acc 0.000 (0.014)
Epoch: [1][306/597]	Time 7.056 (6.987)	Data 6.991 (6.897)	Loss 4.7285 (5.4102)	Acc 0.000 (0.014)
Epoch: [1][307/597]	Time 7.022 (6.987)	Data 6.937 (6.897)	Loss 4.5154 (5.4073)	Acc 0.000 (0.014)
Epoch: [1][308/597]	Time 6.480 (6.986)	Data 6.417 (6.895)	Loss 4.8179 (5.4054)	Acc 0.000 (0.014)
Epoch: [1][309/597]	Time 8.366 (6.990)	Data 8.301 (6.900)	Loss 4.4981 (5.4024)	Acc 0.000 (0.014)
Epoch: [1][310/597]	Time 5.585 (6.985)	Data 5.521 (6.896)	Loss 4.6296 (5.3999)	Acc 0.000 (0.014)
Epoch: [1][311/597]	Time 8.586 (6.991)	Data 8.523 (6.901)	Loss 4.6428 (5.3975)	Acc 0.000 (0.014)
Epoch: [1][312/597]	Time 5.093 (6.985)	Data 5.029 (6.895)	Loss 4.3911 (5.3943)	Acc 0.062 (0.014)
Epoch: [1][313/597]	Time 9.456 (6.992)	Data 9.393 (6.903)	Loss 4.8672 (5.3926)	Acc 0.000 (0.014)
Epoch: [1][314/597]	Time 4.718 (6.985)	Data 4.653 (6.896)	Loss 4.6238 (5.3902)	Acc 0.000 (0.014)
Epoch: [1][315/597]	Time 9.901 (6.994)	Data 9.837 (6.905)	Loss 4.6149 (5.3877)	Acc 0.000 (0.014)
Epoch: [1][316/597]	Time 3.954 (6.985)	Data 3.890 (6.895)	Loss 4.4824 (5.3848)	Acc 0.062 (0.014)
Epoch: [1][317/597]	Time 9.985 (6.994)	Data 9.922 (6.905)	Loss 4.6162 (5.3824)	Acc 0.000 (0.014)
Epoch: [1][318/597]	Time 4.822 (6.987)	Data 4.759 (6.898)	Loss 4.7214 (5.3803)	Acc 0.062 (0.014)
Epoch: [1][319/597]	Time 9.306 (6.995)	Data 9.240 (6.906)	Loss 4.8297 (5.3786)	Acc 0.062 (0.014)
Epoch: [1][320/597]	Time 5.503 (6.990)	Data 5.439 (6.901)	Loss 5.0017 (5.3774)	Acc 0.000 (0.014)
Epoch: [1][321/597]	Time 9.158 (6.997)	Data 9.094 (6.908)	Loss 4.5201 (5.3747)	Acc 0.000 (0.014)
Epoch: [1][322/597]	Time 4.770 (6.990)	Data 4.708 (6.901)	Loss 4.6800 (5.3726)	Acc 0.062 (0.014)
Epoch: [1][323/597]	Time 9.367 (6.997)	Data 9.303 (6.908)	Loss 4.7697 (5.3707)	Acc 0.000 (0.014)
Epoch: [1][324/597]	Time 4.146 (6.988)	Data 4.081 (6.900)	Loss 4.8112 (5.3690)	Acc 0.062 (0.014)
Epoch: [1][325/597]	Time 9.828 (6.997)	Data 9.764 (6.908)	Loss 4.4755 (5.3662)	Acc 0.000 (0.014)
Epoch: [1][326/597]	Time 3.934 (6.988)	Data 3.871 (6.899)	Loss 4.5320 (5.3637)	Acc 0.000 (0.014)
Epoch: [1][327/597]	Time 10.106 (6.997)	Data 10.042 (6.909)	Loss 4.7277 (5.3617)	Acc 0.000 (0.014)
Epoch: [1][328/597]	Time 4.590 (6.990)	Data 4.527 (6.902)	Loss 4.7464 (5.3599)	Acc 0.000 (0.014)
Epoch: [1][329/597]	Time 8.670 (6.995)	Data 8.606 (6.907)	Loss 4.6552 (5.3577)	Acc 0.062 (0.014)
Epoch: [1][330/597]	Time 5.000 (6.989)	Data 4.935 (6.901)	Loss 4.6644 (5.3556)	Acc 0.000 (0.014)
Epoch: [1][331/597]	Time 8.872 (6.995)	Data 8.807 (6.906)	Loss 4.9333 (5.3544)	Acc 0.000 (0.014)
Epoch: [1][332/597]	Time 4.755 (6.988)	Data 4.689 (6.900)	Loss 4.7513 (5.3525)	Acc 0.000 (0.014)
Epoch: [1][333/597]	Time 8.521 (6.993)	Data 8.457 (6.904)	Loss 4.7401 (5.3507)	Acc 0.000 (0.014)
Epoch: [1][334/597]	Time 5.214 (6.987)	Data 5.090 (6.899)	Loss 4.7137 (5.3488)	Acc 0.000 (0.014)
Epoch: [1][335/597]	Time 8.960 (6.993)	Data 8.897 (6.905)	Loss 4.9128 (5.3475)	Acc 0.000 (0.014)
Epoch: [1][336/597]	Time 4.488 (6.986)	Data 4.425 (6.898)	Loss 4.7543 (5.3457)	Acc 0.062 (0.014)
Epoch: [1][337/597]	Time 8.806 (6.991)	Data 8.729 (6.903)	Loss 4.7565 (5.3440)	Acc 0.000 (0.014)
Epoch: [1][338/597]	Time 4.178 (6.983)	Data 4.114 (6.895)	Loss 4.5649 (5.3417)	Acc 0.000 (0.014)
Epoch: [1][339/597]	Time 9.152 (6.989)	Data 9.085 (6.901)	Loss 4.6251 (5.3396)	Acc 0.062 (0.014)
Epoch: [1][340/597]	Time 4.211 (6.981)	Data 4.130 (6.893)	Loss 4.6826 (5.3376)	Acc 0.000 (0.014)
Epoch: [1][341/597]	Time 8.904 (6.987)	Data 8.840 (6.899)	Loss 4.7538 (5.3359)	Acc 0.000 (0.014)
Epoch: [1][342/597]	Time 4.155 (6.978)	Data 4.091 (6.891)	Loss 4.5820 (5.3337)	Acc 0.062 (0.014)
Epoch: [1][343/597]	Time 9.442 (6.986)	Data 9.379 (6.898)	Loss 4.6364 (5.3317)	Acc 0.000 (0.014)
Epoch: [1][344/597]	Time 3.682 (6.976)	Data 3.621 (6.888)	Loss 4.7377 (5.3299)	Acc 0.062 (0.015)
Epoch: [1][345/597]	Time 11.276 (6.988)	Data 11.209 (6.901)	Loss 4.6246 (5.3279)	Acc 0.000 (0.014)
Epoch: [1][346/597]	Time 3.510 (6.978)	Data 3.446 (6.891)	Loss 4.7030 (5.3261)	Acc 0.000 (0.014)
Epoch: [1][347/597]	Time 10.785 (6.989)	Data 10.720 (6.902)	Loss 4.7464 (5.3244)	Acc 0.000 (0.014)
Epoch: [1][348/597]	Time 3.044 (6.978)	Data 2.979 (6.891)	Loss 4.6110 (5.3224)	Acc 0.062 (0.015)
Epoch: [1][349/597]	Time 10.962 (6.989)	Data 10.898 (6.902)	Loss 4.5444 (5.3201)	Acc 0.000 (0.015)
Epoch: [1][350/597]	Time 3.075 (6.978)	Data 2.997 (6.891)	Loss 4.5933 (5.3181)	Acc 0.000 (0.014)
Epoch: [1][351/597]	Time 10.095 (6.987)	Data 10.030 (6.900)	Loss 4.6131 (5.3161)	Acc 0.062 (0.015)
Epoch: [1][352/597]	Time 4.292 (6.979)	Data 4.228 (6.892)	Loss 4.3954 (5.3134)	Acc 0.000 (0.015)
Epoch: [1][353/597]	Time 10.206 (6.989)	Data 10.143 (6.902)	Loss 4.5652 (5.3113)	Acc 0.000 (0.015)
Epoch: [1][354/597]	Time 4.020 (6.980)	Data 3.944 (6.893)	Loss 4.5940 (5.3093)	Acc 0.000 (0.014)
Epoch: [1][355/597]	Time 10.828 (6.991)	Data 10.765 (6.904)	Loss 4.4222 (5.3068)	Acc 0.062 (0.015)
Epoch: [1][356/597]	Time 3.045 (6.980)	Data 2.982 (6.893)	Loss 4.4667 (5.3044)	Acc 0.000 (0.015)
Epoch: [1][357/597]	Time 11.109 (6.992)	Data 11.046 (6.905)	Loss 4.4570 (5.3021)	Acc 0.000 (0.015)
Epoch: [1][358/597]	Time 3.223 (6.981)	Data 3.159 (6.894)	Loss 4.5272 (5.2999)	Acc 0.000 (0.014)
Epoch: [1][359/597]	Time 10.458 (6.991)	Data 10.395 (6.904)	Loss 4.6304 (5.2980)	Acc 0.000 (0.014)
Epoch: [1][360/597]	Time 2.945 (6.979)	Data 2.882 (6.893)	Loss 4.5992 (5.2961)	Acc 0.000 (0.014)
Epoch: [1][361/597]	Time 11.987 (6.993)	Data 11.906 (6.907)	Loss 4.9411 (5.2951)	Acc 0.000 (0.014)
Epoch: [1][362/597]	Time 2.760 (6.982)	Data 2.697 (6.895)	Loss 4.7358 (5.2936)	Acc 0.000 (0.014)
Epoch: [1][363/597]	Time 10.849 (6.992)	Data 10.762 (6.906)	Loss 4.6304 (5.2917)	Acc 0.000 (0.014)
Epoch: [1][364/597]	Time 2.782 (6.981)	Data 2.719 (6.894)	Loss 4.9199 (5.2907)	Acc 0.000 (0.014)
Epoch: [1][365/597]	Time 10.273 (6.990)	Data 10.209 (6.903)	Loss 4.8113 (5.2894)	Acc 0.000 (0.014)
Epoch: [1][366/597]	Time 2.560 (6.978)	Data 2.494 (6.891)	Loss 4.4203 (5.2870)	Acc 0.000 (0.014)
Epoch: [1][367/597]	Time 10.621 (6.988)	Data 10.558 (6.901)	Loss 4.4994 (5.2849)	Acc 0.000 (0.014)
Epoch: [1][368/597]	Time 3.538 (6.978)	Data 3.472 (6.892)	Loss 4.6770 (5.2832)	Acc 0.000 (0.014)
Epoch: [1][369/597]	Time 9.705 (6.986)	Data 9.641 (6.899)	Loss 4.5892 (5.2814)	Acc 0.000 (0.014)
Epoch: [1][370/597]	Time 3.283 (6.976)	Data 3.200 (6.889)	Loss 4.5557 (5.2794)	Acc 0.000 (0.014)
Epoch: [1][371/597]	Time 10.006 (6.984)	Data 9.940 (6.898)	Loss 4.6109 (5.2776)	Acc 0.000 (0.014)
Epoch: [1][372/597]	Time 3.501 (6.974)	Data 3.437 (6.888)	Loss 4.5186 (5.2755)	Acc 0.000 (0.014)
Epoch: [1][373/597]	Time 10.267 (6.983)	Data 10.144 (6.897)	Loss 4.4454 (5.2733)	Acc 0.000 (0.014)
Epoch: [1][374/597]	Time 2.765 (6.972)	Data 2.700 (6.886)	Loss 4.6213 (5.2716)	Acc 0.062 (0.014)
Epoch: [1][375/597]	Time 10.544 (6.981)	Data 10.480 (6.895)	Loss 4.4905 (5.2695)	Acc 0.062 (0.014)
Epoch: [1][376/597]	Time 4.209 (6.974)	Data 4.146 (6.888)	Loss 4.8771 (5.2685)	Acc 0.000 (0.014)
Epoch: [1][377/597]	Time 8.779 (6.979)	Data 8.714 (6.893)	Loss 4.1500 (5.2655)	Acc 0.125 (0.014)
Epoch: [1][378/597]	Time 4.971 (6.974)	Data 4.903 (6.888)	Loss 4.5358 (5.2636)	Acc 0.000 (0.014)
Epoch: [1][379/597]	Time 8.411 (6.977)	Data 8.346 (6.892)	Loss 4.3537 (5.2612)	Acc 0.062 (0.015)
Epoch: [1][380/597]	Time 4.809 (6.972)	Data 4.746 (6.886)	Loss 4.3441 (5.2587)	Acc 0.062 (0.015)
Epoch: [1][381/597]	Time 8.103 (6.975)	Data 8.040 (6.889)	Loss 4.4416 (5.2566)	Acc 0.000 (0.015)
Epoch: [1][382/597]	Time 5.309 (6.970)	Data 5.245 (6.885)	Loss 4.5395 (5.2547)	Acc 0.000 (0.015)
Epoch: [1][383/597]	Time 7.728 (6.972)	Data 7.663 (6.887)	Loss 4.4156 (5.2525)	Acc 0.000 (0.015)
Epoch: [1][384/597]	Time 5.373 (6.968)	Data 5.309 (6.883)	Loss 4.8263 (5.2514)	Acc 0.000 (0.014)
Epoch: [1][385/597]	Time 7.477 (6.969)	Data 7.411 (6.884)	Loss 4.6402 (5.2498)	Acc 0.000 (0.014)
Epoch: [1][386/597]	Time 5.511 (6.966)	Data 5.446 (6.880)	Loss 4.6249 (5.2482)	Acc 0.000 (0.014)
Epoch: [1][387/597]	Time 6.886 (6.965)	Data 6.821 (6.880)	Loss 4.5236 (5.2463)	Acc 0.000 (0.014)
Epoch: [1][388/597]	Time 6.156 (6.963)	Data 6.081 (6.878)	Loss 4.3556 (5.2440)	Acc 0.125 (0.015)
Epoch: [1][389/597]	Time 6.527 (6.962)	Data 6.463 (6.877)	Loss 4.3485 (5.2417)	Acc 0.062 (0.015)
Epoch: [1][390/597]	Time 6.420 (6.961)	Data 6.356 (6.876)	Loss 4.4216 (5.2396)	Acc 0.062 (0.015)
Epoch: [1][391/597]	Time 7.093 (6.961)	Data 7.026 (6.876)	Loss 4.5557 (5.2379)	Acc 0.000 (0.015)
Epoch: [1][392/597]	Time 7.032 (6.961)	Data 6.967 (6.876)	Loss 4.4600 (5.2359)	Acc 0.062 (0.015)
Epoch: [1][393/597]	Time 5.960 (6.959)	Data 5.894 (6.874)	Loss 4.5871 (5.2343)	Acc 0.000 (0.015)
Epoch: [1][394/597]	Time 7.317 (6.960)	Data 7.235 (6.875)	Loss 4.4097 (5.2322)	Acc 0.000 (0.015)
Epoch: [1][395/597]	Time 6.410 (6.958)	Data 6.342 (6.873)	Loss 4.3804 (5.2300)	Acc 0.000 (0.015)
Epoch: [1][396/597]	Time 7.277 (6.959)	Data 7.212 (6.874)	Loss 4.5305 (5.2282)	Acc 0.000 (0.015)
Epoch: [1][397/597]	Time 6.263 (6.957)	Data 6.192 (6.872)	Loss 4.8582 (5.2273)	Acc 0.000 (0.015)
Epoch: [1][398/597]	Time 8.071 (6.960)	Data 8.003 (6.875)	Loss 4.4354 (5.2253)	Acc 0.062 (0.015)
Epoch: [1][399/597]	Time 4.881 (6.955)	Data 4.813 (6.870)	Loss 4.5541 (5.2236)	Acc 0.000 (0.015)
Epoch: [1][400/597]	Time 8.734 (6.959)	Data 8.664 (6.875)	Loss 4.3965 (5.2216)	Acc 0.000 (0.015)
Epoch: [1][401/597]	Time 5.005 (6.955)	Data 4.940 (6.870)	Loss 4.4829 (5.2197)	Acc 0.062 (0.015)
Epoch: [1][402/597]	Time 7.688 (6.956)	Data 7.619 (6.872)	Loss 4.9150 (5.2190)	Acc 0.000 (0.015)
Epoch: [1][403/597]	Time 5.627 (6.953)	Data 5.560 (6.868)	Loss 4.6692 (5.2176)	Acc 0.000 (0.015)
Epoch: [1][404/597]	Time 8.372 (6.957)	Data 8.305 (6.872)	Loss 4.3957 (5.2156)	Acc 0.000 (0.015)
Epoch: [1][405/597]	Time 5.071 (6.952)	Data 5.002 (6.867)	Loss 4.5626 (5.2140)	Acc 0.000 (0.015)
Epoch: [1][406/597]	Time 8.854 (6.957)	Data 8.786 (6.872)	Loss 4.9632 (5.2133)	Acc 0.000 (0.015)
Epoch: [1][407/597]	Time 4.769 (6.951)	Data 4.702 (6.867)	Loss 4.6487 (5.2120)	Acc 0.000 (0.015)
Epoch: [1][408/597]	Time 7.693 (6.953)	Data 7.623 (6.868)	Loss 4.5900 (5.2104)	Acc 0.000 (0.015)
Epoch: [1][409/597]	Time 6.005 (6.951)	Data 5.936 (6.866)	Loss 4.4440 (5.2086)	Acc 0.000 (0.015)
Epoch: [1][410/597]	Time 5.847 (6.948)	Data 5.779 (6.864)	Loss 4.5207 (5.2069)	Acc 0.000 (0.015)
Epoch: [1][411/597]	Time 7.132 (6.948)	Data 7.065 (6.864)	Loss 4.5307 (5.2052)	Acc 0.000 (0.015)
Epoch: [1][412/597]	Time 5.931 (6.946)	Data 5.804 (6.861)	Loss 4.4498 (5.2034)	Acc 0.000 (0.015)
Epoch: [1][413/597]	Time 7.305 (6.947)	Data 7.236 (6.862)	Loss 4.5821 (5.2019)	Acc 0.000 (0.015)
Epoch: [1][414/597]	Time 6.451 (6.946)	Data 6.379 (6.861)	Loss 4.6412 (5.2005)	Acc 0.000 (0.014)
Epoch: [1][415/597]	Time 6.278 (6.944)	Data 6.207 (6.860)	Loss 4.4855 (5.1988)	Acc 0.062 (0.015)
Epoch: [1][416/597]	Time 6.569 (6.943)	Data 6.496 (6.859)	Loss 4.3361 (5.1967)	Acc 0.000 (0.015)
Epoch: [1][417/597]	Time 6.895 (6.943)	Data 6.825 (6.859)	Loss 4.5158 (5.1951)	Acc 0.000 (0.015)
Epoch: [1][418/597]	Time 6.548 (6.942)	Data 6.472 (6.858)	Loss 4.5309 (5.1935)	Acc 0.000 (0.015)
Epoch: [1][419/597]	Time 6.843 (6.942)	Data 6.767 (6.858)	Loss 4.5383 (5.1920)	Acc 0.000 (0.014)
Epoch: [1][420/597]	Time 6.769 (6.941)	Data 6.695 (6.857)	Loss 4.8506 (5.1911)	Acc 0.000 (0.014)
Epoch: [1][421/597]	Time 7.051 (6.942)	Data 6.975 (6.857)	Loss 4.7684 (5.1901)	Acc 0.000 (0.014)
Epoch: [1][422/597]	Time 6.579 (6.941)	Data 6.504 (6.857)	Loss 4.5050 (5.1885)	Acc 0.062 (0.015)
Epoch: [1][423/597]	Time 7.431 (6.942)	Data 7.357 (6.858)	Loss 4.6409 (5.1872)	Acc 0.000 (0.014)
Epoch: [1][424/597]	Time 5.839 (6.939)	Data 5.765 (6.855)	Loss 4.2973 (5.1851)	Acc 0.062 (0.015)
Epoch: [1][425/597]	Time 8.627 (6.943)	Data 8.555 (6.859)	Loss 4.8743 (5.1844)	Acc 0.000 (0.015)
Epoch: [1][426/597]	Time 4.927 (6.939)	Data 4.856 (6.855)	Loss 4.8428 (5.1836)	Acc 0.000 (0.015)
Epoch: [1][427/597]	Time 8.435 (6.942)	Data 8.361 (6.858)	Loss 4.5365 (5.1821)	Acc 0.000 (0.014)
Epoch: [1][428/597]	Time 6.144 (6.940)	Data 6.070 (6.856)	Loss 4.8844 (5.1814)	Acc 0.000 (0.014)
Epoch: [1][429/597]	Time 7.565 (6.942)	Data 7.493 (6.858)	Loss 4.4178 (5.1796)	Acc 0.000 (0.014)
Epoch: [1][430/597]	Time 6.799 (6.941)	Data 6.725 (6.857)	Loss 4.6600 (5.1784)	Acc 0.000 (0.014)
Epoch: [1][431/597]	Time 7.492 (6.943)	Data 7.409 (6.859)	Loss 4.4958 (5.1768)	Acc 0.062 (0.015)
Epoch: [1][432/597]	Time 6.747 (6.942)	Data 6.672 (6.858)	Loss 4.4831 (5.1752)	Acc 0.000 (0.014)
Epoch: [1][433/597]	Time 6.951 (6.942)	Data 6.879 (6.858)	Loss 4.4562 (5.1735)	Acc 0.000 (0.014)
Epoch: [1][434/597]	Time 7.035 (6.942)	Data 6.963 (6.859)	Loss 4.3090 (5.1715)	Acc 0.000 (0.014)
Epoch: [1][435/597]	Time 7.715 (6.944)	Data 7.645 (6.860)	Loss 4.7894 (5.1707)	Acc 0.000 (0.014)
Epoch: [1][436/597]	Time 7.344 (6.945)	Data 7.271 (6.861)	Loss 4.8472 (5.1699)	Acc 0.000 (0.014)
Epoch: [1][437/597]	Time 7.352 (6.946)	Data 7.279 (6.862)	Loss 4.5191 (5.1684)	Acc 0.000 (0.014)
Epoch: [1][438/597]	Time 6.794 (6.946)	Data 6.720 (6.862)	Loss 4.6039 (5.1671)	Acc 0.000 (0.014)
Epoch: [1][439/597]	Time 6.683 (6.945)	Data 6.608 (6.861)	Loss 4.4807 (5.1656)	Acc 0.062 (0.014)
Epoch: [1][440/597]	Time 6.840 (6.945)	Data 6.769 (6.861)	Loss 4.4171 (5.1639)	Acc 0.000 (0.014)
Epoch: [1][441/597]	Time 7.175 (6.945)	Data 7.104 (6.862)	Loss 4.4550 (5.1623)	Acc 0.000 (0.014)
Epoch: [1][442/597]	Time 6.346 (6.944)	Data 6.272 (6.860)	Loss 4.1656 (5.1600)	Acc 0.125 (0.015)
Epoch: [1][443/597]	Time 7.599 (6.946)	Data 7.526 (6.862)	Loss 4.4630 (5.1584)	Acc 0.000 (0.015)
Epoch: [1][444/597]	Time 5.974 (6.943)	Data 5.900 (6.860)	Loss 4.5900 (5.1572)	Acc 0.000 (0.014)
Epoch: [1][445/597]	Time 8.358 (6.947)	Data 8.284 (6.863)	Loss 4.5884 (5.1559)	Acc 0.000 (0.014)
Epoch: [1][446/597]	Time 5.546 (6.943)	Data 5.473 (6.860)	Loss 4.5397 (5.1545)	Acc 0.062 (0.015)
Epoch: [1][447/597]	Time 8.000 (6.946)	Data 7.926 (6.862)	Loss 4.4112 (5.1528)	Acc 0.062 (0.015)
Epoch: [1][448/597]	Time 6.028 (6.944)	Data 5.955 (6.860)	Loss 4.3665 (5.1511)	Acc 0.000 (0.015)
Epoch: [1][449/597]	Time 8.305 (6.947)	Data 8.231 (6.863)	Loss 5.1425 (5.1511)	Acc 0.000 (0.015)
Epoch: [1][450/597]	Time 5.179 (6.943)	Data 5.106 (6.859)	Loss 4.7182 (5.1501)	Acc 0.000 (0.015)
Epoch: [1][451/597]	Time 9.147 (6.948)	Data 8.987 (6.864)	Loss 4.5340 (5.1487)	Acc 0.062 (0.015)
Epoch: [1][452/597]	Time 5.401 (6.944)	Data 5.328 (6.861)	Loss 4.3559 (5.1470)	Acc 0.062 (0.015)
Epoch: [1][453/597]	Time 8.588 (6.948)	Data 8.514 (6.864)	Loss 4.4416 (5.1454)	Acc 0.062 (0.015)
Epoch: [1][454/597]	Time 6.255 (6.946)	Data 6.184 (6.863)	Loss 4.6404 (5.1443)	Acc 0.000 (0.015)
Epoch: [1][455/597]	Time 8.053 (6.949)	Data 7.985 (6.865)	Loss 4.1994 (5.1422)	Acc 0.062 (0.015)
Epoch: [1][456/597]	Time 7.060 (6.949)	Data 6.993 (6.865)	Loss 4.2279 (5.1402)	Acc 0.062 (0.015)
Epoch: [1][457/597]	Time 7.444 (6.950)	Data 7.376 (6.867)	Loss 4.7878 (5.1395)	Acc 0.062 (0.015)
Epoch: [1][458/597]	Time 5.964 (6.948)	Data 5.896 (6.864)	Loss 4.2523 (5.1375)	Acc 0.125 (0.015)
Epoch: [1][459/597]	Time 7.533 (6.949)	Data 7.467 (6.866)	Loss 4.2526 (5.1356)	Acc 0.062 (0.016)
Epoch: [1][460/597]	Time 6.239 (6.948)	Data 6.174 (6.864)	Loss 4.6751 (5.1346)	Acc 0.000 (0.015)
Epoch: [1][461/597]	Time 7.900 (6.950)	Data 7.834 (6.866)	Loss 4.3853 (5.1330)	Acc 0.062 (0.016)
Epoch: [1][462/597]	Time 6.461 (6.949)	Data 6.395 (6.865)	Loss 4.6242 (5.1319)	Acc 0.062 (0.016)
Epoch: [1][463/597]	Time 7.598 (6.950)	Data 7.518 (6.867)	Loss 4.3663 (5.1302)	Acc 0.000 (0.016)
Epoch: [1][464/597]	Time 5.830 (6.948)	Data 5.763 (6.864)	Loss 4.6073 (5.1291)	Acc 0.000 (0.016)
Epoch: [1][465/597]	Time 7.956 (6.950)	Data 7.892 (6.867)	Loss 4.5179 (5.1278)	Acc 0.000 (0.016)
Epoch: [1][466/597]	Time 5.055 (6.946)	Data 4.982 (6.863)	Loss 4.7778 (5.1270)	Acc 0.000 (0.016)
Epoch: [1][467/597]	Time 8.421 (6.949)	Data 8.355 (6.866)	Loss 4.4914 (5.1257)	Acc 0.000 (0.016)
Epoch: [1][468/597]	Time 5.642 (6.946)	Data 5.574 (6.863)	Loss 4.4234 (5.1242)	Acc 0.000 (0.015)
Epoch: [1][469/597]	Time 8.132 (6.949)	Data 8.066 (6.866)	Loss 4.6877 (5.1232)	Acc 0.000 (0.015)
Epoch: [1][470/597]	Time 5.643 (6.946)	Data 5.578 (6.863)	Loss 4.6370 (5.1222)	Acc 0.000 (0.015)
Epoch: [1][471/597]	Time 8.346 (6.949)	Data 8.281 (6.866)	Loss 4.5376 (5.1210)	Acc 0.000 (0.015)
Epoch: [1][472/597]	Time 5.670 (6.946)	Data 5.604 (6.863)	Loss 4.3116 (5.1192)	Acc 0.000 (0.015)
Epoch: [1][473/597]	Time 7.821 (6.948)	Data 7.755 (6.865)	Loss 4.3543 (5.1176)	Acc 0.000 (0.015)
Epoch: [1][474/597]	Time 5.110 (6.944)	Data 5.044 (6.861)	Loss 4.5075 (5.1163)	Acc 0.062 (0.015)
Epoch: [1][475/597]	Time 8.504 (6.947)	Data 8.440 (6.865)	Loss 4.4527 (5.1149)	Acc 0.000 (0.015)
Epoch: [1][476/597]	Time 5.222 (6.944)	Data 5.155 (6.861)	Loss 4.5996 (5.1139)	Acc 0.000 (0.015)
Epoch: [1][477/597]	Time 8.433 (6.947)	Data 8.368 (6.864)	Loss 4.1383 (5.1118)	Acc 0.062 (0.015)
Epoch: [1][478/597]	Time 5.322 (6.944)	Data 5.253 (6.861)	Loss 4.4411 (5.1104)	Acc 0.000 (0.015)
Epoch: [1][479/597]	Time 7.262 (6.944)	Data 7.197 (6.861)	Loss 4.6938 (5.1095)	Acc 0.000 (0.015)
Epoch: [1][480/597]	Time 5.658 (6.942)	Data 5.592 (6.859)	Loss 4.4290 (5.1081)	Acc 0.062 (0.015)
Epoch: [1][481/597]	Time 7.394 (6.942)	Data 7.330 (6.860)	Loss 4.4798 (5.1068)	Acc 0.000 (0.015)
Epoch: [1][482/597]	Time 6.423 (6.941)	Data 6.356 (6.859)	Loss 4.5052 (5.1056)	Acc 0.000 (0.015)
Epoch: [1][483/597]	Time 7.185 (6.942)	Data 7.120 (6.859)	Loss 4.5999 (5.1045)	Acc 0.000 (0.015)
Epoch: [1][484/597]	Time 6.157 (6.940)	Data 6.094 (6.858)	Loss 4.3914 (5.1030)	Acc 0.000 (0.015)
Epoch: [1][485/597]	Time 6.853 (6.940)	Data 6.785 (6.858)	Loss 4.7595 (5.1023)	Acc 0.000 (0.015)
Epoch: [1][486/597]	Time 6.441 (6.939)	Data 6.371 (6.857)	Loss 4.6351 (5.1014)	Acc 0.000 (0.015)
Epoch: [1][487/597]	Time 6.974 (6.939)	Data 6.910 (6.857)	Loss 4.1440 (5.0994)	Acc 0.125 (0.016)
Epoch: [1][488/597]	Time 5.734 (6.937)	Data 5.651 (6.854)	Loss 4.2731 (5.0977)	Acc 0.062 (0.016)
Epoch: [1][489/597]	Time 8.011 (6.939)	Data 7.945 (6.856)	Loss 4.1369 (5.0958)	Acc 0.000 (0.016)
Epoch: [1][490/597]	Time 5.699 (6.936)	Data 5.581 (6.854)	Loss 4.3678 (5.0943)	Acc 0.000 (0.016)
Epoch: [1][491/597]	Time 7.896 (6.938)	Data 7.832 (6.856)	Loss 4.4550 (5.0930)	Acc 0.062 (0.016)
Epoch: [1][492/597]	Time 5.264 (6.935)	Data 5.198 (6.852)	Loss 4.6470 (5.0921)	Acc 0.062 (0.016)
Epoch: [1][493/597]	Time 8.028 (6.937)	Data 7.961 (6.855)	Loss 4.3325 (5.0905)	Acc 0.000 (0.016)
Epoch: [1][494/597]	Time 5.560 (6.934)	Data 5.486 (6.852)	Loss 4.6077 (5.0895)	Acc 0.062 (0.016)
Epoch: [1][495/597]	Time 8.497 (6.937)	Data 8.433 (6.855)	Loss 4.2794 (5.0879)	Acc 0.000 (0.016)
Epoch: [1][496/597]	Time 5.049 (6.934)	Data 4.984 (6.851)	Loss 4.6290 (5.0870)	Acc 0.000 (0.016)
Epoch: [1][497/597]	Time 8.184 (6.936)	Data 8.120 (6.854)	Loss 4.6239 (5.0861)	Acc 0.000 (0.016)
Epoch: [1][498/597]	Time 5.848 (6.934)	Data 5.783 (6.852)	Loss 4.9680 (5.0858)	Acc 0.000 (0.016)
Epoch: [1][499/597]	Time 8.333 (6.937)	Data 8.268 (6.855)	Loss 4.5895 (5.0848)	Acc 0.000 (0.016)
Epoch: [1][500/597]	Time 5.449 (6.934)	Data 5.385 (6.852)	Loss 4.1755 (5.0830)	Acc 0.125 (0.016)
Epoch: [1][501/597]	Time 8.662 (6.937)	Data 8.596 (6.855)	Loss 4.5493 (5.0819)	Acc 0.000 (0.016)
Epoch: [1][502/597]	Time 4.916 (6.933)	Data 4.852 (6.851)	Loss 4.6742 (5.0811)	Acc 0.000 (0.016)
Epoch: [1][503/597]	Time 9.417 (6.938)	Data 9.353 (6.856)	Loss 4.6837 (5.0803)	Acc 0.000 (0.016)
Epoch: [1][504/597]	Time 4.737 (6.934)	Data 4.672 (6.852)	Loss 4.7943 (5.0798)	Acc 0.000 (0.016)
Epoch: [1][505/597]	Time 8.746 (6.937)	Data 8.679 (6.855)	Loss 4.5625 (5.0787)	Acc 0.062 (0.016)
Epoch: [1][506/597]	Time 4.378 (6.932)	Data 4.299 (6.850)	Loss 4.4593 (5.0775)	Acc 0.000 (0.016)
Epoch: [1][507/597]	Time 9.761 (6.938)	Data 9.697 (6.856)	Loss 4.6293 (5.0766)	Acc 0.000 (0.016)
Epoch: [1][508/597]	Time 4.513 (6.933)	Data 4.449 (6.851)	Loss 4.7119 (5.0759)	Acc 0.000 (0.016)
Epoch: [1][509/597]	Time 9.782 (6.939)	Data 9.719 (6.857)	Loss 4.6827 (5.0751)	Acc 0.000 (0.016)
Epoch: [1][510/597]	Time 3.870 (6.933)	Data 3.804 (6.851)	Loss 4.4464 (5.0739)	Acc 0.000 (0.016)
Epoch: [1][511/597]	Time 9.807 (6.938)	Data 9.729 (6.856)	Loss 4.3660 (5.0725)	Acc 0.000 (0.016)
Epoch: [1][512/597]	Time 3.742 (6.932)	Data 3.679 (6.850)	Loss 4.6921 (5.0718)	Acc 0.000 (0.016)
Epoch: [1][513/597]	Time 9.447 (6.937)	Data 9.367 (6.855)	Loss 4.4150 (5.0705)	Acc 0.000 (0.016)
Epoch: [1][514/597]	Time 4.991 (6.933)	Data 4.926 (6.851)	Loss 4.4722 (5.0693)	Acc 0.000 (0.016)
Epoch: [1][515/597]	Time 8.937 (6.937)	Data 8.874 (6.855)	Loss 4.3365 (5.0679)	Acc 0.062 (0.016)
Epoch: [1][516/597]	Time 4.960 (6.933)	Data 4.892 (6.852)	Loss 4.3418 (5.0665)	Acc 0.000 (0.016)
Epoch: [1][517/597]	Time 8.630 (6.937)	Data 8.566 (6.855)	Loss 4.3237 (5.0651)	Acc 0.000 (0.016)
Epoch: [1][518/597]	Time 4.987 (6.933)	Data 4.924 (6.851)	Loss 4.5260 (5.0640)	Acc 0.000 (0.016)
Epoch: [1][519/597]	Time 8.073 (6.935)	Data 8.010 (6.853)	Loss 4.3622 (5.0627)	Acc 0.062 (0.016)
Epoch: [1][520/597]	Time 4.737 (6.931)	Data 4.672 (6.849)	Loss 4.2131 (5.0610)	Acc 0.062 (0.016)
Epoch: [1][521/597]	Time 8.203 (6.933)	Data 8.140 (6.852)	Loss 4.1992 (5.0594)	Acc 0.000 (0.016)
Epoch: [1][522/597]	Time 5.165 (6.930)	Data 5.097 (6.848)	Loss 4.5873 (5.0585)	Acc 0.000 (0.016)
Epoch: [1][523/597]	Time 8.348 (6.933)	Data 8.283 (6.851)	Loss 4.6900 (5.0578)	Acc 0.000 (0.016)
Epoch: [1][524/597]	Time 5.407 (6.930)	Data 5.344 (6.848)	Loss 4.0835 (5.0559)	Acc 0.062 (0.016)
Epoch: [1][525/597]	Time 8.462 (6.933)	Data 8.395 (6.851)	Loss 3.8907 (5.0537)	Acc 0.125 (0.016)
Epoch: [1][526/597]	Time 4.168 (6.927)	Data 4.105 (6.846)	Loss 4.4218 (5.0525)	Acc 0.000 (0.016)
Epoch: [1][527/597]	Time 8.767 (6.931)	Data 8.700 (6.849)	Loss 4.4972 (5.0514)	Acc 0.000 (0.016)
Epoch: [1][528/597]	Time 5.152 (6.927)	Data 5.081 (6.846)	Loss 4.1641 (5.0498)	Acc 0.062 (0.016)
Epoch: [1][529/597]	Time 9.553 (6.932)	Data 9.431 (6.851)	Loss 4.2096 (5.0482)	Acc 0.062 (0.016)
Epoch: [1][530/597]	Time 3.892 (6.927)	Data 3.828 (6.845)	Loss 3.9146 (5.0460)	Acc 0.062 (0.016)
Epoch: [1][531/597]	Time 10.298 (6.933)	Data 10.233 (6.852)	Loss 4.3025 (5.0446)	Acc 0.062 (0.016)
Epoch: [1][532/597]	Time 4.175 (6.928)	Data 4.098 (6.846)	Loss 4.6558 (5.0439)	Acc 0.000 (0.016)
Epoch: [1][533/597]	Time 9.996 (6.934)	Data 9.930 (6.852)	Loss 4.7706 (5.0434)	Acc 0.000 (0.016)
Epoch: [1][534/597]	Time 4.234 (6.929)	Data 4.149 (6.847)	Loss 4.2272 (5.0419)	Acc 0.000 (0.016)
Epoch: [1][535/597]	Time 9.053 (6.932)	Data 8.990 (6.851)	Loss 4.3197 (5.0405)	Acc 0.000 (0.016)
Epoch: [1][536/597]	Time 4.425 (6.928)	Data 4.359 (6.847)	Loss 4.7321 (5.0399)	Acc 0.000 (0.016)
Epoch: [1][537/597]	Time 10.361 (6.934)	Data 10.285 (6.853)	Loss 4.4415 (5.0388)	Acc 0.125 (0.016)
Epoch: [1][538/597]	Time 3.746 (6.928)	Data 3.682 (6.847)	Loss 4.5621 (5.0379)	Acc 0.000 (0.016)
Epoch: [1][539/597]	Time 9.722 (6.933)	Data 9.658 (6.852)	Loss 4.3179 (5.0366)	Acc 0.000 (0.016)
Epoch: [1][540/597]	Time 3.516 (6.927)	Data 3.454 (6.846)	Loss 4.5918 (5.0358)	Acc 0.000 (0.016)
Epoch: [1][541/597]	Time 9.847 (6.933)	Data 9.781 (6.851)	Loss 4.4107 (5.0346)	Acc 0.000 (0.016)
Epoch: [1][542/597]	Time 3.719 (6.927)	Data 3.657 (6.845)	Loss 4.5256 (5.0337)	Acc 0.000 (0.016)
Epoch: [1][543/597]	Time 10.792 (6.934)	Data 10.727 (6.853)	Loss 4.7881 (5.0332)	Acc 0.000 (0.016)
Epoch: [1][544/597]	Time 3.471 (6.927)	Data 3.408 (6.846)	Loss 5.3393 (5.0338)	Acc 0.000 (0.016)
Epoch: [1][545/597]	Time 10.170 (6.933)	Data 10.107 (6.852)	Loss 4.4300 (5.0327)	Acc 0.125 (0.016)
Epoch: [1][546/597]	Time 2.528 (6.925)	Data 2.465 (6.844)	Loss 4.8065 (5.0323)	Acc 0.062 (0.016)
Epoch: [1][547/597]	Time 10.622 (6.932)	Data 10.558 (6.851)	Loss 4.5750 (5.0314)	Acc 0.000 (0.016)
Epoch: [1][548/597]	Time 1.928 (6.923)	Data 1.869 (6.842)	Loss 4.3878 (5.0303)	Acc 0.125 (0.017)
Epoch: [1][549/597]	Time 10.988 (6.930)	Data 10.921 (6.849)	Loss 4.7671 (5.0298)	Acc 0.000 (0.017)
Epoch: [1][550/597]	Time 2.322 (6.922)	Data 2.256 (6.841)	Loss 4.7797 (5.0293)	Acc 0.000 (0.016)
Epoch: [1][551/597]	Time 11.360 (6.930)	Data 11.282 (6.849)	Loss 4.4175 (5.0282)	Acc 0.000 (0.016)
Epoch: [1][552/597]	Time 2.559 (6.922)	Data 2.496 (6.841)	Loss 4.5667 (5.0274)	Acc 0.000 (0.016)
Epoch: [1][553/597]	Time 11.468 (6.930)	Data 11.404 (6.849)	Loss 4.5187 (5.0265)	Acc 0.000 (0.016)
Epoch: [1][554/597]	Time 1.638 (6.921)	Data 1.577 (6.840)	Loss 4.5714 (5.0256)	Acc 0.000 (0.016)
Epoch: [1][555/597]	Time 12.256 (6.930)	Data 12.191 (6.850)	Loss 4.7956 (5.0252)	Acc 0.000 (0.016)
Epoch: [1][556/597]	Time 1.317 (6.920)	Data 1.253 (6.839)	Loss 4.4454 (5.0242)	Acc 0.125 (0.017)
Epoch: [1][557/597]	Time 12.559 (6.930)	Data 12.492 (6.850)	Loss 4.4664 (5.0232)	Acc 0.000 (0.016)
Epoch: [1][558/597]	Time 1.913 (6.921)	Data 1.850 (6.841)	Loss 4.8006 (5.0228)	Acc 0.000 (0.016)
Epoch: [1][559/597]	Time 12.805 (6.932)	Data 12.740 (6.851)	Loss 4.4538 (5.0218)	Acc 0.000 (0.016)
Epoch: [1][560/597]	Time 1.250 (6.922)	Data 1.188 (6.841)	Loss 4.3634 (5.0206)	Acc 0.062 (0.017)
Epoch: [1][561/597]	Time 14.266 (6.935)	Data 14.202 (6.854)	Loss 4.5031 (5.0197)	Acc 0.000 (0.016)
Epoch: [1][562/597]	Time 0.865 (6.924)	Data 0.790 (6.843)	Loss 4.5307 (5.0188)	Acc 0.000 (0.016)
Epoch: [1][563/597]	Time 13.010 (6.935)	Data 12.944 (6.854)	Loss 4.3576 (5.0176)	Acc 0.000 (0.016)
Epoch: [1][564/597]	Time 1.337 (6.925)	Data 1.278 (6.844)	Loss 4.4739 (5.0167)	Acc 0.000 (0.016)
Epoch: [1][565/597]	Time 12.068 (6.934)	Data 12.006 (6.854)	Loss 4.5003 (5.0157)	Acc 0.062 (0.016)
Epoch: [1][566/597]	Time 1.841 (6.925)	Data 1.773 (6.845)	Loss 4.8042 (5.0154)	Acc 0.000 (0.016)
Epoch: [1][567/597]	Time 12.173 (6.934)	Data 12.101 (6.854)	Loss 4.5096 (5.0145)	Acc 0.000 (0.016)
Epoch: [1][568/597]	Time 1.654 (6.925)	Data 1.534 (6.844)	Loss 4.4004 (5.0134)	Acc 0.062 (0.017)
Epoch: [1][569/597]	Time 13.269 (6.936)	Data 13.206 (6.856)	Loss 4.4207 (5.0124)	Acc 0.000 (0.016)
Epoch: [1][570/597]	Time 1.599 (6.927)	Data 1.535 (6.846)	Loss 4.4137 (5.0113)	Acc 0.000 (0.016)
Epoch: [1][571/597]	Time 12.152 (6.936)	Data 12.084 (6.855)	Loss 4.2511 (5.0100)	Acc 0.062 (0.017)
Epoch: [1][572/597]	Time 1.718 (6.927)	Data 1.655 (6.846)	Loss 4.7377 (5.0095)	Acc 0.000 (0.016)
Epoch: [1][573/597]	Time 11.597 (6.935)	Data 11.534 (6.855)	Loss 4.5463 (5.0087)	Acc 0.000 (0.016)
Epoch: [1][574/597]	Time 2.570 (6.927)	Data 2.508 (6.847)	Loss 4.4317 (5.0077)	Acc 0.000 (0.016)
Epoch: [1][575/597]	Time 10.712 (6.934)	Data 10.648 (6.854)	Loss 4.5294 (5.0069)	Acc 0.000 (0.016)
Epoch: [1][576/597]	Time 2.577 (6.926)	Data 2.509 (6.846)	Loss 4.5701 (5.0061)	Acc 0.000 (0.016)
Epoch: [1][577/597]	Time 11.399 (6.934)	Data 11.336 (6.854)	Loss 4.2155 (5.0047)	Acc 0.062 (0.016)
Epoch: [1][578/597]	Time 2.632 (6.927)	Data 2.569 (6.846)	Loss 4.2993 (5.0035)	Acc 0.062 (0.017)
Epoch: [1][579/597]	Time 11.537 (6.935)	Data 11.471 (6.854)	Loss 4.3858 (5.0024)	Acc 0.000 (0.017)
Epoch: [1][580/597]	Time 2.137 (6.926)	Data 2.072 (6.846)	Loss 4.3902 (5.0014)	Acc 0.062 (0.017)
Epoch: [1][581/597]	Time 11.154 (6.934)	Data 11.089 (6.853)	Loss 4.9427 (5.0013)	Acc 0.000 (0.017)
Epoch: [1][582/597]	Time 2.629 (6.926)	Data 2.548 (6.846)	Loss 4.2685 (5.0000)	Acc 0.062 (0.017)
Epoch: [1][583/597]	Time 11.231 (6.934)	Data 11.159 (6.853)	Loss 4.1267 (4.9985)	Acc 0.125 (0.017)
Epoch: [1][584/597]	Time 2.681 (6.926)	Data 2.615 (6.846)	Loss 4.1421 (4.9971)	Acc 0.062 (0.017)
Epoch: [1][585/597]	Time 11.606 (6.934)	Data 11.531 (6.854)	Loss 4.5906 (4.9964)	Acc 0.000 (0.017)
Epoch: [1][586/597]	Time 2.703 (6.927)	Data 2.638 (6.847)	Loss 4.3223 (4.9952)	Acc 0.062 (0.017)
Epoch: [1][587/597]	Time 11.210 (6.934)	Data 11.146 (6.854)	Loss 4.4227 (4.9942)	Acc 0.000 (0.017)
Epoch: [1][588/597]	Time 2.726 (6.927)	Data 2.661 (6.847)	Loss 4.4342 (4.9933)	Acc 0.000 (0.017)
Epoch: [1][589/597]	Time 10.883 (6.934)	Data 10.817 (6.854)	Loss 4.5069 (4.9925)	Acc 0.000 (0.017)
Epoch: [1][590/597]	Time 3.416 (6.928)	Data 3.353 (6.848)	Loss 4.5501 (4.9917)	Acc 0.000 (0.017)
Epoch: [1][591/597]	Time 10.695 (6.934)	Data 10.632 (6.854)	Loss 4.2077 (4.9904)	Acc 0.000 (0.017)
Epoch: [1][592/597]	Time 3.537 (6.929)	Data 3.473 (6.849)	Loss 4.5347 (4.9896)	Acc 0.062 (0.017)
Epoch: [1][593/597]	Time 10.575 (6.935)	Data 10.510 (6.855)	Loss 4.2329 (4.9883)	Acc 0.000 (0.017)
Epoch: [1][594/597]	Time 3.833 (6.930)	Data 3.768 (6.850)	Loss 4.3243 (4.9872)	Acc 0.000 (0.017)
Epoch: [1][595/597]	Time 10.146 (6.935)	Data 10.083 (6.855)	Loss 4.3530 (4.9862)	Acc 0.062 (0.017)
Epoch: [1][596/597]	Time 3.675 (6.929)	Data 3.614 (6.850)	Loss 4.1263 (4.9847)	Acc 0.062 (0.017)
Epoch: [1][597/597]	Time 0.796 (6.919)	Data 0.000 (6.838)	Loss 4.5775 (4.9847)	Acc 0.000 (0.017)
validation at epoch 1
Traceback (most recent call last):
  File "main.py", line 433, in <module>
    main_worker(-1, opt)
  File "main.py", line 400, in main_worker
    prev_val_loss = val_epoch(i, val_loader, model, criterion,
  File "/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/validation.py", line 34, in val_epoch
    targets = targets.to(device, non_blocking=True)
AttributeError: 'list' object has no attribute 'to'
srun: error: influ3: task 0: Exited with exit code 1
