Namespace(accimage=False, annotation_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/UCF-101/json_annotations/ucf101_01.json'), arch='resnet-50', batch_size=16, batchnorm_sync=False, begin_epoch=1, checkpoint=5, colorjitter=False, conv1_t_size=7, conv1_t_stride=1, dampening=0.0, dataset='ucf101', dist_url='tcp://127.0.0.1:23456', distributed=False, file_type='jpg', ft_begin_module='', inference=False, inference_batch_size=16, inference_crop='center', inference_no_average=False, inference_stride=16, inference_subset='val', input_type='rgb', learning_rate=0.01, lr_scheduler='multistep', manual_seed=1, mean=[0.4345, 0.4051, 0.3775], mean_dataset='kinetics', model='resnet', model_depth=50, momentum=0.9, multistep_milestones=[40], n_classes=700, n_epochs=80, n_finetune_classes=101, n_input_channels=3, n_pretrain_classes=700, n_threads=4, n_val_samples=3, nesterov=False, no_cuda=False, no_hflip=False, no_max_pool=False, no_mean_norm=False, no_std_norm=False, no_train=False, no_val=False, optimizer='sgd', output_topk=5, overwrite_milestones=False, plateau_patience=10, pretrain_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/pretrained_models/r3d50_K_200ep.pth'), receptive_size=9, resnet_shortcut='B', resnet_widen_factor=1.0, resnext_cardinality=32, result_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/results/UCF101_kinetics_pretrained'), resume_path=None, root_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff'), sample_duration=48, sample_size=64, sample_t_stride=1, std=[0.2768, 0.2713, 0.2737], tensorboard=True, train_crop='random', train_crop_min_ratio=0.75, train_crop_min_scale=0.25, train_t_crop='random', value_scale=1, video_path=PosixPath('/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/UCF-101/jpg'), weight_decay=0.001, wide_resnet_k=2, world_size=-1)
loading pretrained model /tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/pretrained_models/r3d50_K_200ep.pth
DataParallel(
  (module): ResNet(
    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)
    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)
          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))
    (fc): Linear(in_features=2048, out_features=101, bias=True)
  )
)
random
random
Building VideoDataset for UCF-101.
Compose(
    RandomResizedCrop(size=(64, 64), scale=(0.25, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    <spatial_transforms.ScaleValue object at 0x7f115003f310>
    Normalize(mean=[0.4345, 0.4051, 0.3775], std=[0.2768, 0.2713, 0.2737])
)
<temporal_transforms.Compose object at 0x7f1150034f70>
<datasets.loader.VideoLoader object at 0x7f1150034e50>
dataset loading [0/9537]
dataset loading [1907/9537]
dataset loading [3814/9537]
dataset loading [5721/9537]
dataset loading [7628/9537]
dataset loading [9535/9537]
VideoDataset temporal_transform <temporal_transforms.Compose object at 0x7f1150034f70>
dataset loading [0/3783]
dataset loading [756/3783]
dataset loading [1512/3783]
dataset loading [2268/3783]
dataset loading [3024/3783]
dataset loading [3780/3783]
VideoDataset temporal_transform <temporal_transforms.Compose object at 0x7f115003f1f0>
train at epoch 1
Epoch: [1][1/597]	Time 21.034 (21.034)	Data 13.824 (13.824)	Loss 4.7018 (4.7018)	Acc 0.000 (0.000)
Epoch: [1][2/597]	Time 0.220 (10.627)	Data 0.000 (6.912)	Loss 4.7051 (4.7034)	Acc 0.000 (0.000)
Epoch: [1][3/597]	Time 0.147 (7.134)	Data 0.000 (4.608)	Loss 4.7333 (4.7134)	Acc 0.000 (0.000)
Epoch: [1][4/597]	Time 0.198 (5.400)	Data 0.000 (3.456)	Loss 4.8100 (4.7376)	Acc 0.062 (0.016)
Epoch: [1][5/597]	Time 6.815 (5.683)	Data 6.687 (4.102)	Loss 4.5556 (4.7012)	Acc 0.000 (0.013)
Epoch: [1][6/597]	Time 0.228 (4.774)	Data 0.000 (3.419)	Loss 4.6705 (4.6961)	Acc 0.062 (0.021)
Epoch: [1][7/597]	Time 0.193 (4.119)	Data 0.000 (2.930)	Loss 4.9428 (4.7313)	Acc 0.000 (0.018)
Epoch: [1][8/597]	Time 0.194 (3.629)	Data 0.000 (2.564)	Loss 5.0948 (4.7767)	Acc 0.000 (0.016)
Epoch: [1][9/597]	Time 12.126 (4.573)	Data 11.970 (3.609)	Loss 5.0625 (4.8085)	Acc 0.062 (0.021)
Epoch: [1][10/597]	Time 0.288 (4.144)	Data 0.173 (3.265)	Loss 4.8710 (4.8147)	Acc 0.000 (0.019)
Epoch: [1][11/597]	Time 0.681 (3.830)	Data 0.565 (3.020)	Loss 5.4586 (4.8733)	Acc 0.000 (0.017)
Epoch: [1][12/597]	Time 0.241 (3.530)	Data 0.000 (2.768)	Loss 4.9621 (4.8807)	Acc 0.000 (0.016)
Epoch: [1][13/597]	Time 12.348 (4.209)	Data 12.204 (3.494)	Loss 4.6976 (4.8666)	Acc 0.062 (0.019)
Epoch: [1][14/597]	Time 0.536 (3.946)	Data 0.398 (3.273)	Loss 4.6367 (4.8502)	Acc 0.125 (0.027)
Epoch: [1][15/597]	Time 0.201 (3.697)	Data 0.000 (3.055)	Loss 4.7165 (4.8413)	Acc 0.188 (0.037)
Epoch: [1][16/597]	Time 0.197 (3.478)	Data 0.000 (2.864)	Loss 4.3617 (4.8113)	Acc 0.062 (0.039)
Epoch: [1][17/597]	Time 12.534 (4.011)	Data 12.421 (3.426)	Loss 4.7967 (4.8104)	Acc 0.000 (0.037)
Epoch: [1][18/597]	Time 0.201 (3.799)	Data 0.000 (3.236)	Loss 4.4521 (4.7905)	Acc 0.062 (0.038)
Epoch: [1][19/597]	Time 0.316 (3.616)	Data 0.186 (3.075)	Loss 4.1941 (4.7591)	Acc 0.125 (0.043)
Epoch: [1][20/597]	Time 0.225 (3.446)	Data 0.000 (2.922)	Loss 4.7239 (4.7574)	Acc 0.000 (0.041)
Epoch: [1][21/597]	Time 12.977 (3.900)	Data 12.825 (3.393)	Loss 4.8068 (4.7597)	Acc 0.000 (0.039)
Epoch: [1][22/597]	Time 0.304 (3.737)	Data 0.185 (3.247)	Loss 4.4921 (4.7476)	Acc 0.062 (0.040)
Epoch: [1][23/597]	Time 0.201 (3.583)	Data 0.000 (3.106)	Loss 3.9475 (4.7128)	Acc 0.125 (0.043)
Epoch: [1][24/597]	Time 0.198 (3.442)	Data 0.000 (2.977)	Loss 3.8230 (4.6757)	Acc 0.188 (0.049)
Epoch: [1][25/597]	Time 12.230 (3.793)	Data 12.116 (3.342)	Loss 4.0010 (4.6487)	Acc 0.188 (0.055)
Epoch: [1][26/597]	Time 0.199 (3.655)	Data 0.000 (3.214)	Loss 3.8924 (4.6196)	Acc 0.312 (0.065)
Epoch: [1][27/597]	Time 0.200 (3.527)	Data 0.000 (3.095)	Loss 4.1681 (4.6029)	Acc 0.062 (0.065)
Epoch: [1][28/597]	Time 0.360 (3.414)	Data 0.238 (2.993)	Loss 4.5009 (4.5993)	Acc 0.125 (0.067)
Epoch: [1][29/597]	Time 11.779 (3.702)	Data 11.656 (3.291)	Loss 4.4642 (4.5946)	Acc 0.062 (0.067)
Epoch: [1][30/597]	Time 0.780 (3.605)	Data 0.662 (3.204)	Loss 5.3838 (4.6209)	Acc 0.000 (0.065)
Epoch: [1][31/597]	Time 0.838 (3.516)	Data 0.722 (3.124)	Loss 4.3909 (4.6135)	Acc 0.125 (0.067)
Epoch: [1][32/597]	Time 0.824 (3.432)	Data 0.709 (3.048)	Loss 3.9079 (4.5914)	Acc 0.188 (0.070)
Epoch: [1][33/597]	Time 11.831 (3.686)	Data 11.701 (3.310)	Loss 4.5575 (4.5904)	Acc 0.188 (0.074)
Epoch: [1][34/597]	Time 0.294 (3.586)	Data 0.173 (3.218)	Loss 4.1682 (4.5780)	Acc 0.250 (0.079)
Epoch: [1][35/597]	Time 1.018 (3.513)	Data 0.900 (3.152)	Loss 4.5427 (4.5770)	Acc 0.125 (0.080)
Epoch: [1][36/597]	Time 1.166 (3.448)	Data 1.050 (3.094)	Loss 4.0447 (4.5622)	Acc 0.188 (0.083)
Epoch: [1][37/597]	Time 11.029 (3.653)	Data 10.913 (3.305)	Loss 4.3573 (4.5567)	Acc 0.188 (0.086)
Epoch: [1][38/597]	Time 0.203 (3.562)	Data 0.000 (3.218)	Loss 4.5042 (4.5553)	Acc 0.125 (0.087)
Epoch: [1][39/597]	Time 0.992 (3.496)	Data 0.875 (3.158)	Loss 2.9976 (4.5153)	Acc 0.375 (0.095)
Epoch: [1][40/597]	Time 0.585 (3.423)	Data 0.470 (3.091)	Loss 3.9501 (4.5012)	Acc 0.250 (0.098)
Epoch: [1][41/597]	Time 11.334 (3.616)	Data 11.206 (3.289)	Loss 3.2799 (4.4714)	Acc 0.062 (0.098)
Epoch: [1][42/597]	Time 0.199 (3.535)	Data 0.000 (3.210)	Loss 3.3506 (4.4447)	Acc 0.375 (0.104)
Epoch: [1][43/597]	Time 0.201 (3.457)	Data 0.000 (3.136)	Loss 3.4182 (4.4209)	Acc 0.250 (0.108)
Epoch: [1][44/597]	Time 1.713 (3.418)	Data 1.598 (3.101)	Loss 3.6522 (4.4034)	Acc 0.375 (0.114)
Epoch: [1][45/597]	Time 10.840 (3.583)	Data 10.723 (3.270)	Loss 3.6225 (4.3860)	Acc 0.312 (0.118)
Epoch: [1][46/597]	Time 0.210 (3.509)	Data 0.000 (3.199)	Loss 4.0896 (4.3796)	Acc 0.188 (0.120)
Epoch: [1][47/597]	Time 0.207 (3.439)	Data 0.000 (3.131)	Loss 4.1863 (4.3755)	Acc 0.125 (0.120)
Epoch: [1][48/597]	Time 1.517 (3.399)	Data 1.399 (3.095)	Loss 3.6706 (4.3608)	Acc 0.125 (0.120)
Epoch: [1][49/597]	Time 10.793 (3.550)	Data 10.664 (3.249)	Loss 3.5922 (4.3451)	Acc 0.188 (0.121)
Epoch: [1][50/597]	Time 0.215 (3.483)	Data 0.000 (3.184)	Loss 3.1507 (4.3212)	Acc 0.188 (0.122)
Epoch: [1][51/597]	Time 0.195 (3.419)	Data 0.000 (3.122)	Loss 3.3403 (4.3020)	Acc 0.188 (0.124)
Epoch: [1][52/597]	Time 0.994 (3.372)	Data 0.876 (3.079)	Loss 3.4067 (4.2848)	Acc 0.250 (0.126)
Epoch: [1][53/597]	Time 11.683 (3.529)	Data 11.568 (3.239)	Loss 3.1498 (4.2634)	Acc 0.250 (0.129)
Epoch: [1][54/597]	Time 0.219 (3.468)	Data 0.000 (3.179)	Loss 3.9375 (4.2573)	Acc 0.125 (0.128)
Epoch: [1][55/597]	Time 0.192 (3.408)	Data 0.043 (3.122)	Loss 2.9676 (4.2339)	Acc 0.375 (0.133)
Epoch: [1][56/597]	Time 1.463 (3.373)	Data 1.328 (3.090)	Loss 4.8406 (4.2447)	Acc 0.125 (0.133)
Epoch: [1][57/597]	Time 11.604 (3.518)	Data 11.478 (3.237)	Loss 3.9542 (4.2396)	Acc 0.125 (0.133)
Epoch: [1][58/597]	Time 0.227 (3.461)	Data 0.000 (3.181)	Loss 4.3362 (4.2413)	Acc 0.125 (0.133)
Epoch: [1][59/597]	Time 0.202 (3.406)	Data 0.000 (3.127)	Loss 3.9561 (4.2364)	Acc 0.188 (0.133)
Epoch: [1][60/597]	Time 2.078 (3.384)	Data 1.952 (3.108)	Loss 4.1869 (4.2356)	Acc 0.188 (0.134)
Epoch: [1][61/597]	Time 10.651 (3.503)	Data 10.519 (3.229)	Loss 5.7534 (4.2605)	Acc 0.000 (0.132)
Epoch: [1][62/597]	Time 0.219 (3.450)	Data 0.000 (3.177)	Loss 3.6215 (4.2502)	Acc 0.188 (0.133)
Epoch: [1][63/597]	Time 0.534 (3.404)	Data 0.400 (3.133)	Loss 2.9261 (4.2292)	Acc 0.375 (0.137)
Epoch: [1][64/597]	Time 2.687 (3.392)	Data 2.550 (3.124)	Loss 4.2721 (4.2298)	Acc 0.062 (0.136)
Epoch: [1][65/597]	Time 9.692 (3.489)	Data 9.577 (3.223)	Loss 3.7331 (4.2222)	Acc 0.125 (0.136)
Epoch: [1][66/597]	Time 0.201 (3.439)	Data 0.000 (3.174)	Loss 4.1312 (4.2208)	Acc 0.188 (0.136)
Epoch: [1][67/597]	Time 0.590 (3.397)	Data 0.457 (3.134)	Loss 3.3612 (4.2080)	Acc 0.125 (0.136)
Epoch: [1][68/597]	Time 2.702 (3.387)	Data 2.585 (3.126)	Loss 4.1755 (4.2075)	Acc 0.125 (0.136)
Epoch: [1][69/597]	Time 8.918 (3.467)	Data 8.793 (3.208)	Loss 4.3640 (4.2098)	Acc 0.062 (0.135)
Epoch: [1][70/597]	Time 0.454 (3.424)	Data 0.334 (3.167)	Loss 4.0462 (4.2074)	Acc 0.125 (0.135)
Epoch: [1][71/597]	Time 1.189 (3.392)	Data 1.053 (3.137)	Loss 3.6153 (4.1991)	Acc 0.250 (0.136)
Epoch: [1][72/597]	Time 2.777 (3.384)	Data 2.659 (3.130)	Loss 3.1114 (4.1840)	Acc 0.062 (0.135)
Epoch: [1][73/597]	Time 8.245 (3.450)	Data 8.111 (3.199)	Loss 3.9473 (4.1808)	Acc 0.188 (0.136)
Epoch: [1][74/597]	Time 0.677 (3.413)	Data 0.553 (3.163)	Loss 3.3128 (4.1690)	Acc 0.188 (0.137)
Epoch: [1][75/597]	Time 0.797 (3.378)	Data 0.679 (3.130)	Loss 3.2245 (4.1564)	Acc 0.188 (0.138)
Epoch: [1][76/597]	Time 3.998 (3.386)	Data 3.870 (3.140)	Loss 3.3218 (4.1455)	Acc 0.312 (0.140)
Epoch: [1][77/597]	Time 7.945 (3.445)	Data 7.819 (3.200)	Loss 3.4493 (4.1364)	Acc 0.188 (0.140)
Epoch: [1][78/597]	Time 0.501 (3.408)	Data 0.389 (3.164)	Loss 3.6791 (4.1305)	Acc 0.125 (0.140)
Epoch: [1][79/597]	Time 0.895 (3.376)	Data 0.769 (3.134)	Loss 3.5691 (4.1234)	Acc 0.312 (0.142)
Epoch: [1][80/597]	Time 3.085 (3.372)	Data 2.959 (3.132)	Loss 4.0637 (4.1227)	Acc 0.188 (0.143)
Epoch: [1][81/597]	Time 8.024 (3.430)	Data 7.909 (3.191)	Loss 3.8716 (4.1196)	Acc 0.062 (0.142)
Epoch: [1][82/597]	Time 0.710 (3.396)	Data 0.587 (3.159)	Loss 4.6140 (4.1256)	Acc 0.062 (0.141)
Epoch: [1][83/597]	Time 0.761 (3.365)	Data 0.631 (3.129)	Loss 4.8558 (4.1344)	Acc 0.000 (0.139)
Epoch: [1][84/597]	Time 3.344 (3.364)	Data 3.228 (3.130)	Loss 3.3261 (4.1248)	Acc 0.188 (0.140)
Epoch: [1][85/597]	Time 8.393 (3.424)	Data 8.225 (3.190)	Loss 3.7359 (4.1202)	Acc 0.250 (0.141)
Epoch: [1][86/597]	Time 0.217 (3.386)	Data 0.000 (3.153)	Loss 3.3298 (4.1110)	Acc 0.250 (0.142)
Epoch: [1][87/597]	Time 0.190 (3.350)	Data 0.074 (3.117)	Loss 3.8436 (4.1080)	Acc 0.125 (0.142)
Epoch: [1][88/597]	Time 5.052 (3.369)	Data 4.916 (3.138)	Loss 3.2183 (4.0979)	Acc 0.312 (0.144)
Epoch: [1][89/597]	Time 6.504 (3.404)	Data 6.380 (3.174)	Loss 4.2097 (4.0991)	Acc 0.125 (0.144)
Epoch: [1][90/597]	Time 1.111 (3.379)	Data 0.991 (3.150)	Loss 4.1502 (4.0997)	Acc 0.062 (0.143)
Epoch: [1][91/597]	Time 0.322 (3.345)	Data 0.191 (3.117)	Loss 3.8582 (4.0970)	Acc 0.125 (0.143)
Epoch: [1][92/597]	Time 4.760 (3.360)	Data 4.641 (3.134)	Loss 3.8396 (4.0942)	Acc 0.250 (0.144)
Epoch: [1][93/597]	Time 6.898 (3.399)	Data 6.773 (3.173)	Loss 4.0530 (4.0938)	Acc 0.125 (0.144)
Epoch: [1][94/597]	Time 0.963 (3.373)	Data 0.844 (3.148)	Loss 3.4510 (4.0869)	Acc 0.125 (0.144)
Epoch: [1][95/597]	Time 0.474 (3.342)	Data 0.339 (3.119)	Loss 4.1524 (4.0876)	Acc 0.188 (0.144)
Epoch: [1][96/597]	Time 4.179 (3.351)	Data 4.040 (3.128)	Loss 3.6096 (4.0827)	Acc 0.188 (0.145)
Epoch: [1][97/597]	Time 9.065 (3.410)	Data 8.950 (3.188)	Loss 2.8251 (4.0697)	Acc 0.250 (0.146)
Epoch: [1][98/597]	Time 0.235 (3.377)	Data 0.000 (3.156)	Loss 3.2119 (4.0609)	Acc 0.312 (0.147)
Epoch: [1][99/597]	Time 0.299 (3.346)	Data 0.181 (3.126)	Loss 3.3963 (4.0542)	Acc 0.188 (0.148)
Epoch: [1][100/597]	Time 3.982 (3.353)	Data 3.859 (3.133)	Loss 3.0185 (4.0439)	Acc 0.312 (0.149)
Epoch: [1][101/597]	Time 9.358 (3.412)	Data 9.242 (3.193)	Loss 4.4051 (4.0474)	Acc 0.062 (0.149)
Epoch: [1][102/597]	Time 0.194 (3.380)	Data 0.000 (3.162)	Loss 3.3607 (4.0407)	Acc 0.312 (0.150)
Epoch: [1][103/597]	Time 0.200 (3.350)	Data 0.000 (3.131)	Loss 2.6533 (4.0272)	Acc 0.312 (0.152)
Epoch: [1][104/597]	Time 4.113 (3.357)	Data 3.977 (3.140)	Loss 3.3344 (4.0206)	Acc 0.188 (0.152)
Epoch: [1][105/597]	Time 9.018 (3.411)	Data 8.890 (3.194)	Loss 3.8118 (4.0186)	Acc 0.250 (0.153)
Epoch: [1][106/597]	Time 0.212 (3.381)	Data 0.000 (3.164)	Loss 3.2524 (4.0114)	Acc 0.312 (0.154)
Epoch: [1][107/597]	Time 0.205 (3.351)	Data 0.000 (3.135)	Loss 4.5348 (4.0162)	Acc 0.125 (0.154)
Epoch: [1][108/597]	Time 3.954 (3.357)	Data 3.838 (3.141)	Loss 3.3245 (4.0098)	Acc 0.250 (0.155)
Epoch: [1][109/597]	Time 8.917 (3.408)	Data 8.800 (3.193)	Loss 3.7027 (4.0070)	Acc 0.250 (0.156)
Epoch: [1][110/597]	Time 0.218 (3.379)	Data 0.000 (3.164)	Loss 4.7496 (4.0138)	Acc 0.000 (0.155)
Epoch: [1][111/597]	Time 0.187 (3.350)	Data 0.000 (3.136)	Loss 3.4533 (4.0087)	Acc 0.125 (0.154)
Epoch: [1][112/597]	Time 3.473 (3.351)	Data 3.347 (3.137)	Loss 3.5721 (4.0048)	Acc 0.188 (0.155)
Epoch: [1][113/597]	Time 9.686 (3.407)	Data 9.562 (3.194)	Loss 3.4641 (4.0000)	Acc 0.062 (0.154)
Epoch: [1][114/597]	Time 0.224 (3.379)	Data 0.000 (3.166)	Loss 3.4759 (3.9954)	Acc 0.188 (0.154)
Epoch: [1][115/597]	Time 0.207 (3.352)	Data 0.000 (3.139)	Loss 3.3607 (3.9899)	Acc 0.188 (0.154)
Epoch: [1][116/597]	Time 2.859 (3.347)	Data 2.743 (3.135)	Loss 3.0837 (3.9821)	Acc 0.250 (0.155)
Epoch: [1][117/597]	Time 10.142 (3.405)	Data 10.016 (3.194)	Loss 3.8202 (3.9807)	Acc 0.188 (0.155)
Epoch: [1][118/597]	Time 0.270 (3.379)	Data 0.000 (3.167)	Loss 3.5780 (3.9773)	Acc 0.250 (0.156)
Epoch: [1][119/597]	Time 0.163 (3.352)	Data 0.000 (3.140)	Loss 3.4436 (3.9728)	Acc 0.250 (0.157)
Epoch: [1][120/597]	Time 2.466 (3.344)	Data 2.350 (3.134)	Loss 4.1971 (3.9747)	Acc 0.125 (0.157)
Epoch: [1][121/597]	Time 10.845 (3.406)	Data 10.710 (3.196)	Loss 3.6351 (3.9719)	Acc 0.125 (0.157)
Epoch: [1][122/597]	Time 0.191 (3.380)	Data 0.000 (3.170)	Loss 3.1560 (3.9652)	Acc 0.125 (0.156)
Epoch: [1][123/597]	Time 0.208 (3.354)	Data 0.000 (3.145)	Loss 3.9067 (3.9647)	Acc 0.000 (0.155)
Epoch: [1][124/597]	Time 2.298 (3.346)	Data 2.166 (3.137)	Loss 2.7098 (3.9546)	Acc 0.312 (0.156)
Epoch: [1][125/597]	Time 10.023 (3.399)	Data 9.902 (3.191)	Loss 4.4419 (3.9585)	Acc 0.188 (0.157)
Epoch: [1][126/597]	Time 0.218 (3.374)	Data 0.000 (3.165)	Loss 4.1837 (3.9603)	Acc 0.125 (0.156)
Epoch: [1][127/597]	Time 0.194 (3.349)	Data 0.000 (3.140)	Loss 4.2389 (3.9625)	Acc 0.312 (0.157)
Epoch: [1][128/597]	Time 3.215 (3.348)	Data 3.093 (3.140)	Loss 3.4580 (3.9585)	Acc 0.188 (0.158)
Epoch: [1][129/597]	Time 10.605 (3.404)	Data 10.484 (3.197)	Loss 3.4146 (3.9543)	Acc 0.125 (0.157)
Epoch: [1][130/597]	Time 0.190 (3.379)	Data 0.000 (3.172)	Loss 4.5214 (3.9587)	Acc 0.125 (0.157)
Epoch: [1][131/597]	Time 0.202 (3.355)	Data 0.000 (3.148)	Loss 3.0399 (3.9517)	Acc 0.188 (0.157)
Epoch: [1][132/597]	Time 2.470 (3.348)	Data 2.357 (3.142)	Loss 3.8540 (3.9509)	Acc 0.250 (0.158)
Epoch: [1][133/597]	Time 11.229 (3.408)	Data 11.103 (3.202)	Loss 3.8477 (3.9502)	Acc 0.188 (0.158)
Epoch: [1][134/597]	Time 0.227 (3.384)	Data 0.002 (3.178)	Loss 4.3557 (3.9532)	Acc 0.125 (0.158)
Epoch: [1][135/597]	Time 0.215 (3.360)	Data 0.000 (3.155)	Loss 3.2405 (3.9479)	Acc 0.188 (0.158)
Epoch: [1][136/597]	Time 2.158 (3.352)	Data 2.040 (3.146)	Loss 3.4440 (3.9442)	Acc 0.188 (0.159)
Epoch: [1][137/597]	Time 11.792 (3.413)	Data 11.676 (3.209)	Loss 2.8439 (3.9362)	Acc 0.250 (0.159)
Epoch: [1][138/597]	Time 0.201 (3.390)	Data 0.000 (3.185)	Loss 3.4117 (3.9324)	Acc 0.250 (0.160)
Epoch: [1][139/597]	Time 0.199 (3.367)	Data 0.000 (3.163)	Loss 3.4079 (3.9286)	Acc 0.125 (0.160)
Epoch: [1][140/597]	Time 2.040 (3.357)	Data 1.924 (3.154)	Loss 3.7887 (3.9276)	Acc 0.188 (0.160)
Epoch: [1][141/597]	Time 12.546 (3.423)	Data 12.423 (3.219)	Loss 3.6614 (3.9257)	Acc 0.125 (0.160)
Epoch: [1][142/597]	Time 0.216 (3.400)	Data 0.000 (3.197)	Loss 4.7330 (3.9314)	Acc 0.000 (0.158)
Epoch: [1][143/597]	Time 0.197 (3.378)	Data 0.000 (3.174)	Loss 3.8735 (3.9310)	Acc 0.125 (0.158)
Epoch: [1][144/597]	Time 1.875 (3.367)	Data 1.758 (3.165)	Loss 3.3514 (3.9270)	Acc 0.188 (0.158)
Epoch: [1][145/597]	Time 10.712 (3.418)	Data 10.588 (3.216)	Loss 3.8876 (3.9267)	Acc 0.062 (0.158)
Epoch: [1][146/597]	Time 0.216 (3.396)	Data 0.000 (3.194)	Loss 2.8196 (3.9191)	Acc 0.250 (0.158)
Epoch: [1][147/597]	Time 0.213 (3.374)	Data 0.000 (3.172)	Loss 2.4417 (3.9091)	Acc 0.375 (0.160)
Epoch: [1][148/597]	Time 2.080 (3.366)	Data 1.967 (3.164)	Loss 2.9241 (3.9024)	Acc 0.375 (0.161)
Epoch: [1][149/597]	Time 10.727 (3.415)	Data 10.609 (3.214)	Loss 4.0141 (3.9032)	Acc 0.188 (0.161)
Epoch: [1][150/597]	Time 0.200 (3.394)	Data 0.000 (3.192)	Loss 3.2819 (3.8990)	Acc 0.312 (0.163)
Epoch: [1][151/597]	Time 0.198 (3.372)	Data 0.000 (3.171)	Loss 2.8665 (3.8922)	Acc 0.312 (0.163)
Epoch: [1][152/597]	Time 1.720 (3.361)	Data 1.603 (3.161)	Loss 3.3548 (3.8886)	Acc 0.250 (0.164)
Epoch: [1][153/597]	Time 12.799 (3.423)	Data 12.674 (3.223)	Loss 3.6925 (3.8874)	Acc 0.188 (0.164)
Epoch: [1][154/597]	Time 0.215 (3.402)	Data 0.000 (3.202)	Loss 3.7377 (3.8864)	Acc 0.125 (0.164)
Epoch: [1][155/597]	Time 0.200 (3.382)	Data 0.000 (3.182)	Loss 4.0869 (3.8877)	Acc 0.062 (0.163)
Epoch: [1][156/597]	Time 0.509 (3.363)	Data 0.349 (3.163)	Loss 3.8750 (3.8876)	Acc 0.125 (0.163)
Epoch: [1][157/597]	Time 12.377 (3.421)	Data 12.232 (3.221)	Loss 4.4378 (3.8911)	Acc 0.188 (0.163)
Epoch: [1][158/597]	Time 0.199 (3.400)	Data 0.000 (3.201)	Loss 4.1619 (3.8928)	Acc 0.188 (0.163)
Epoch: [1][159/597]	Time 0.198 (3.380)	Data 0.000 (3.181)	Loss 2.3797 (3.8833)	Acc 0.375 (0.165)
Epoch: [1][160/597]	Time 0.202 (3.360)	Data 0.000 (3.161)	Loss 3.6344 (3.8817)	Acc 0.188 (0.165)
Epoch: [1][161/597]	Time 12.786 (3.419)	Data 12.631 (3.220)	Loss 3.3660 (3.8785)	Acc 0.312 (0.166)
Epoch: [1][162/597]	Time 0.179 (3.399)	Data 0.000 (3.200)	Loss 2.9582 (3.8729)	Acc 0.312 (0.167)
Epoch: [1][163/597]	Time 0.200 (3.379)	Data 0.000 (3.180)	Loss 4.1797 (3.8747)	Acc 0.062 (0.166)
Epoch: [1][164/597]	Time 0.202 (3.360)	Data 0.000 (3.161)	Loss 3.5619 (3.8728)	Acc 0.062 (0.165)
Epoch: [1][165/597]	Time 12.382 (3.415)	Data 12.261 (3.216)	Loss 3.6800 (3.8717)	Acc 0.188 (0.166)
Epoch: [1][166/597]	Time 0.198 (3.395)	Data 0.000 (3.197)	Loss 3.2916 (3.8682)	Acc 0.312 (0.166)
Epoch: [1][167/597]	Time 0.207 (3.376)	Data 0.000 (3.177)	Loss 2.9076 (3.8624)	Acc 0.438 (0.168)
Epoch: [1][168/597]	Time 0.388 (3.358)	Data 0.269 (3.160)	Loss 3.2062 (3.8585)	Acc 0.062 (0.167)
Epoch: [1][169/597]	Time 11.870 (3.409)	Data 11.746 (3.211)	Loss 2.9994 (3.8534)	Acc 0.188 (0.168)
Epoch: [1][170/597]	Time 0.219 (3.390)	Data 0.000 (3.192)	Loss 3.7516 (3.8528)	Acc 0.188 (0.168)
Epoch: [1][171/597]	Time 0.207 (3.371)	Data 0.000 (3.173)	Loss 2.9774 (3.8477)	Acc 0.312 (0.168)
Epoch: [1][172/597]	Time 0.396 (3.354)	Data 0.285 (3.157)	Loss 3.3557 (3.8449)	Acc 0.188 (0.169)
Epoch: [1][173/597]	Time 12.711 (3.408)	Data 12.571 (3.211)	Loss 3.1909 (3.8411)	Acc 0.125 (0.168)
Epoch: [1][174/597]	Time 0.218 (3.390)	Data 0.000 (3.192)	Loss 3.5035 (3.8391)	Acc 0.375 (0.170)
Epoch: [1][175/597]	Time 0.211 (3.372)	Data 0.000 (3.174)	Loss 3.2007 (3.8355)	Acc 0.312 (0.170)
Epoch: [1][176/597]	Time 0.328 (3.354)	Data 0.108 (3.157)	Loss 3.7108 (3.8348)	Acc 0.062 (0.170)
Epoch: [1][177/597]	Time 12.532 (3.406)	Data 12.413 (3.209)	Loss 3.6272 (3.8336)	Acc 0.062 (0.169)
Epoch: [1][178/597]	Time 0.214 (3.388)	Data 0.000 (3.191)	Loss 4.3670 (3.8366)	Acc 0.125 (0.169)
Epoch: [1][179/597]	Time 0.187 (3.370)	Data 0.000 (3.173)	Loss 3.7667 (3.8362)	Acc 0.188 (0.169)
Epoch: [1][180/597]	Time 0.201 (3.353)	Data 0.000 (3.156)	Loss 3.2184 (3.8328)	Acc 0.250 (0.169)
Epoch: [1][181/597]	Time 11.701 (3.399)	Data 11.575 (3.202)	Loss 2.9330 (3.8278)	Acc 0.188 (0.170)
Epoch: [1][182/597]	Time 0.220 (3.381)	Data 0.000 (3.185)	Loss 3.5616 (3.8263)	Acc 0.125 (0.169)
Epoch: [1][183/597]	Time 0.220 (3.364)	Data 0.000 (3.167)	Loss 2.9557 (3.8216)	Acc 0.250 (0.170)
Epoch: [1][184/597]	Time 0.336 (3.348)	Data 0.211 (3.151)	Loss 3.0428 (3.8174)	Acc 0.188 (0.170)
Epoch: [1][185/597]	Time 12.652 (3.398)	Data 12.537 (3.202)	Loss 3.6996 (3.8167)	Acc 0.250 (0.170)
Epoch: [1][186/597]	Time 0.194 (3.381)	Data 0.000 (3.185)	Loss 2.7924 (3.8112)	Acc 0.250 (0.171)
Epoch: [1][187/597]	Time 0.201 (3.364)	Data 0.000 (3.168)	Loss 3.5796 (3.8100)	Acc 0.188 (0.171)
Epoch: [1][188/597]	Time 0.215 (3.347)	Data 0.000 (3.151)	Loss 3.8193 (3.8100)	Acc 0.062 (0.170)
Epoch: [1][189/597]	Time 12.644 (3.396)	Data 12.488 (3.200)	Loss 4.3841 (3.8131)	Acc 0.062 (0.170)
Epoch: [1][190/597]	Time 0.213 (3.379)	Data 0.000 (3.183)	Loss 3.2451 (3.8101)	Acc 0.250 (0.170)
Epoch: [1][191/597]	Time 0.208 (3.363)	Data 0.000 (3.167)	Loss 3.7217 (3.8096)	Acc 0.188 (0.170)
Epoch: [1][192/597]	Time 0.195 (3.346)	Data 0.000 (3.150)	Loss 3.7624 (3.8094)	Acc 0.125 (0.170)
Epoch: [1][193/597]	Time 13.167 (3.397)	Data 13.044 (3.201)	Loss 2.1127 (3.8006)	Acc 0.500 (0.172)
Epoch: [1][194/597]	Time 0.199 (3.381)	Data 0.000 (3.185)	Loss 3.4579 (3.7988)	Acc 0.125 (0.171)
Epoch: [1][195/597]	Time 0.200 (3.364)	Data 0.000 (3.169)	Loss 3.5310 (3.7974)	Acc 0.188 (0.171)
Epoch: [1][196/597]	Time 0.200 (3.348)	Data 0.000 (3.152)	Loss 3.3648 (3.7952)	Acc 0.250 (0.172)
Epoch: [1][197/597]	Time 13.463 (3.400)	Data 13.339 (3.204)	Loss 2.6607 (3.7895)	Acc 0.375 (0.173)
Epoch: [1][198/597]	Time 0.232 (3.384)	Data 0.000 (3.188)	Loss 2.8797 (3.7849)	Acc 0.250 (0.173)
Epoch: [1][199/597]	Time 0.203 (3.368)	Data 0.000 (3.172)	Loss 2.3665 (3.7777)	Acc 0.375 (0.174)
Epoch: [1][200/597]	Time 0.195 (3.352)	Data 0.000 (3.156)	Loss 2.9501 (3.7736)	Acc 0.375 (0.175)
Epoch: [1][201/597]	Time 13.295 (3.401)	Data 13.166 (3.206)	Loss 3.1992 (3.7707)	Acc 0.188 (0.175)
Epoch: [1][202/597]	Time 0.202 (3.385)	Data 0.000 (3.190)	Loss 3.6009 (3.7699)	Acc 0.125 (0.175)
Epoch: [1][203/597]	Time 0.207 (3.370)	Data 0.000 (3.174)	Loss 3.2263 (3.7672)	Acc 0.250 (0.175)
Epoch: [1][204/597]	Time 0.209 (3.354)	Data 0.000 (3.159)	Loss 3.0738 (3.7638)	Acc 0.125 (0.175)
Epoch: [1][205/597]	Time 12.281 (3.398)	Data 12.159 (3.203)	Loss 2.6809 (3.7585)	Acc 0.375 (0.176)
Epoch: [1][206/597]	Time 0.201 (3.382)	Data 0.000 (3.187)	Loss 2.3394 (3.7517)	Acc 0.500 (0.178)
Epoch: [1][207/597]	Time 0.203 (3.367)	Data 0.000 (3.172)	Loss 3.2706 (3.7493)	Acc 0.188 (0.178)
Epoch: [1][208/597]	Time 0.195 (3.352)	Data 0.000 (3.156)	Loss 2.8912 (3.7452)	Acc 0.375 (0.179)
Epoch: [1][209/597]	Time 13.262 (3.399)	Data 13.130 (3.204)	Loss 3.0430 (3.7418)	Acc 0.312 (0.179)
Epoch: [1][210/597]	Time 0.220 (3.384)	Data 0.000 (3.189)	Loss 2.5815 (3.7363)	Acc 0.312 (0.180)
Epoch: [1][211/597]	Time 0.215 (3.369)	Data 0.000 (3.174)	Loss 3.5146 (3.7353)	Acc 0.125 (0.180)
Epoch: [1][212/597]	Time 0.194 (3.354)	Data 0.000 (3.159)	Loss 3.2670 (3.7331)	Acc 0.250 (0.180)
Epoch: [1][213/597]	Time 13.232 (3.400)	Data 13.114 (3.206)	Loss 3.4401 (3.7317)	Acc 0.250 (0.180)
Epoch: [1][214/597]	Time 0.206 (3.385)	Data 0.000 (3.191)	Loss 3.4869 (3.7305)	Acc 0.188 (0.180)
Epoch: [1][215/597]	Time 0.198 (3.371)	Data 0.000 (3.176)	Loss 3.4828 (3.7294)	Acc 0.250 (0.181)
Epoch: [1][216/597]	Time 0.199 (3.356)	Data 0.000 (3.161)	Loss 3.2416 (3.7271)	Acc 0.250 (0.181)
Epoch: [1][217/597]	Time 14.023 (3.405)	Data 13.898 (3.211)	Loss 3.0801 (3.7242)	Acc 0.312 (0.182)
Epoch: [1][218/597]	Time 0.229 (3.390)	Data 0.000 (3.196)	Loss 3.7833 (3.7244)	Acc 0.125 (0.181)
Epoch: [1][219/597]	Time 0.193 (3.376)	Data 0.000 (3.181)	Loss 4.2705 (3.7269)	Acc 0.125 (0.181)
Epoch: [1][220/597]	Time 0.205 (3.361)	Data 0.000 (3.167)	Loss 3.8817 (3.7276)	Acc 0.250 (0.182)
Epoch: [1][221/597]	Time 12.928 (3.405)	Data 12.805 (3.210)	Loss 2.6973 (3.7230)	Acc 0.438 (0.183)
Epoch: [1][222/597]	Time 0.218 (3.390)	Data 0.000 (3.196)	Loss 2.5511 (3.7177)	Acc 0.312 (0.183)
Epoch: [1][223/597]	Time 0.207 (3.376)	Data 0.000 (3.182)	Loss 2.9937 (3.7144)	Acc 0.250 (0.184)
Epoch: [1][224/597]	Time 0.211 (3.362)	Data 0.000 (3.167)	Loss 2.2954 (3.7081)	Acc 0.438 (0.185)
Epoch: [1][225/597]	Time 12.997 (3.405)	Data 12.878 (3.211)	Loss 2.8776 (3.7044)	Acc 0.188 (0.185)
Epoch: [1][226/597]	Time 0.206 (3.391)	Data 0.000 (3.196)	Loss 2.4255 (3.6987)	Acc 0.188 (0.185)
Epoch: [1][227/597]	Time 0.190 (3.377)	Data 0.000 (3.182)	Loss 3.1626 (3.6964)	Acc 0.375 (0.186)
Epoch: [1][228/597]	Time 0.202 (3.363)	Data 0.000 (3.168)	Loss 3.0244 (3.6934)	Acc 0.375 (0.186)
Epoch: [1][229/597]	Time 12.605 (3.403)	Data 12.477 (3.209)	Loss 3.1226 (3.6909)	Acc 0.312 (0.187)
Epoch: [1][230/597]	Time 0.224 (3.389)	Data 0.000 (3.195)	Loss 2.6375 (3.6864)	Acc 0.375 (0.188)
Epoch: [1][231/597]	Time 0.208 (3.375)	Data 0.000 (3.181)	Loss 4.0083 (3.6878)	Acc 0.312 (0.188)
Epoch: [1][232/597]	Time 0.198 (3.362)	Data 0.000 (3.167)	Loss 2.8750 (3.6843)	Acc 0.250 (0.189)
Epoch: [1][233/597]	Time 12.656 (3.402)	Data 12.525 (3.208)	Loss 3.5158 (3.6835)	Acc 0.250 (0.189)
Epoch: [1][234/597]	Time 0.202 (3.388)	Data 0.000 (3.194)	Loss 3.2264 (3.6816)	Acc 0.062 (0.188)
Epoch: [1][235/597]	Time 0.205 (3.374)	Data 0.000 (3.180)	Loss 3.4203 (3.6805)	Acc 0.312 (0.189)
Epoch: [1][236/597]	Time 0.198 (3.361)	Data 0.000 (3.167)	Loss 3.1976 (3.6784)	Acc 0.375 (0.190)
Epoch: [1][237/597]	Time 14.366 (3.407)	Data 14.237 (3.214)	Loss 3.1998 (3.6764)	Acc 0.188 (0.190)
Epoch: [1][238/597]	Time 0.229 (3.394)	Data 0.000 (3.200)	Loss 3.4012 (3.6752)	Acc 0.062 (0.189)
Epoch: [1][239/597]	Time 0.196 (3.381)	Data 0.000 (3.187)	Loss 3.5844 (3.6749)	Acc 0.125 (0.189)
Epoch: [1][240/597]	Time 0.204 (3.367)	Data 0.000 (3.173)	Loss 3.2053 (3.6729)	Acc 0.250 (0.189)
Epoch: [1][241/597]	Time 13.149 (3.408)	Data 13.021 (3.214)	Loss 3.2909 (3.6713)	Acc 0.312 (0.190)
Epoch: [1][242/597]	Time 0.222 (3.395)	Data 0.000 (3.201)	Loss 2.1137 (3.6649)	Acc 0.250 (0.190)
Epoch: [1][243/597]	Time 0.203 (3.382)	Data 0.000 (3.188)	Loss 3.1513 (3.6628)	Acc 0.250 (0.190)
Epoch: [1][244/597]	Time 0.209 (3.369)	Data 0.000 (3.175)	Loss 3.5273 (3.6622)	Acc 0.125 (0.190)
Epoch: [1][245/597]	Time 12.761 (3.407)	Data 12.621 (3.213)	Loss 3.3053 (3.6608)	Acc 0.188 (0.190)
Epoch: [1][246/597]	Time 0.198 (3.394)	Data 0.001 (3.200)	Loss 2.9917 (3.6580)	Acc 0.250 (0.190)
Epoch: [1][247/597]	Time 0.201 (3.381)	Data 0.000 (3.187)	Loss 3.7511 (3.6584)	Acc 0.062 (0.190)
Epoch: [1][248/597]	Time 0.214 (3.368)	Data 0.000 (3.174)	Loss 2.8656 (3.6552)	Acc 0.375 (0.190)
Epoch: [1][249/597]	Time 14.044 (3.411)	Data 13.917 (3.218)	Loss 2.2879 (3.6497)	Acc 0.500 (0.192)
Epoch: [1][250/597]	Time 0.216 (3.398)	Data 0.000 (3.205)	Loss 2.4090 (3.6448)	Acc 0.250 (0.192)
Epoch: [1][251/597]	Time 0.203 (3.386)	Data 0.000 (3.192)	Loss 3.5626 (3.6444)	Acc 0.188 (0.192)
Epoch: [1][252/597]	Time 0.199 (3.373)	Data 0.000 (3.179)	Loss 3.1919 (3.6426)	Acc 0.125 (0.191)
Epoch: [1][253/597]	Time 12.783 (3.410)	Data 12.671 (3.217)	Loss 2.9885 (3.6401)	Acc 0.438 (0.192)
Epoch: [1][254/597]	Time 0.221 (3.398)	Data 0.000 (3.204)	Loss 3.7658 (3.6406)	Acc 0.188 (0.192)
Epoch: [1][255/597]	Time 0.206 (3.385)	Data 0.000 (3.192)	Loss 3.3569 (3.6394)	Acc 0.250 (0.193)
Epoch: [1][256/597]	Time 0.197 (3.373)	Data 0.000 (3.179)	Loss 3.7771 (3.6400)	Acc 0.188 (0.193)
Epoch: [1][257/597]	Time 13.179 (3.411)	Data 13.027 (3.217)	Loss 3.4710 (3.6393)	Acc 0.125 (0.192)
Epoch: [1][258/597]	Time 0.216 (3.398)	Data 0.000 (3.205)	Loss 3.6324 (3.6393)	Acc 0.125 (0.192)
Epoch: [1][259/597]	Time 0.212 (3.386)	Data 0.000 (3.193)	Loss 3.0229 (3.6369)	Acc 0.125 (0.192)
Epoch: [1][260/597]	Time 0.198 (3.374)	Data 0.000 (3.180)	Loss 2.7550 (3.6335)	Acc 0.312 (0.192)
Epoch: [1][261/597]	Time 12.528 (3.409)	Data 12.407 (3.216)	Loss 3.2152 (3.6319)	Acc 0.312 (0.193)
Epoch: [1][262/597]	Time 0.219 (3.397)	Data 0.000 (3.203)	Loss 3.2032 (3.6303)	Acc 0.188 (0.193)
Epoch: [1][263/597]	Time 0.211 (3.385)	Data 0.000 (3.191)	Loss 3.3934 (3.6294)	Acc 0.188 (0.193)
Epoch: [1][264/597]	Time 0.199 (3.373)	Data 0.000 (3.179)	Loss 2.1853 (3.6239)	Acc 0.438 (0.194)
Epoch: [1][265/597]	Time 14.046 (3.413)	Data 13.933 (3.220)	Loss 3.8267 (3.6247)	Acc 0.312 (0.194)
Epoch: [1][266/597]	Time 0.202 (3.401)	Data 0.000 (3.208)	Loss 3.6391 (3.6247)	Acc 0.250 (0.194)
Epoch: [1][267/597]	Time 0.202 (3.389)	Data 0.000 (3.196)	Loss 2.8672 (3.6219)	Acc 0.312 (0.195)
Epoch: [1][268/597]	Time 0.215 (3.377)	Data 0.000 (3.184)	Loss 3.5878 (3.6218)	Acc 0.312 (0.195)
Epoch: [1][269/597]	Time 14.146 (3.417)	Data 14.018 (3.224)	Loss 2.5313 (3.6177)	Acc 0.375 (0.196)
Epoch: [1][270/597]	Time 0.213 (3.405)	Data 0.000 (3.212)	Loss 3.4794 (3.6172)	Acc 0.125 (0.196)
Epoch: [1][271/597]	Time 0.211 (3.393)	Data 0.000 (3.200)	Loss 2.8448 (3.6144)	Acc 0.375 (0.196)
Epoch: [1][272/597]	Time 0.185 (3.382)	Data 0.000 (3.188)	Loss 3.2559 (3.6130)	Acc 0.188 (0.196)
Epoch: [1][273/597]	Time 12.176 (3.414)	Data 12.050 (3.221)	Loss 2.7610 (3.6099)	Acc 0.312 (0.197)
Epoch: [1][274/597]	Time 0.216 (3.402)	Data 0.000 (3.209)	Loss 2.5868 (3.6062)	Acc 0.438 (0.198)
Epoch: [1][275/597]	Time 0.198 (3.390)	Data 0.000 (3.197)	Loss 2.4830 (3.6021)	Acc 0.375 (0.198)
Epoch: [1][276/597]	Time 0.208 (3.379)	Data 0.000 (3.186)	Loss 3.7665 (3.6027)	Acc 0.188 (0.198)
Epoch: [1][277/597]	Time 13.374 (3.415)	Data 13.256 (3.222)	Loss 3.3880 (3.6019)	Acc 0.125 (0.198)
Epoch: [1][278/597]	Time 0.214 (3.403)	Data 0.000 (3.211)	Loss 2.4102 (3.5976)	Acc 0.250 (0.198)
Epoch: [1][279/597]	Time 0.194 (3.392)	Data 0.000 (3.199)	Loss 2.9096 (3.5952)	Acc 0.312 (0.198)
Epoch: [1][280/597]	Time 0.200 (3.381)	Data 0.000 (3.188)	Loss 3.3792 (3.5944)	Acc 0.250 (0.199)
Epoch: [1][281/597]	Time 13.310 (3.416)	Data 13.200 (3.223)	Loss 2.8627 (3.5918)	Acc 0.188 (0.199)
Epoch: [1][282/597]	Time 0.202 (3.404)	Data 0.000 (3.212)	Loss 2.6768 (3.5885)	Acc 0.438 (0.199)
Epoch: [1][283/597]	Time 0.200 (3.393)	Data 0.000 (3.200)	Loss 4.0655 (3.5902)	Acc 0.125 (0.199)
Epoch: [1][284/597]	Time 0.216 (3.382)	Data 0.000 (3.189)	Loss 3.0838 (3.5884)	Acc 0.375 (0.200)
Epoch: [1][285/597]	Time 13.692 (3.418)	Data 13.567 (3.226)	Loss 3.8256 (3.5893)	Acc 0.188 (0.200)
Epoch: [1][286/597]	Time 0.220 (3.407)	Data 0.000 (3.214)	Loss 2.6439 (3.5860)	Acc 0.375 (0.200)
Epoch: [1][287/597]	Time 0.208 (3.396)	Data 0.000 (3.203)	Loss 3.0053 (3.5839)	Acc 0.250 (0.201)
Epoch: [1][288/597]	Time 0.191 (3.385)	Data 0.000 (3.192)	Loss 2.5716 (3.5804)	Acc 0.438 (0.201)
Epoch: [1][289/597]	Time 13.889 (3.421)	Data 13.766 (3.229)	Loss 3.0558 (3.5786)	Acc 0.250 (0.202)
Epoch: [1][290/597]	Time 0.228 (3.410)	Data 0.000 (3.217)	Loss 3.7024 (3.5790)	Acc 0.125 (0.201)
Epoch: [1][291/597]	Time 0.195 (3.399)	Data 0.000 (3.206)	Loss 2.4755 (3.5753)	Acc 0.188 (0.201)
Epoch: [1][292/597]	Time 0.200 (3.388)	Data 0.000 (3.195)	Loss 2.9790 (3.5732)	Acc 0.312 (0.202)
Epoch: [1][293/597]	Time 14.074 (3.424)	Data 13.933 (3.232)	Loss 4.4730 (3.5763)	Acc 0.250 (0.202)
Epoch: [1][294/597]	Time 0.202 (3.414)	Data 0.000 (3.221)	Loss 3.0432 (3.5745)	Acc 0.250 (0.202)
Epoch: [1][295/597]	Time 0.198 (3.403)	Data 0.000 (3.210)	Loss 3.3245 (3.5736)	Acc 0.188 (0.202)
Epoch: [1][296/597]	Time 0.198 (3.392)	Data 0.000 (3.199)	Loss 3.0302 (3.5718)	Acc 0.062 (0.201)
Epoch: [1][297/597]	Time 12.690 (3.423)	Data 12.547 (3.231)	Loss 3.4583 (3.5714)	Acc 0.312 (0.202)
Epoch: [1][298/597]	Time 0.198 (3.412)	Data 0.000 (3.220)	Loss 2.5516 (3.5680)	Acc 0.312 (0.202)
Epoch: [1][299/597]	Time 0.197 (3.402)	Data 0.000 (3.209)	Loss 3.3114 (3.5671)	Acc 0.125 (0.202)
Epoch: [1][300/597]	Time 0.208 (3.391)	Data 0.000 (3.198)	Loss 2.5914 (3.5639)	Acc 0.375 (0.203)
Epoch: [1][301/597]	Time 13.617 (3.425)	Data 13.488 (3.233)	Loss 4.1650 (3.5659)	Acc 0.250 (0.203)
Epoch: [1][302/597]	Time 0.216 (3.414)	Data 0.000 (3.222)	Loss 3.2544 (3.5648)	Acc 0.312 (0.203)
Epoch: [1][303/597]	Time 0.203 (3.404)	Data 0.000 (3.211)	Loss 2.8607 (3.5625)	Acc 0.188 (0.203)
Epoch: [1][304/597]	Time 0.201 (3.393)	Data 0.000 (3.201)	Loss 2.8281 (3.5601)	Acc 0.250 (0.203)
Epoch: [1][305/597]	Time 13.572 (3.426)	Data 13.455 (3.234)	Loss 2.9193 (3.5580)	Acc 0.188 (0.203)
Epoch: [1][306/597]	Time 0.214 (3.416)	Data 0.000 (3.224)	Loss 2.4177 (3.5543)	Acc 0.312 (0.203)
Epoch: [1][307/597]	Time 0.204 (3.406)	Data 0.000 (3.213)	Loss 2.6040 (3.5512)	Acc 0.375 (0.204)
Epoch: [1][308/597]	Time 0.194 (3.395)	Data 0.000 (3.203)	Loss 3.4569 (3.5509)	Acc 0.312 (0.204)
Epoch: [1][309/597]	Time 13.494 (3.428)	Data 13.320 (3.236)	Loss 3.0589 (3.5493)	Acc 0.250 (0.204)
Epoch: [1][310/597]	Time 0.202 (3.417)	Data 0.000 (3.225)	Loss 2.9384 (3.5473)	Acc 0.250 (0.205)
Epoch: [1][311/597]	Time 0.211 (3.407)	Data 0.000 (3.215)	Loss 3.3313 (3.5466)	Acc 0.125 (0.204)
Epoch: [1][312/597]	Time 0.199 (3.397)	Data 0.000 (3.205)	Loss 3.0315 (3.5450)	Acc 0.188 (0.204)
Epoch: [1][313/597]	Time 13.337 (3.429)	Data 13.213 (3.237)	Loss 3.3674 (3.5444)	Acc 0.125 (0.204)
Epoch: [1][314/597]	Time 0.212 (3.418)	Data 0.000 (3.226)	Loss 3.2317 (3.5434)	Acc 0.250 (0.204)
Epoch: [1][315/597]	Time 0.197 (3.408)	Data 0.000 (3.216)	Loss 2.8731 (3.5413)	Acc 0.438 (0.205)
Epoch: [1][316/597]	Time 0.211 (3.398)	Data 0.000 (3.206)	Loss 2.4316 (3.5378)	Acc 0.375 (0.205)
Epoch: [1][317/597]	Time 12.341 (3.426)	Data 12.226 (3.234)	Loss 3.1209 (3.5364)	Acc 0.312 (0.206)
Epoch: [1][318/597]	Time 0.205 (3.416)	Data 0.000 (3.224)	Loss 2.4694 (3.5331)	Acc 0.438 (0.207)
Epoch: [1][319/597]	Time 0.192 (3.406)	Data 0.000 (3.214)	Loss 2.8157 (3.5308)	Acc 0.188 (0.207)
Epoch: [1][320/597]	Time 0.211 (3.396)	Data 0.000 (3.204)	Loss 3.8525 (3.5318)	Acc 0.062 (0.206)
Epoch: [1][321/597]	Time 13.186 (3.426)	Data 13.069 (3.235)	Loss 3.6745 (3.5323)	Acc 0.250 (0.206)
Epoch: [1][322/597]	Time 0.199 (3.416)	Data 0.000 (3.225)	Loss 3.2442 (3.5314)	Acc 0.250 (0.206)
Epoch: [1][323/597]	Time 0.213 (3.406)	Data 0.000 (3.215)	Loss 2.7032 (3.5288)	Acc 0.375 (0.207)
Epoch: [1][324/597]	Time 0.194 (3.397)	Data 0.000 (3.205)	Loss 3.1782 (3.5277)	Acc 0.250 (0.207)
Epoch: [1][325/597]	Time 13.383 (3.427)	Data 13.261 (3.236)	Loss 2.3620 (3.5242)	Acc 0.375 (0.207)
Epoch: [1][326/597]	Time 0.218 (3.417)	Data 0.000 (3.226)	Loss 2.0386 (3.5196)	Acc 0.562 (0.209)
Epoch: [1][327/597]	Time 0.198 (3.408)	Data 0.000 (3.216)	Loss 2.1857 (3.5155)	Acc 0.500 (0.209)
Epoch: [1][328/597]	Time 0.201 (3.398)	Data 0.000 (3.206)	Loss 2.6932 (3.5130)	Acc 0.312 (0.210)
Epoch: [1][329/597]	Time 13.661 (3.429)	Data 13.537 (3.237)	Loss 3.4856 (3.5129)	Acc 0.188 (0.210)
Epoch: [1][330/597]	Time 0.215 (3.419)	Data 0.000 (3.228)	Loss 2.7788 (3.5107)	Acc 0.250 (0.210)
Epoch: [1][331/597]	Time 0.222 (3.410)	Data 0.000 (3.218)	Loss 2.5804 (3.5079)	Acc 0.250 (0.210)
Epoch: [1][332/597]	Time 0.213 (3.400)	Data 0.000 (3.208)	Loss 3.1320 (3.5068)	Acc 0.375 (0.210)
Epoch: [1][333/597]	Time 13.392 (3.430)	Data 13.272 (3.238)	Loss 3.3680 (3.5063)	Acc 0.312 (0.211)
Epoch: [1][334/597]	Time 0.197 (3.420)	Data 0.000 (3.229)	Loss 3.0291 (3.5049)	Acc 0.188 (0.211)
Epoch: [1][335/597]	Time 0.201 (3.411)	Data 0.000 (3.219)	Loss 3.2799 (3.5042)	Acc 0.312 (0.211)
Epoch: [1][336/597]	Time 0.220 (3.401)	Data 0.000 (3.210)	Loss 3.1097 (3.5031)	Acc 0.312 (0.211)
Epoch: [1][337/597]	Time 12.060 (3.427)	Data 11.935 (3.235)	Loss 3.3234 (3.5025)	Acc 0.312 (0.212)
Epoch: [1][338/597]	Time 0.220 (3.417)	Data 0.000 (3.226)	Loss 3.2932 (3.5019)	Acc 0.250 (0.212)
Epoch: [1][339/597]	Time 0.200 (3.408)	Data 0.000 (3.216)	Loss 3.5324 (3.5020)	Acc 0.188 (0.212)
Epoch: [1][340/597]	Time 0.208 (3.399)	Data 0.000 (3.207)	Loss 3.1035 (3.5008)	Acc 0.250 (0.212)
Epoch: [1][341/597]	Time 12.960 (3.427)	Data 12.838 (3.235)	Loss 2.7878 (3.4987)	Acc 0.250 (0.212)
Epoch: [1][342/597]	Time 0.222 (3.417)	Data 0.000 (3.226)	Loss 3.3223 (3.4982)	Acc 0.188 (0.212)
Epoch: [1][343/597]	Time 0.212 (3.408)	Data 0.000 (3.216)	Loss 2.9243 (3.4966)	Acc 0.250 (0.212)
Epoch: [1][344/597]	Time 0.204 (3.399)	Data 0.000 (3.207)	Loss 2.8733 (3.4947)	Acc 0.312 (0.212)
Epoch: [1][345/597]	Time 12.817 (3.426)	Data 12.701 (3.234)	Loss 3.4793 (3.4947)	Acc 0.188 (0.212)
Epoch: [1][346/597]	Time 0.215 (3.417)	Data 0.000 (3.225)	Loss 2.4454 (3.4917)	Acc 0.312 (0.212)
Epoch: [1][347/597]	Time 0.187 (3.407)	Data 0.000 (3.216)	Loss 3.6771 (3.4922)	Acc 0.250 (0.213)
Epoch: [1][348/597]	Time 0.214 (3.398)	Data 0.000 (3.207)	Loss 2.4517 (3.4892)	Acc 0.375 (0.213)
Epoch: [1][349/597]	Time 13.174 (3.426)	Data 13.033 (3.235)	Loss 2.8553 (3.4874)	Acc 0.312 (0.213)
Epoch: [1][350/597]	Time 0.221 (3.417)	Data 0.000 (3.225)	Loss 3.2189 (3.4866)	Acc 0.125 (0.213)
Epoch: [1][351/597]	Time 0.205 (3.408)	Data 0.000 (3.216)	Loss 3.1291 (3.4856)	Acc 0.375 (0.213)
Epoch: [1][352/597]	Time 0.200 (3.399)	Data 0.000 (3.207)	Loss 2.0279 (3.4815)	Acc 0.375 (0.214)
Epoch: [1][353/597]	Time 13.412 (3.427)	Data 13.297 (3.236)	Loss 2.6493 (3.4791)	Acc 0.312 (0.214)
Epoch: [1][354/597]	Time 0.197 (3.418)	Data 0.000 (3.227)	Loss 2.9869 (3.4777)	Acc 0.312 (0.215)
Epoch: [1][355/597]	Time 0.199 (3.409)	Data 0.000 (3.217)	Loss 2.4183 (3.4747)	Acc 0.250 (0.215)
Epoch: [1][356/597]	Time 0.204 (3.400)	Data 0.000 (3.208)	Loss 3.0841 (3.4736)	Acc 0.188 (0.215)
Epoch: [1][357/597]	Time 12.904 (3.426)	Data 12.764 (3.235)	Loss 2.2562 (3.4702)	Acc 0.312 (0.215)
Epoch: [1][358/597]	Time 0.218 (3.418)	Data 0.000 (3.226)	Loss 2.4757 (3.4675)	Acc 0.312 (0.215)
Epoch: [1][359/597]	Time 0.200 (3.409)	Data 0.000 (3.217)	Loss 2.8066 (3.4656)	Acc 0.250 (0.215)
Epoch: [1][360/597]	Time 0.214 (3.400)	Data 0.000 (3.208)	Loss 3.0356 (3.4644)	Acc 0.312 (0.215)
Epoch: [1][361/597]	Time 13.565 (3.428)	Data 13.448 (3.237)	Loss 2.3325 (3.4613)	Acc 0.500 (0.216)
Epoch: [1][362/597]	Time 0.196 (3.419)	Data 0.000 (3.228)	Loss 2.4835 (3.4586)	Acc 0.375 (0.217)
Epoch: [1][363/597]	Time 0.203 (3.410)	Data 0.000 (3.219)	Loss 2.8514 (3.4569)	Acc 0.438 (0.217)
Epoch: [1][364/597]	Time 0.211 (3.401)	Data 0.000 (3.210)	Loss 2.1348 (3.4533)	Acc 0.312 (0.218)
Epoch: [1][365/597]	Time 13.695 (3.429)	Data 13.572 (3.238)	Loss 3.1123 (3.4523)	Acc 0.375 (0.218)
Epoch: [1][366/597]	Time 0.235 (3.421)	Data 0.000 (3.229)	Loss 3.0114 (3.4511)	Acc 0.188 (0.218)
Epoch: [1][367/597]	Time 0.197 (3.412)	Data 0.000 (3.221)	Loss 2.4858 (3.4485)	Acc 0.500 (0.219)
Epoch: [1][368/597]	Time 0.199 (3.403)	Data 0.000 (3.212)	Loss 3.3478 (3.4482)	Acc 0.250 (0.219)
Epoch: [1][369/597]	Time 12.269 (3.427)	Data 12.144 (3.236)	Loss 2.7806 (3.4464)	Acc 0.500 (0.220)
Epoch: [1][370/597]	Time 0.210 (3.419)	Data 0.000 (3.227)	Loss 3.4192 (3.4464)	Acc 0.188 (0.219)
Epoch: [1][371/597]	Time 0.198 (3.410)	Data 0.000 (3.219)	Loss 3.4418 (3.4463)	Acc 0.188 (0.219)
Epoch: [1][372/597]	Time 0.199 (3.401)	Data 0.000 (3.210)	Loss 3.9078 (3.4476)	Acc 0.062 (0.219)
Epoch: [1][373/597]	Time 13.989 (3.430)	Data 13.857 (3.239)	Loss 1.7838 (3.4431)	Acc 0.562 (0.220)
Epoch: [1][374/597]	Time 0.196 (3.421)	Data 0.000 (3.230)	Loss 3.7090 (3.4438)	Acc 0.188 (0.220)
Epoch: [1][375/597]	Time 0.195 (3.412)	Data 0.000 (3.221)	Loss 2.7034 (3.4419)	Acc 0.375 (0.220)
Epoch: [1][376/597]	Time 0.199 (3.404)	Data 0.000 (3.213)	Loss 3.5529 (3.4422)	Acc 0.188 (0.220)
Epoch: [1][377/597]	Time 12.865 (3.429)	Data 12.729 (3.238)	Loss 2.6676 (3.4401)	Acc 0.250 (0.220)
Epoch: [1][378/597]	Time 0.208 (3.420)	Data 0.000 (3.229)	Loss 2.7568 (3.4383)	Acc 0.250 (0.220)
Epoch: [1][379/597]	Time 0.198 (3.412)	Data 0.000 (3.221)	Loss 2.9558 (3.4370)	Acc 0.375 (0.221)
Epoch: [1][380/597]	Time 0.196 (3.403)	Data 0.000 (3.212)	Loss 3.5362 (3.4373)	Acc 0.188 (0.221)
Epoch: [1][381/597]	Time 13.769 (3.431)	Data 13.646 (3.240)	Loss 2.9409 (3.4360)	Acc 0.312 (0.221)
Epoch: [1][382/597]	Time 0.226 (3.422)	Data 0.000 (3.231)	Loss 3.4029 (3.4359)	Acc 0.188 (0.221)
Epoch: [1][383/597]	Time 0.206 (3.414)	Data 0.000 (3.223)	Loss 2.7270 (3.4340)	Acc 0.250 (0.221)
Epoch: [1][384/597]	Time 0.197 (3.405)	Data 0.000 (3.214)	Loss 3.0798 (3.4331)	Acc 0.250 (0.221)
Epoch: [1][385/597]	Time 13.771 (3.432)	Data 13.639 (3.242)	Loss 2.5263 (3.4308)	Acc 0.375 (0.221)
Epoch: [1][386/597]	Time 0.191 (3.424)	Data 0.000 (3.233)	Loss 2.8023 (3.4291)	Acc 0.438 (0.222)
Epoch: [1][387/597]	Time 0.200 (3.416)	Data 0.000 (3.225)	Loss 2.6590 (3.4271)	Acc 0.312 (0.222)
Epoch: [1][388/597]	Time 0.201 (3.407)	Data 0.000 (3.217)	Loss 3.3843 (3.4270)	Acc 0.375 (0.222)
Epoch: [1][389/597]	Time 13.283 (3.433)	Data 13.156 (3.242)	Loss 2.9910 (3.4259)	Acc 0.375 (0.223)
Epoch: [1][390/597]	Time 0.218 (3.425)	Data 0.000 (3.234)	Loss 2.7304 (3.4241)	Acc 0.312 (0.223)
Epoch: [1][391/597]	Time 0.205 (3.416)	Data 0.000 (3.225)	Loss 2.3723 (3.4214)	Acc 0.375 (0.223)
Epoch: [1][392/597]	Time 0.208 (3.408)	Data 0.000 (3.217)	Loss 2.6351 (3.4194)	Acc 0.312 (0.224)
Epoch: [1][393/597]	Time 12.912 (3.432)	Data 12.796 (3.242)	Loss 2.9114 (3.4181)	Acc 0.312 (0.224)
Epoch: [1][394/597]	Time 0.202 (3.424)	Data 0.000 (3.233)	Loss 2.8599 (3.4167)	Acc 0.375 (0.224)
Epoch: [1][395/597]	Time 0.196 (3.416)	Data 0.000 (3.225)	Loss 3.0981 (3.4159)	Acc 0.375 (0.225)
Epoch: [1][396/597]	Time 0.200 (3.408)	Data 0.000 (3.217)	Loss 3.6198 (3.4164)	Acc 0.312 (0.225)
Epoch: [1][397/597]	Time 12.129 (3.430)	Data 12.004 (3.239)	Loss 2.6788 (3.4146)	Acc 0.312 (0.225)
Epoch: [1][398/597]	Time 0.206 (3.422)	Data 0.000 (3.231)	Loss 3.2741 (3.4142)	Acc 0.188 (0.225)
Epoch: [1][399/597]	Time 0.201 (3.414)	Data 0.000 (3.223)	Loss 2.0623 (3.4108)	Acc 0.438 (0.226)
Epoch: [1][400/597]	Time 0.202 (3.406)	Data 0.000 (3.215)	Loss 3.7475 (3.4117)	Acc 0.188 (0.225)
Epoch: [1][401/597]	Time 14.138 (3.432)	Data 14.013 (3.242)	Loss 3.7040 (3.4124)	Acc 0.125 (0.225)
Epoch: [1][402/597]	Time 0.222 (3.424)	Data 0.000 (3.234)	Loss 2.6217 (3.4104)	Acc 0.375 (0.226)
Epoch: [1][403/597]	Time 0.201 (3.416)	Data 0.000 (3.226)	Loss 2.9709 (3.4093)	Acc 0.188 (0.225)
Epoch: [1][404/597]	Time 0.198 (3.408)	Data 0.000 (3.218)	Loss 2.5982 (3.4073)	Acc 0.250 (0.226)
Epoch: [1][405/597]	Time 14.636 (3.436)	Data 14.502 (3.246)	Loss 3.0920 (3.4066)	Acc 0.250 (0.226)
Epoch: [1][406/597]	Time 0.187 (3.428)	Data 0.000 (3.238)	Loss 2.0245 (3.4032)	Acc 0.562 (0.226)
Epoch: [1][407/597]	Time 0.197 (3.420)	Data 0.000 (3.230)	Loss 2.4836 (3.4009)	Acc 0.438 (0.227)
Epoch: [1][408/597]	Time 0.200 (3.412)	Data 0.000 (3.222)	Loss 2.7309 (3.3993)	Acc 0.438 (0.227)
Epoch: [1][409/597]	Time 14.717 (3.440)	Data 14.581 (3.250)	Loss 2.7331 (3.3976)	Acc 0.312 (0.228)
Epoch: [1][410/597]	Time 0.213 (3.432)	Data 0.000 (3.242)	Loss 2.7662 (3.3961)	Acc 0.438 (0.228)
Epoch: [1][411/597]	Time 0.209 (3.424)	Data 0.000 (3.234)	Loss 2.6854 (3.3944)	Acc 0.375 (0.229)
Epoch: [1][412/597]	Time 0.203 (3.416)	Data 0.000 (3.226)	Loss 2.6353 (3.3925)	Acc 0.250 (0.229)
Epoch: [1][413/597]	Time 14.942 (3.444)	Data 14.805 (3.254)	Loss 3.1745 (3.3920)	Acc 0.125 (0.228)
Epoch: [1][414/597]	Time 0.215 (3.436)	Data 0.000 (3.246)	Loss 2.5955 (3.3901)	Acc 0.375 (0.229)
Epoch: [1][415/597]	Time 0.196 (3.429)	Data 0.000 (3.238)	Loss 3.4080 (3.3901)	Acc 0.250 (0.229)
Epoch: [1][416/597]	Time 0.201 (3.421)	Data 0.000 (3.230)	Loss 2.7324 (3.3885)	Acc 0.312 (0.229)
Epoch: [1][417/597]	Time 13.859 (3.446)	Data 13.746 (3.256)	Loss 3.0424 (3.3877)	Acc 0.375 (0.229)
Epoch: [1][418/597]	Time 0.199 (3.438)	Data 0.000 (3.248)	Loss 2.4134 (3.3854)	Acc 0.375 (0.230)
Epoch: [1][419/597]	Time 0.214 (3.430)	Data 0.000 (3.240)	Loss 1.5124 (3.3809)	Acc 0.500 (0.230)
Epoch: [1][420/597]	Time 0.207 (3.423)	Data 0.000 (3.232)	Loss 2.4322 (3.3786)	Acc 0.500 (0.231)
Epoch: [1][421/597]	Time 14.143 (3.448)	Data 14.016 (3.258)	Loss 2.1482 (3.3757)	Acc 0.438 (0.231)
Epoch: [1][422/597]	Time 0.219 (3.441)	Data 0.000 (3.250)	Loss 3.6650 (3.3764)	Acc 0.125 (0.231)
Epoch: [1][423/597]	Time 0.204 (3.433)	Data 0.000 (3.243)	Loss 3.2077 (3.3760)	Acc 0.250 (0.231)
Epoch: [1][424/597]	Time 0.210 (3.425)	Data 0.000 (3.235)	Loss 2.3385 (3.3735)	Acc 0.250 (0.231)
Epoch: [1][425/597]	Time 13.889 (3.450)	Data 13.761 (3.260)	Loss 2.1873 (3.3708)	Acc 0.250 (0.231)
Epoch: [1][426/597]	Time 0.219 (3.442)	Data 0.000 (3.252)	Loss 2.0087 (3.3676)	Acc 0.562 (0.232)
Epoch: [1][427/597]	Time 0.207 (3.435)	Data 0.000 (3.244)	Loss 2.9803 (3.3667)	Acc 0.375 (0.232)
Epoch: [1][428/597]	Time 0.205 (3.427)	Data 0.000 (3.237)	Loss 3.0307 (3.3659)	Acc 0.250 (0.232)
Epoch: [1][429/597]	Time 14.470 (3.453)	Data 14.356 (3.263)	Loss 2.7799 (3.3645)	Acc 0.375 (0.233)
Epoch: [1][430/597]	Time 0.200 (3.445)	Data 0.000 (3.255)	Loss 1.5946 (3.3604)	Acc 0.500 (0.233)
Epoch: [1][431/597]	Time 0.193 (3.438)	Data 0.000 (3.248)	Loss 2.0026 (3.3572)	Acc 0.375 (0.234)
Epoch: [1][432/597]	Time 0.212 (3.430)	Data 0.000 (3.240)	Loss 2.5757 (3.3554)	Acc 0.312 (0.234)
Epoch: [1][433/597]	Time 13.769 (3.454)	Data 13.646 (3.264)	Loss 2.4871 (3.3534)	Acc 0.375 (0.234)
Epoch: [1][434/597]	Time 0.221 (3.447)	Data 0.000 (3.257)	Loss 2.5787 (3.3516)	Acc 0.312 (0.234)
Epoch: [1][435/597]	Time 0.209 (3.439)	Data 0.000 (3.249)	Loss 2.0546 (3.3487)	Acc 0.438 (0.235)
Epoch: [1][436/597]	Time 0.210 (3.432)	Data 0.000 (3.242)	Loss 2.2084 (3.3460)	Acc 0.562 (0.236)
Epoch: [1][437/597]	Time 12.998 (3.454)	Data 12.879 (3.264)	Loss 2.0516 (3.3431)	Acc 0.500 (0.236)
Epoch: [1][438/597]	Time 0.200 (3.446)	Data 0.000 (3.256)	Loss 2.1117 (3.3403)	Acc 0.312 (0.236)
Epoch: [1][439/597]	Time 0.207 (3.439)	Data 0.000 (3.249)	Loss 2.6325 (3.3387)	Acc 0.250 (0.236)
Epoch: [1][440/597]	Time 0.205 (3.432)	Data 0.000 (3.242)	Loss 2.0611 (3.3357)	Acc 0.562 (0.237)
Epoch: [1][441/597]	Time 12.855 (3.453)	Data 12.715 (3.263)	Loss 2.6261 (3.3341)	Acc 0.375 (0.238)
Epoch: [1][442/597]	Time 0.220 (3.446)	Data 0.000 (3.256)	Loss 2.4076 (3.3320)	Acc 0.375 (0.238)
Epoch: [1][443/597]	Time 0.197 (3.438)	Data 0.000 (3.248)	Loss 2.5528 (3.3303)	Acc 0.500 (0.238)
Epoch: [1][444/597]	Time 0.200 (3.431)	Data 0.000 (3.241)	Loss 2.8349 (3.3292)	Acc 0.312 (0.239)
Epoch: [1][445/597]	Time 13.818 (3.455)	Data 13.692 (3.264)	Loss 2.6230 (3.3276)	Acc 0.250 (0.239)
Epoch: [1][446/597]	Time 0.217 (3.447)	Data 0.000 (3.257)	Loss 2.8395 (3.3265)	Acc 0.125 (0.238)
Epoch: [1][447/597]	Time 0.203 (3.440)	Data 0.000 (3.250)	Loss 2.3908 (3.3244)	Acc 0.375 (0.239)
Epoch: [1][448/597]	Time 0.195 (3.433)	Data 0.000 (3.243)	Loss 2.7403 (3.3231)	Acc 0.250 (0.239)
Epoch: [1][449/597]	Time 13.386 (3.455)	Data 13.275 (3.265)	Loss 1.5821 (3.3192)	Acc 0.625 (0.240)
Epoch: [1][450/597]	Time 0.203 (3.448)	Data 0.000 (3.258)	Loss 2.3886 (3.3171)	Acc 0.438 (0.240)
Epoch: [1][451/597]	Time 0.196 (3.440)	Data 0.000 (3.250)	Loss 2.5857 (3.3155)	Acc 0.375 (0.240)
Epoch: [1][452/597]	Time 0.197 (3.433)	Data 0.000 (3.243)	Loss 3.5646 (3.3161)	Acc 0.062 (0.240)
Epoch: [1][453/597]	Time 14.530 (3.458)	Data 14.406 (3.268)	Loss 1.7237 (3.3126)	Acc 0.625 (0.241)
Epoch: [1][454/597]	Time 0.222 (3.451)	Data 0.000 (3.261)	Loss 1.7166 (3.3090)	Acc 0.438 (0.241)
Epoch: [1][455/597]	Time 0.209 (3.444)	Data 0.000 (3.254)	Loss 2.0055 (3.3062)	Acc 0.375 (0.241)
Epoch: [1][456/597]	Time 0.215 (3.436)	Data 0.000 (3.246)	Loss 2.4006 (3.3042)	Acc 0.562 (0.242)
Epoch: [1][457/597]	Time 13.419 (3.458)	Data 13.304 (3.268)	Loss 2.8949 (3.3033)	Acc 0.312 (0.242)
Epoch: [1][458/597]	Time 0.200 (3.451)	Data 0.000 (3.261)	Loss 2.7163 (3.3020)	Acc 0.375 (0.243)
Epoch: [1][459/597]	Time 0.217 (3.444)	Data 0.000 (3.254)	Loss 2.7722 (3.3009)	Acc 0.312 (0.243)
Epoch: [1][460/597]	Time 0.186 (3.437)	Data 0.000 (3.247)	Loss 1.4611 (3.2969)	Acc 0.688 (0.244)
Epoch: [1][461/597]	Time 13.833 (3.460)	Data 13.710 (3.270)	Loss 2.4766 (3.2951)	Acc 0.375 (0.244)
Epoch: [1][462/597]	Time 0.216 (3.453)	Data 0.002 (3.263)	Loss 2.3832 (3.2931)	Acc 0.250 (0.244)
Epoch: [1][463/597]	Time 0.203 (3.446)	Data 0.000 (3.256)	Loss 2.9399 (3.2923)	Acc 0.188 (0.244)
Epoch: [1][464/597]	Time 0.197 (3.439)	Data 0.000 (3.249)	Loss 2.2547 (3.2901)	Acc 0.188 (0.244)
Epoch: [1][465/597]	Time 13.493 (3.460)	Data 13.368 (3.270)	Loss 2.3401 (3.2881)	Acc 0.312 (0.244)
Epoch: [1][466/597]	Time 0.223 (3.453)	Data 0.000 (3.263)	Loss 2.2378 (3.2858)	Acc 0.312 (0.244)
Epoch: [1][467/597]	Time 0.203 (3.446)	Data 0.000 (3.256)	Loss 1.8287 (3.2827)	Acc 0.438 (0.245)
Epoch: [1][468/597]	Time 0.200 (3.439)	Data 0.000 (3.249)	Loss 2.8829 (3.2818)	Acc 0.375 (0.245)
Epoch: [1][469/597]	Time 13.226 (3.460)	Data 13.115 (3.271)	Loss 2.6710 (3.2805)	Acc 0.250 (0.245)
Epoch: [1][470/597]	Time 0.211 (3.453)	Data 0.000 (3.264)	Loss 2.9846 (3.2799)	Acc 0.250 (0.245)
Epoch: [1][471/597]	Time 0.196 (3.446)	Data 0.000 (3.257)	Loss 1.6853 (3.2765)	Acc 0.375 (0.245)
Epoch: [1][472/597]	Time 0.198 (3.440)	Data 0.000 (3.250)	Loss 3.0634 (3.2761)	Acc 0.250 (0.245)
Epoch: [1][473/597]	Time 13.546 (3.461)	Data 13.422 (3.271)	Loss 2.9483 (3.2754)	Acc 0.375 (0.245)
Epoch: [1][474/597]	Time 0.233 (3.454)	Data 0.000 (3.264)	Loss 2.3345 (3.2734)	Acc 0.312 (0.246)
Epoch: [1][475/597]	Time 0.192 (3.447)	Data 0.000 (3.257)	Loss 2.8174 (3.2724)	Acc 0.375 (0.246)
Epoch: [1][476/597]	Time 0.197 (3.440)	Data 0.000 (3.251)	Loss 2.6267 (3.2711)	Acc 0.375 (0.246)
Epoch: [1][477/597]	Time 13.021 (3.460)	Data 12.895 (3.271)	Loss 2.4181 (3.2693)	Acc 0.438 (0.246)
Epoch: [1][478/597]	Time 0.226 (3.454)	Data 0.000 (3.264)	Loss 3.0488 (3.2688)	Acc 0.312 (0.247)
Epoch: [1][479/597]	Time 0.201 (3.447)	Data 0.000 (3.257)	Loss 2.1246 (3.2664)	Acc 0.375 (0.247)
Epoch: [1][480/597]	Time 0.195 (3.440)	Data 0.000 (3.250)	Loss 2.9116 (3.2657)	Acc 0.312 (0.247)
Epoch: [1][481/597]	Time 13.604 (3.461)	Data 13.491 (3.272)	Loss 2.6214 (3.2644)	Acc 0.188 (0.247)
Epoch: [1][482/597]	Time 0.211 (3.455)	Data 0.000 (3.265)	Loss 2.2905 (3.2623)	Acc 0.375 (0.247)
Epoch: [1][483/597]	Time 0.200 (3.448)	Data 0.000 (3.258)	Loss 1.7083 (3.2591)	Acc 0.625 (0.248)
Epoch: [1][484/597]	Time 0.195 (3.441)	Data 0.000 (3.251)	Loss 2.0833 (3.2567)	Acc 0.438 (0.248)
Epoch: [1][485/597]	Time 13.332 (3.461)	Data 13.193 (3.272)	Loss 2.5932 (3.2553)	Acc 0.312 (0.248)
Epoch: [1][486/597]	Time 0.210 (3.455)	Data 0.000 (3.265)	Loss 2.8031 (3.2544)	Acc 0.312 (0.249)
Epoch: [1][487/597]	Time 0.204 (3.448)	Data 0.000 (3.258)	Loss 1.9112 (3.2516)	Acc 0.375 (0.249)
Epoch: [1][488/597]	Time 0.211 (3.441)	Data 0.000 (3.252)	Loss 2.8892 (3.2509)	Acc 0.312 (0.249)
Epoch: [1][489/597]	Time 13.268 (3.462)	Data 13.152 (3.272)	Loss 2.4147 (3.2492)	Acc 0.375 (0.249)
Epoch: [1][490/597]	Time 0.205 (3.455)	Data 0.000 (3.265)	Loss 2.3087 (3.2473)	Acc 0.375 (0.249)
Epoch: [1][491/597]	Time 0.190 (3.448)	Data 0.000 (3.259)	Loss 1.4354 (3.2436)	Acc 0.562 (0.250)
Epoch: [1][492/597]	Time 0.197 (3.442)	Data 0.000 (3.252)	Loss 2.1486 (3.2413)	Acc 0.438 (0.251)
Epoch: [1][493/597]	Time 13.112 (3.461)	Data 12.970 (3.272)	Loss 2.4019 (3.2396)	Acc 0.312 (0.251)
Epoch: [1][494/597]	Time 0.219 (3.455)	Data 0.000 (3.265)	Loss 1.9479 (3.2370)	Acc 0.625 (0.251)
Epoch: [1][495/597]	Time 0.206 (3.448)	Data 0.000 (3.259)	Loss 1.9795 (3.2345)	Acc 0.500 (0.252)
Epoch: [1][496/597]	Time 0.201 (3.442)	Data 0.000 (3.252)	Loss 2.5569 (3.2331)	Acc 0.438 (0.252)
Epoch: [1][497/597]	Time 13.261 (3.461)	Data 13.147 (3.272)	Loss 2.5159 (3.2317)	Acc 0.438 (0.253)
Epoch: [1][498/597]	Time 0.198 (3.455)	Data 0.000 (3.265)	Loss 3.1093 (3.2314)	Acc 0.188 (0.253)
Epoch: [1][499/597]	Time 0.213 (3.448)	Data 0.000 (3.259)	Loss 1.9615 (3.2289)	Acc 0.375 (0.253)
Epoch: [1][500/597]	Time 0.196 (3.442)	Data 0.000 (3.252)	Loss 2.2754 (3.2270)	Acc 0.312 (0.253)
Epoch: [1][501/597]	Time 13.216 (3.461)	Data 13.091 (3.272)	Loss 2.8803 (3.2263)	Acc 0.188 (0.253)
Epoch: [1][502/597]	Time 0.220 (3.455)	Data 0.000 (3.265)	Loss 1.8094 (3.2235)	Acc 0.500 (0.253)
Epoch: [1][503/597]	Time 0.205 (3.448)	Data 0.000 (3.259)	Loss 1.3976 (3.2198)	Acc 0.812 (0.254)
Epoch: [1][504/597]	Time 0.206 (3.442)	Data 0.000 (3.252)	Loss 2.6104 (3.2186)	Acc 0.438 (0.255)
Epoch: [1][505/597]	Time 12.375 (3.460)	Data 12.251 (3.270)	Loss 2.1861 (3.2166)	Acc 0.375 (0.255)
Epoch: [1][506/597]	Time 0.221 (3.453)	Data 0.000 (3.264)	Loss 3.5166 (3.2172)	Acc 0.312 (0.255)
Epoch: [1][507/597]	Time 0.222 (3.447)	Data 0.000 (3.257)	Loss 2.2195 (3.2152)	Acc 0.500 (0.256)
Epoch: [1][508/597]	Time 0.180 (3.440)	Data 0.000 (3.251)	Loss 2.5268 (3.2139)	Acc 0.375 (0.256)
Epoch: [1][509/597]	Time 13.836 (3.461)	Data 13.718 (3.272)	Loss 2.9675 (3.2134)	Acc 0.125 (0.256)
Epoch: [1][510/597]	Time 0.193 (3.454)	Data 0.000 (3.265)	Loss 3.3288 (3.2136)	Acc 0.250 (0.256)
Epoch: [1][511/597]	Time 0.256 (3.448)	Data 0.141 (3.259)	Loss 2.2735 (3.2118)	Acc 0.438 (0.256)
Epoch: [1][512/597]	Time 0.198 (3.442)	Data 0.000 (3.253)	Loss 2.0851 (3.2096)	Acc 0.312 (0.256)
Epoch: [1][513/597]	Time 13.566 (3.462)	Data 13.411 (3.272)	Loss 2.8233 (3.2088)	Acc 0.250 (0.256)
Epoch: [1][514/597]	Time 0.183 (3.455)	Data 0.000 (3.266)	Loss 2.1685 (3.2068)	Acc 0.375 (0.256)
Epoch: [1][515/597]	Time 0.198 (3.449)	Data 0.000 (3.260)	Loss 2.2894 (3.2050)	Acc 0.500 (0.257)
Epoch: [1][516/597]	Time 0.197 (3.443)	Data 0.000 (3.253)	Loss 3.0372 (3.2047)	Acc 0.250 (0.257)
Epoch: [1][517/597]	Time 13.369 (3.462)	Data 13.240 (3.273)	Loss 3.7097 (3.2056)	Acc 0.250 (0.257)
Epoch: [1][518/597]	Time 0.227 (3.456)	Data 0.000 (3.266)	Loss 2.0308 (3.2034)	Acc 0.438 (0.257)
Epoch: [1][519/597]	Time 0.193 (3.449)	Data 0.056 (3.260)	Loss 2.4987 (3.2020)	Acc 0.312 (0.257)
Epoch: [1][520/597]	Time 0.198 (3.443)	Data 0.000 (3.254)	Loss 2.5455 (3.2008)	Acc 0.312 (0.257)
Epoch: [1][521/597]	Time 14.030 (3.463)	Data 13.899 (3.274)	Loss 2.3560 (3.1991)	Acc 0.375 (0.257)
Epoch: [1][522/597]	Time 0.195 (3.457)	Data 0.000 (3.268)	Loss 2.7487 (3.1983)	Acc 0.375 (0.258)
Epoch: [1][523/597]	Time 0.192 (3.451)	Data 0.000 (3.262)	Loss 2.9758 (3.1979)	Acc 0.062 (0.257)
Epoch: [1][524/597]	Time 0.203 (3.445)	Data 0.000 (3.256)	Loss 2.5975 (3.1967)	Acc 0.438 (0.258)
Epoch: [1][525/597]	Time 13.685 (3.464)	Data 13.559 (3.275)	Loss 2.6373 (3.1956)	Acc 0.250 (0.258)
Epoch: [1][526/597]	Time 0.212 (3.458)	Data 0.000 (3.269)	Loss 1.7203 (3.1928)	Acc 0.562 (0.258)
Epoch: [1][527/597]	Time 0.205 (3.452)	Data 0.000 (3.263)	Loss 1.8696 (3.1903)	Acc 0.438 (0.259)
Epoch: [1][528/597]	Time 0.199 (3.446)	Data 0.000 (3.257)	Loss 1.8945 (3.1879)	Acc 0.500 (0.259)
Epoch: [1][529/597]	Time 13.662 (3.465)	Data 13.535 (3.276)	Loss 3.2186 (3.1879)	Acc 0.125 (0.259)
Epoch: [1][530/597]	Time 0.233 (3.459)	Data 0.000 (3.270)	Loss 2.2685 (3.1862)	Acc 0.375 (0.259)
Epoch: [1][531/597]	Time 0.194 (3.453)	Data 0.000 (3.264)	Loss 2.9203 (3.1857)	Acc 0.188 (0.259)
Epoch: [1][532/597]	Time 0.198 (3.447)	Data 0.000 (3.258)	Loss 3.6692 (3.1866)	Acc 0.188 (0.259)
Epoch: [1][533/597]	Time 13.203 (3.465)	Data 13.089 (3.276)	Loss 1.9001 (3.1842)	Acc 0.375 (0.259)
Epoch: [1][534/597]	Time 0.209 (3.459)	Data 0.000 (3.270)	Loss 2.3642 (3.1827)	Acc 0.500 (0.259)
Epoch: [1][535/597]	Time 0.199 (3.453)	Data 0.000 (3.264)	Loss 2.4989 (3.1814)	Acc 0.438 (0.260)
Epoch: [1][536/597]	Time 0.198 (3.447)	Data 0.000 (3.258)	Loss 2.7207 (3.1805)	Acc 0.312 (0.260)
Epoch: [1][537/597]	Time 13.756 (3.466)	Data 13.631 (3.277)	Loss 3.1542 (3.1805)	Acc 0.250 (0.260)
Epoch: [1][538/597]	Time 0.230 (3.460)	Data 0.000 (3.271)	Loss 2.1266 (3.1785)	Acc 0.438 (0.260)
Epoch: [1][539/597]	Time 0.189 (3.454)	Data 0.000 (3.265)	Loss 2.4648 (3.1772)	Acc 0.312 (0.260)
Epoch: [1][540/597]	Time 0.199 (3.448)	Data 0.000 (3.259)	Loss 2.7185 (3.1763)	Acc 0.250 (0.260)
Epoch: [1][541/597]	Time 13.529 (3.466)	Data 13.401 (3.278)	Loss 2.7412 (3.1755)	Acc 0.375 (0.260)
Epoch: [1][542/597]	Time 0.198 (3.460)	Data 0.000 (3.272)	Loss 2.1358 (3.1736)	Acc 0.562 (0.261)
Epoch: [1][543/597]	Time 0.200 (3.454)	Data 0.000 (3.266)	Loss 3.1917 (3.1736)	Acc 0.250 (0.261)
Epoch: [1][544/597]	Time 0.198 (3.448)	Data 0.000 (3.260)	Loss 2.1398 (3.1717)	Acc 0.500 (0.261)
Epoch: [1][545/597]	Time 12.821 (3.465)	Data 12.684 (3.277)	Loss 3.1121 (3.1716)	Acc 0.188 (0.261)
Epoch: [1][546/597]	Time 0.219 (3.460)	Data 0.000 (3.271)	Loss 2.9567 (3.1712)	Acc 0.125 (0.261)
Epoch: [1][547/597]	Time 0.205 (3.454)	Data 0.000 (3.265)	Loss 2.3802 (3.1698)	Acc 0.500 (0.261)
Epoch: [1][548/597]	Time 0.198 (3.448)	Data 0.000 (3.259)	Loss 2.2432 (3.1681)	Acc 0.562 (0.262)
Epoch: [1][549/597]	Time 12.915 (3.465)	Data 12.783 (3.276)	Loss 1.9040 (3.1658)	Acc 0.375 (0.262)
Epoch: [1][550/597]	Time 0.192 (3.459)	Data 0.000 (3.270)	Loss 2.3214 (3.1643)	Acc 0.375 (0.262)
Epoch: [1][551/597]	Time 0.200 (3.453)	Data 0.000 (3.264)	Loss 2.6222 (3.1633)	Acc 0.438 (0.263)
Epoch: [1][552/597]	Time 0.198 (3.447)	Data 0.000 (3.258)	Loss 2.2656 (3.1617)	Acc 0.500 (0.263)
Epoch: [1][553/597]	Time 13.951 (3.466)	Data 13.828 (3.278)	Loss 3.2611 (3.1618)	Acc 0.250 (0.263)
Epoch: [1][554/597]	Time 0.216 (3.460)	Data 0.000 (3.272)	Loss 2.2517 (3.1602)	Acc 0.500 (0.264)
Epoch: [1][555/597]	Time 0.213 (3.454)	Data 0.000 (3.266)	Loss 2.4392 (3.1589)	Acc 0.375 (0.264)
Epoch: [1][556/597]	Time 0.193 (3.449)	Data 0.000 (3.260)	Loss 2.4136 (3.1576)	Acc 0.500 (0.264)
Epoch: [1][557/597]	Time 13.528 (3.467)	Data 13.393 (3.278)	Loss 3.3135 (3.1578)	Acc 0.250 (0.264)
Epoch: [1][558/597]	Time 0.222 (3.461)	Data 0.000 (3.272)	Loss 3.3923 (3.1583)	Acc 0.250 (0.264)
Epoch: [1][559/597]	Time 0.208 (3.455)	Data 0.000 (3.266)	Loss 1.9379 (3.1561)	Acc 0.500 (0.265)
Epoch: [1][560/597]	Time 0.213 (3.449)	Data 0.000 (3.260)	Loss 3.1816 (3.1561)	Acc 0.188 (0.264)
Epoch: [1][561/597]	Time 13.531 (3.467)	Data 13.416 (3.279)	Loss 1.1283 (3.1525)	Acc 0.750 (0.265)
Epoch: [1][562/597]	Time 0.197 (3.461)	Data 0.000 (3.273)	Loss 1.6357 (3.1498)	Acc 0.500 (0.266)
Epoch: [1][563/597]	Time 0.199 (3.456)	Data 0.000 (3.267)	Loss 2.4539 (3.1486)	Acc 0.375 (0.266)
Epoch: [1][564/597]	Time 0.197 (3.450)	Data 0.000 (3.261)	Loss 2.2195 (3.1469)	Acc 0.500 (0.266)
Epoch: [1][565/597]	Time 13.492 (3.468)	Data 13.373 (3.279)	Loss 2.7693 (3.1463)	Acc 0.438 (0.267)
Epoch: [1][566/597]	Time 0.218 (3.462)	Data 0.000 (3.273)	Loss 2.0421 (3.1443)	Acc 0.438 (0.267)
Epoch: [1][567/597]	Time 0.211 (3.456)	Data 0.000 (3.267)	Loss 3.1825 (3.1444)	Acc 0.250 (0.267)
Epoch: [1][568/597]	Time 0.200 (3.450)	Data 0.000 (3.262)	Loss 1.8857 (3.1422)	Acc 0.500 (0.267)
Epoch: [1][569/597]	Time 15.122 (3.471)	Data 15.000 (3.282)	Loss 2.0774 (3.1403)	Acc 0.438 (0.268)
Epoch: [1][570/597]	Time 0.229 (3.465)	Data 0.000 (3.277)	Loss 2.4323 (3.1390)	Acc 0.438 (0.268)
Epoch: [1][571/597]	Time 0.192 (3.459)	Data 0.000 (3.271)	Loss 2.5361 (3.1380)	Acc 0.438 (0.268)
Epoch: [1][572/597]	Time 0.202 (3.454)	Data 0.000 (3.265)	Loss 3.9125 (3.1393)	Acc 0.250 (0.268)
Epoch: [1][573/597]	Time 12.988 (3.470)	Data 12.860 (3.282)	Loss 1.7601 (3.1369)	Acc 0.500 (0.269)
Epoch: [1][574/597]	Time 0.199 (3.465)	Data 0.000 (3.276)	Loss 2.2913 (3.1355)	Acc 0.438 (0.269)
Epoch: [1][575/597]	Time 0.198 (3.459)	Data 0.000 (3.270)	Loss 2.7093 (3.1347)	Acc 0.188 (0.269)
Epoch: [1][576/597]	Time 0.200 (3.453)	Data 0.000 (3.265)	Loss 1.5393 (3.1319)	Acc 0.500 (0.269)
Epoch: [1][577/597]	Time 13.460 (3.471)	Data 13.331 (3.282)	Loss 2.8372 (3.1314)	Acc 0.312 (0.269)
Epoch: [1][578/597]	Time 0.217 (3.465)	Data 0.000 (3.277)	Loss 2.8442 (3.1309)	Acc 0.375 (0.269)
Epoch: [1][579/597]	Time 0.209 (3.459)	Data 0.000 (3.271)	Loss 2.9253 (3.1306)	Acc 0.125 (0.269)
Epoch: [1][580/597]	Time 0.200 (3.454)	Data 0.000 (3.265)	Loss 2.2636 (3.1291)	Acc 0.438 (0.269)
Epoch: [1][581/597]	Time 12.674 (3.470)	Data 12.559 (3.281)	Loss 2.1956 (3.1275)	Acc 0.375 (0.270)
Epoch: [1][582/597]	Time 0.207 (3.464)	Data 0.000 (3.276)	Loss 3.2612 (3.1277)	Acc 0.188 (0.269)
Epoch: [1][583/597]	Time 0.212 (3.459)	Data 0.000 (3.270)	Loss 2.0380 (3.1258)	Acc 0.375 (0.270)
Epoch: [1][584/597]	Time 0.189 (3.453)	Data 0.000 (3.264)	Loss 1.8112 (3.1236)	Acc 0.312 (0.270)
Epoch: [1][585/597]	Time 12.162 (3.468)	Data 12.037 (3.279)	Loss 2.5794 (3.1227)	Acc 0.375 (0.270)
Epoch: [1][586/597]	Time 0.212 (3.462)	Data 0.000 (3.274)	Loss 2.5277 (3.1216)	Acc 0.375 (0.270)
Epoch: [1][587/597]	Time 0.736 (3.458)	Data 0.617 (3.269)	Loss 2.3713 (3.1204)	Acc 0.375 (0.270)
Epoch: [1][588/597]	Time 0.195 (3.452)	Data 0.000 (3.264)	Loss 2.8615 (3.1199)	Acc 0.188 (0.270)
Epoch: [1][589/597]	Time 12.973 (3.468)	Data 12.858 (3.280)	Loss 3.4825 (3.1205)	Acc 0.250 (0.270)
Epoch: [1][590/597]	Time 0.218 (3.463)	Data 0.000 (3.274)	Loss 1.8348 (3.1184)	Acc 0.500 (0.270)
Epoch: [1][591/597]	Time 0.319 (3.457)	Data 0.199 (3.269)	Loss 2.5137 (3.1173)	Acc 0.375 (0.271)
Epoch: [1][592/597]	Time 0.198 (3.452)	Data 0.000 (3.264)	Loss 3.2468 (3.1176)	Acc 0.250 (0.271)
Epoch: [1][593/597]	Time 12.743 (3.468)	Data 12.623 (3.279)	Loss 2.7227 (3.1169)	Acc 0.312 (0.271)
Epoch: [1][594/597]	Time 0.240 (3.462)	Data 0.000 (3.274)	Loss 2.5333 (3.1159)	Acc 0.312 (0.271)
Epoch: [1][595/597]	Time 0.179 (3.457)	Data 0.014 (3.268)	Loss 2.1789 (3.1143)	Acc 0.562 (0.271)
Epoch: [1][596/597]	Time 0.196 (3.451)	Data 0.000 (3.263)	Loss 2.3830 (3.1131)	Acc 0.250 (0.271)
Epoch: [1][597/597]	Time 3.474 (3.451)	Data 0.240 (3.258)	Loss 7.1070 (3.1135)	Acc 0.000 (0.271)
validation at epoch 1
Epoch: [1][1/757]	Time 14.421 (14.421)	Data 13.575 (13.575)	Loss 0.6753 (0.6753)	Acc 0.667 (0.667)
Epoch: [1][2/757]	Time 0.074 (7.247)	Data 0.000 (6.787)	Loss 0.9521 (0.8137)	Acc 0.333 (0.500)
Epoch: [1][3/757]	Time 0.072 (4.856)	Data 0.000 (4.525)	Loss 1.5232 (1.0502)	Acc 0.000 (0.333)
Epoch: [1][4/757]	Time 0.071 (3.659)	Data 0.000 (3.394)	Loss 0.8430 (0.9984)	Acc 0.600 (0.400)
Epoch: [1][5/757]	Time 11.977 (5.323)	Data 11.902 (5.096)	Loss 0.8112 (0.9609)	Acc 0.400 (0.400)
Epoch: [1][6/757]	Time 0.084 (4.450)	Data 0.000 (4.246)	Loss 0.4338 (0.8731)	Acc 1.000 (0.500)
Epoch: [1][7/757]	Time 0.072 (3.824)	Data 0.000 (3.640)	Loss 0.6199 (0.8369)	Acc 0.933 (0.562)
Epoch: [1][8/757]	Time 0.076 (3.356)	Data 0.000 (3.185)	Loss 0.5356 (0.7993)	Acc 0.933 (0.608)
Epoch: [1][9/757]	Time 11.690 (4.282)	Data 11.611 (4.121)	Loss 0.3194 (0.7459)	Acc 1.000 (0.652)
Epoch: [1][10/757]	Time 0.079 (3.862)	Data 0.000 (3.709)	Loss 0.3788 (0.7092)	Acc 0.800 (0.667)
Epoch: [1][11/757]	Time 0.078 (3.518)	Data 0.000 (3.372)	Loss 0.8129 (0.7186)	Acc 0.667 (0.667)
Epoch: [1][12/757]	Time 0.075 (3.231)	Data 0.000 (3.091)	Loss 0.6726 (0.7148)	Acc 0.800 (0.678)
Epoch: [1][13/757]	Time 13.387 (4.012)	Data 13.315 (3.877)	Loss 0.7495 (0.7175)	Acc 0.667 (0.677)
Epoch: [1][14/757]	Time 0.071 (3.731)	Data 0.000 (3.600)	Loss 0.8061 (0.7238)	Acc 0.667 (0.676)
Epoch: [1][15/757]	Time 0.073 (3.487)	Data 0.000 (3.360)	Loss 0.1705 (0.6869)	Acc 1.000 (0.698)
Epoch: [1][16/757]	Time 0.072 (3.273)	Data 0.000 (3.150)	Loss 1.0753 (0.7112)	Acc 0.533 (0.688)
Epoch: [1][17/757]	Time 13.659 (3.884)	Data 13.588 (3.764)	Loss 3.6607 (0.8847)	Acc 0.000 (0.647)
Epoch: [1][18/757]	Time 0.071 (3.672)	Data 0.000 (3.555)	Loss 2.8727 (0.9951)	Acc 0.200 (0.622)
Epoch: [1][19/757]	Time 0.072 (3.483)	Data 0.000 (3.368)	Loss 3.4619 (1.1250)	Acc 0.067 (0.593)
Epoch: [1][20/757]	Time 0.075 (3.312)	Data 0.000 (3.200)	Loss 2.7039 (1.2039)	Acc 0.000 (0.563)
Epoch: [1][21/757]	Time 11.767 (3.715)	Data 11.695 (3.604)	Loss 4.1413 (1.3438)	Acc 0.000 (0.537)
Epoch: [1][22/757]	Time 0.071 (3.549)	Data 0.000 (3.440)	Loss 5.8556 (1.5489)	Acc 0.000 (0.512)
Epoch: [1][23/757]	Time 0.070 (3.398)	Data 0.000 (3.291)	Loss 3.1961 (1.6205)	Acc 0.267 (0.501)
Epoch: [1][24/757]	Time 0.197 (3.265)	Data 0.000 (3.154)	Loss 3.8261 (1.7124)	Acc 0.267 (0.492)
Epoch: [1][25/757]	Time 11.167 (3.581)	Data 11.084 (3.471)	Loss 2.4445 (1.7417)	Acc 0.200 (0.480)
Epoch: [1][26/757]	Time 0.073 (3.446)	Data 0.000 (3.337)	Loss 1.2918 (1.7244)	Acc 0.667 (0.487)
Epoch: [1][27/757]	Time 0.073 (3.321)	Data 0.000 (3.214)	Loss 2.0604 (1.7368)	Acc 0.467 (0.486)
Epoch: [1][28/757]	Time 0.073 (3.205)	Data 0.000 (3.099)	Loss 2.2831 (1.7563)	Acc 0.267 (0.479)
Epoch: [1][29/757]	Time 14.219 (3.585)	Data 14.139 (3.480)	Loss 2.9767 (1.7984)	Acc 0.133 (0.467)
Epoch: [1][30/757]	Time 0.085 (3.468)	Data 0.005 (3.364)	Loss 0.9528 (1.7702)	Acc 0.867 (0.480)
Epoch: [1][31/757]	Time 0.072 (3.359)	Data 0.000 (3.255)	Loss 5.1955 (1.8807)	Acc 0.133 (0.469)
Epoch: [1][32/757]	Time 0.071 (3.256)	Data 0.000 (3.154)	Loss 2.4789 (1.8994)	Acc 0.133 (0.458)
Epoch: [1][33/757]	Time 10.857 (3.486)	Data 10.787 (3.385)	Loss 3.0626 (1.9347)	Acc 0.067 (0.446)
Epoch: [1][34/757]	Time 0.072 (3.386)	Data 0.000 (3.285)	Loss 5.8800 (2.0507)	Acc 0.000 (0.433)
Epoch: [1][35/757]	Time 0.070 (3.291)	Data 0.000 (3.192)	Loss 8.8845 (2.2459)	Acc 0.000 (0.421)
Epoch: [1][36/757]	Time 0.074 (3.202)	Data 0.000 (3.103)	Loss 8.1349 (2.4095)	Acc 0.000 (0.409)
Epoch: [1][37/757]	Time 12.459 (3.452)	Data 12.380 (3.354)	Loss 2.6368 (2.4157)	Acc 0.400 (0.409)
Epoch: [1][38/757]	Time 0.077 (3.363)	Data 0.000 (3.265)	Loss 0.2992 (2.3600)	Acc 0.933 (0.423)
Epoch: [1][39/757]	Time 0.079 (3.279)	Data 0.000 (3.182)	Loss 0.5742 (2.3142)	Acc 0.867 (0.434)
Epoch: [1][40/757]	Time 0.090 (3.199)	Data 0.000 (3.102)	Loss 1.6412 (2.2974)	Acc 0.600 (0.438)
Epoch: [1][41/757]	Time 12.765 (3.432)	Data 12.692 (3.336)	Loss 1.9148 (2.2880)	Acc 0.467 (0.439)
Epoch: [1][42/757]	Time 0.439 (3.361)	Data 0.000 (3.257)	Loss 0.9189 (2.2597)	Acc 0.692 (0.444)
Epoch: [1][43/757]	Time 0.070 (3.285)	Data 0.000 (3.181)	Loss 1.7881 (2.2487)	Acc 0.400 (0.443)
Epoch: [1][44/757]	Time 0.070 (3.212)	Data 0.000 (3.109)	Loss 1.7222 (2.2367)	Acc 0.400 (0.442)
Epoch: [1][45/757]	Time 11.643 (3.399)	Data 11.573 (3.297)	Loss 1.9027 (2.2292)	Acc 0.533 (0.444)
Epoch: [1][46/757]	Time 0.071 (3.327)	Data 0.000 (3.225)	Loss 5.4574 (2.2996)	Acc 0.133 (0.438)
Epoch: [1][47/757]	Time 0.071 (3.257)	Data 0.000 (3.156)	Loss 3.0342 (2.3153)	Acc 0.600 (0.441)
Epoch: [1][48/757]	Time 0.071 (3.191)	Data 0.000 (3.091)	Loss 4.6067 (2.3632)	Acc 0.200 (0.436)
Epoch: [1][49/757]	Time 10.966 (3.350)	Data 10.895 (3.250)	Loss 4.1673 (2.4001)	Acc 0.267 (0.432)
Epoch: [1][50/757]	Time 0.071 (3.284)	Data 0.000 (3.185)	Loss 6.5675 (2.4837)	Acc 0.000 (0.424)
Epoch: [1][51/757]	Time 0.071 (3.221)	Data 0.000 (3.122)	Loss 3.9765 (2.5130)	Acc 0.000 (0.415)
Epoch: [1][52/757]	Time 0.056 (3.160)	Data 0.000 (3.062)	Loss 0.2618 (2.4753)	Acc 0.923 (0.424)
Epoch: [1][53/757]	Time 10.965 (3.307)	Data 10.885 (3.210)	Loss 0.6268 (2.4402)	Acc 0.667 (0.429)
Epoch: [1][54/757]	Time 0.081 (3.248)	Data 0.000 (3.151)	Loss 1.4189 (2.4212)	Acc 0.200 (0.424)
Epoch: [1][55/757]	Time 0.081 (3.190)	Data 0.000 (3.093)	Loss 1.3566 (2.4018)	Acc 0.400 (0.424)
Epoch: [1][56/757]	Time 0.076 (3.135)	Data 0.000 (3.038)	Loss 1.3121 (2.3822)	Acc 0.533 (0.426)
Epoch: [1][57/757]	Time 12.134 (3.292)	Data 12.063 (3.196)	Loss 1.2639 (2.3625)	Acc 0.600 (0.429)
Epoch: [1][58/757]	Time 0.071 (3.237)	Data 0.000 (3.141)	Loss 0.9574 (2.3382)	Acc 0.600 (0.432)
Epoch: [1][59/757]	Time 0.071 (3.183)	Data 0.000 (3.088)	Loss 1.2974 (2.3205)	Acc 0.467 (0.432)
Epoch: [1][60/757]	Time 0.070 (3.131)	Data 0.000 (3.037)	Loss 1.8210 (2.3121)	Acc 0.333 (0.431)
Epoch: [1][61/757]	Time 10.566 (3.253)	Data 10.495 (3.159)	Loss 1.3452 (2.2962)	Acc 0.600 (0.434)
Epoch: [1][62/757]	Time 0.071 (3.202)	Data 0.000 (3.108)	Loss 0.4948 (2.2670)	Acc 0.867 (0.441)
Epoch: [1][63/757]	Time 0.071 (3.152)	Data 0.000 (3.059)	Loss 1.2037 (2.2500)	Acc 0.600 (0.443)
Epoch: [1][64/757]	Time 0.071 (3.104)	Data 0.000 (3.011)	Loss 1.2926 (2.2350)	Acc 0.800 (0.449)
Epoch: [1][65/757]	Time 8.502 (3.187)	Data 8.442 (3.094)	Loss 1.2258 (2.2205)	Acc 0.643 (0.452)
Epoch: [1][66/757]	Time 0.072 (3.140)	Data 0.000 (3.047)	Loss 0.9344 (2.2009)	Acc 0.733 (0.456)
Epoch: [1][67/757]	Time 0.072 (3.094)	Data 0.000 (3.002)	Loss 1.3556 (2.1882)	Acc 0.800 (0.461)
Traceback (most recent call last):
  File "main.py", line 433, in <module>
    main_worker(-1, opt)
  File "main.py", line 400, in main_worker
    prev_val_loss = val_epoch(i, val_loader, model, criterion,
  File "/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/validation.py", line 36, in val_epoch
    outputs = model(inputs)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 155, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 165, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 85, in parallel_apply
    output.reraise()
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 60, in _worker
    output = module(*input, **kwargs)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/models/resnet.py", line 223, in forward
    x = self.layer3(x)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/tudelft.net/staff-bulk/ewi/insy/VisionLab/ombrettastraff/3D-ResNets-PyTorch/models/resnet.py", line 108, in forward
    out = self.conv3(out)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/nfs/ombrettastraff/envs/h5/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 480, in forward
    return F.conv3d(input, self.weight, self.bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 9.14 GiB (GPU 0; 10.92 GiB total capacity; 555.36 MiB already allocated; 9.14 GiB free; 1.21 GiB reserved in total by PyTorch)

srun: error: insy14: task 0: Exited with exit code 1
